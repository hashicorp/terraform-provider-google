// Copyright (c) HashiCorp, Inc.
// SPDX-License-Identifier: MPL-2.0

// ----------------------------------------------------------------------------
//
//     ***     AUTO GENERATED CODE    ***    Type: MMv1     ***
//
// ----------------------------------------------------------------------------
//
//     This code is generated by Magic Modules using the following:
//
//     Configuration: https://github.com/GoogleCloudPlatform/magic-modules/tree/main/mmv1/products/storagebatchoperations/Job.yaml
//     Template:      https://github.com/GoogleCloudPlatform/magic-modules/tree/main/mmv1/templates/terraform/resource.go.tmpl
//
//     DO NOT EDIT this file directly. Any changes made to this file will be
//     overwritten during the next generation cycle.
//
// ----------------------------------------------------------------------------

package storagebatchoperations

import (
	"fmt"
	"log"
	"net/http"
	"reflect"
	"time"

	"github.com/hashicorp/terraform-plugin-sdk/v2/helper/customdiff"
	"github.com/hashicorp/terraform-plugin-sdk/v2/helper/schema"
	"github.com/hashicorp/terraform-plugin-sdk/v2/helper/validation"

	"github.com/hashicorp/terraform-provider-google/google/tpgresource"
	transport_tpg "github.com/hashicorp/terraform-provider-google/google/transport"
	"github.com/hashicorp/terraform-provider-google/google/verify"
)

func ResourceStorageBatchOperationsJob() *schema.Resource {
	return &schema.Resource{
		Create: resourceStorageBatchOperationsJobCreate,
		Read:   resourceStorageBatchOperationsJobRead,
		Update: resourceStorageBatchOperationsJobUpdate,
		Delete: resourceStorageBatchOperationsJobDelete,

		Importer: &schema.ResourceImporter{
			State: resourceStorageBatchOperationsJobImport,
		},

		Timeouts: &schema.ResourceTimeout{
			Create: schema.DefaultTimeout(120 * time.Minute),
			Update: schema.DefaultTimeout(120 * time.Minute),
			Delete: schema.DefaultTimeout(20 * time.Minute),
		},

		CustomizeDiff: customdiff.All(
			tpgresource.DefaultProviderProject,
		),

		Schema: map[string]*schema.Schema{
			"bucket_list": {
				Type:        schema.TypeList,
				Optional:    true,
				ForceNew:    true,
				Description: `List of buckets and their objects to be transformed. Currently, only one bucket configuration is supported. If multiple buckets are specified, an error will be returned`,
				MaxItems:    1,
				Elem: &schema.Resource{
					Schema: map[string]*schema.Schema{
						"buckets": {
							Type:        schema.TypeList,
							Required:    true,
							ForceNew:    true,
							Description: `List of buckets and their objects to be transformed.`,
							MinItems:    1,
							MaxItems:    1,
							Elem: &schema.Resource{
								Schema: map[string]*schema.Schema{
									"bucket": {
										Type:        schema.TypeString,
										Required:    true,
										ForceNew:    true,
										Description: `Bucket name for the objects to be transformed.`,
									},
									"manifest": {
										Type:        schema.TypeList,
										Optional:    true,
										ForceNew:    true,
										Description: `contain the manifest source file that is a CSV file in a Google Cloud Storage bucket.`,
										MaxItems:    1,
										Elem: &schema.Resource{
											Schema: map[string]*schema.Schema{
												"manifest_location": {
													Type:        schema.TypeString,
													Optional:    true,
													ForceNew:    true,
													Description: `Specifies objects in a manifest file.`,
												},
											},
										},
										ExactlyOneOf: []string{"bucket_list.0.buckets.0.prefix_list", "bucket_list.0.buckets.0.manifest"},
									},
									"prefix_list": {
										Type:        schema.TypeList,
										Optional:    true,
										ForceNew:    true,
										Description: `Specifies objects matching a prefix set.`,
										MaxItems:    1,
										Elem: &schema.Resource{
											Schema: map[string]*schema.Schema{
												"included_object_prefixes": {
													Type:        schema.TypeList,
													Optional:    true,
													ForceNew:    true,
													Description: ``,
													MinItems:    1,
													Elem: &schema.Schema{
														Type: schema.TypeString,
													},
												},
											},
										},
										ExactlyOneOf: []string{"bucket_list.0.buckets.0.prefix_list", "bucket_list.0.buckets.0.manifest"},
									},
								},
							},
						},
					},
				},
			},
			"delete_object": {
				Type:        schema.TypeList,
				Optional:    true,
				ForceNew:    true,
				Description: `allows batch operations to delete objects in bucket`,
				MaxItems:    1,
				Elem: &schema.Resource{
					Schema: map[string]*schema.Schema{
						"permanent_object_deletion_enabled": {
							Type:        schema.TypeBool,
							Required:    true,
							ForceNew:    true,
							Description: `enable flag to permanently delete object and all object versions if versioning is enabled on bucket.`,
						},
					},
				},
				ExactlyOneOf: []string{"delete_object", "put_metadata", "rewrite_object", "put_object_hold"},
			},
			"job_id": {
				Type:         schema.TypeString,
				Optional:     true,
				ForceNew:     true,
				ValidateFunc: verify.ValidateRegexp(`^[a-z0-9]([-a-z0-9]*[a-z0-9])?.$`),
				Description:  `The ID of the job.`,
			},
			"put_metadata": {
				Type:        schema.TypeList,
				Optional:    true,
				ForceNew:    true,
				Description: `allows batch operations to update metadata for objects in bucket`,
				MaxItems:    1,
				Elem: &schema.Resource{
					Schema: map[string]*schema.Schema{
						"cache_control": {
							Type:         schema.TypeString,
							Optional:     true,
							ForceNew:     true,
							Description:  `Cache-Control directive to specify caching behavior of object data. If omitted and object is accessible to all anonymous users, the default will be public, max-age=3600`,
							AtLeastOneOf: []string{"put_metadata.0.content_disposition", "put_metadata.0.content_encoding", "put_metadata.0.content_language", "put_metadata.0.content_type", "put_metadata.0.cache_control", "put_metadata.0.custom_metadata", "put_metadata.0.custom_time"},
						},
						"content_disposition": {
							Type:         schema.TypeString,
							Optional:     true,
							ForceNew:     true,
							Description:  `Content-Disposition of the object data.`,
							AtLeastOneOf: []string{"put_metadata.0.content_disposition", "put_metadata.0.content_encoding", "put_metadata.0.content_language", "put_metadata.0.content_type", "put_metadata.0.cache_control", "put_metadata.0.custom_metadata", "put_metadata.0.custom_time"},
						},
						"content_encoding": {
							Type:         schema.TypeString,
							Optional:     true,
							ForceNew:     true,
							Description:  `Content Encoding of the object data.`,
							AtLeastOneOf: []string{"put_metadata.0.content_disposition", "put_metadata.0.content_encoding", "put_metadata.0.content_language", "put_metadata.0.content_type", "put_metadata.0.cache_control", "put_metadata.0.custom_metadata", "put_metadata.0.custom_time"},
						},
						"content_language": {
							Type:         schema.TypeString,
							Optional:     true,
							ForceNew:     true,
							Description:  `Content-Language of the object data.`,
							AtLeastOneOf: []string{"put_metadata.0.content_disposition", "put_metadata.0.content_encoding", "put_metadata.0.content_language", "put_metadata.0.content_type", "put_metadata.0.cache_control", "put_metadata.0.custom_metadata", "put_metadata.0.custom_time"},
						},
						"content_type": {
							Type:         schema.TypeString,
							Optional:     true,
							ForceNew:     true,
							Description:  `Content-Type of the object data.`,
							AtLeastOneOf: []string{"put_metadata.0.content_disposition", "put_metadata.0.content_encoding", "put_metadata.0.content_language", "put_metadata.0.content_type", "put_metadata.0.cache_control", "put_metadata.0.custom_metadata", "put_metadata.0.custom_time"},
						},
						"custom_metadata": {
							Type:         schema.TypeMap,
							Optional:     true,
							ForceNew:     true,
							Description:  `User-provided metadata, in key/value pairs.`,
							Elem:         &schema.Schema{Type: schema.TypeString},
							AtLeastOneOf: []string{"put_metadata.0.content_disposition", "put_metadata.0.content_encoding", "put_metadata.0.content_language", "put_metadata.0.content_type", "put_metadata.0.cache_control", "put_metadata.0.custom_metadata", "put_metadata.0.custom_time"},
						},
						"custom_time": {
							Type:         schema.TypeString,
							Optional:     true,
							ForceNew:     true,
							Description:  `Updates the objects fixed custom time metadata.`,
							AtLeastOneOf: []string{"put_metadata.0.content_disposition", "put_metadata.0.content_encoding", "put_metadata.0.content_language", "put_metadata.0.content_type", "put_metadata.0.cache_control", "put_metadata.0.custom_metadata", "put_metadata.0.custom_time"},
						},
					},
				},
				ExactlyOneOf: []string{"delete_object", "put_metadata", "rewrite_object", "put_object_hold"},
			},
			"put_object_hold": {
				Type:        schema.TypeList,
				Optional:    true,
				ForceNew:    true,
				Description: `allows to update temporary hold or eventBased hold for objects in bucket.`,
				MaxItems:    1,
				Elem: &schema.Resource{
					Schema: map[string]*schema.Schema{
						"event_based_hold": {
							Type:         schema.TypeString,
							Optional:     true,
							ForceNew:     true,
							ValidateFunc: validation.StringInSlice([]string{"SET", "UNSET"}, false),
							Description:  `set/unset to update event based hold for objects.`,
						},
						"temporary_hold": {
							Type:         schema.TypeString,
							Optional:     true,
							ForceNew:     true,
							ValidateFunc: validation.StringInSlice([]string{"SET", "UNSET"}, false),
							Description:  `set/unset to update temporary based hold for objects.`,
						},
					},
				},
				ExactlyOneOf: []string{"delete_object", "put_metadata", "rewrite_object", "put_object_hold"},
			},
			"rewrite_object": {
				Type:        schema.TypeList,
				Optional:    true,
				ForceNew:    true,
				Description: `allows to update encryption key for objects in bucket.`,
				MaxItems:    1,
				Elem: &schema.Resource{
					Schema: map[string]*schema.Schema{
						"kms_key": {
							Type:        schema.TypeString,
							Required:    true,
							ForceNew:    true,
							Description: `valid kms key`,
						},
					},
				},
				ExactlyOneOf: []string{"delete_object", "put_metadata", "rewrite_object", "put_object_hold"},
			},
			"complete_time": {
				Type:        schema.TypeString,
				Computed:    true,
				Description: `The time that the job was completed.`,
			},
			"create_time": {
				Type:        schema.TypeString,
				Computed:    true,
				Description: `The timestamp at which this storage batch operation was created.`,
			},
			"schedule_time": {
				Type:        schema.TypeString,
				Computed:    true,
				Description: `The time that the job was scheduled.`,
			},
			"state": {
				Type:        schema.TypeString,
				Computed:    true,
				Description: `State of the job.`,
			},
			"update_time": {
				Type:        schema.TypeString,
				Computed:    true,
				Description: `The timestamp at which this storage batch operation was most recently updated.`,
			},
			"delete_protection": {
				Type:        schema.TypeBool,
				Optional:    true,
				Description: `If set to 'true', the storage batch operation job will not be deleted and new job will be created.`,
				Default:     true,
			},
			"project": {
				Type:     schema.TypeString,
				Optional: true,
				Computed: true,
				ForceNew: true,
			},
		},
		UseJSONNumber: true,
	}
}

func resourceStorageBatchOperationsJobCreate(d *schema.ResourceData, meta interface{}) error {
	config := meta.(*transport_tpg.Config)
	userAgent, err := tpgresource.GenerateUserAgentString(d, config.UserAgent)
	if err != nil {
		return err
	}

	obj := make(map[string]interface{})
	bucketListProp, err := expandStorageBatchOperationsJobBucketList(d.Get("bucket_list"), d, config)
	if err != nil {
		return err
	} else if v, ok := d.GetOkExists("bucket_list"); !tpgresource.IsEmptyValue(reflect.ValueOf(bucketListProp)) && (ok || !reflect.DeepEqual(v, bucketListProp)) {
		obj["bucketList"] = bucketListProp
	}
	deleteObjectProp, err := expandStorageBatchOperationsJobDeleteObject(d.Get("delete_object"), d, config)
	if err != nil {
		return err
	} else if v, ok := d.GetOkExists("delete_object"); !tpgresource.IsEmptyValue(reflect.ValueOf(deleteObjectProp)) && (ok || !reflect.DeepEqual(v, deleteObjectProp)) {
		obj["deleteObject"] = deleteObjectProp
	}
	putMetadataProp, err := expandStorageBatchOperationsJobPutMetadata(d.Get("put_metadata"), d, config)
	if err != nil {
		return err
	} else if v, ok := d.GetOkExists("put_metadata"); !tpgresource.IsEmptyValue(reflect.ValueOf(putMetadataProp)) && (ok || !reflect.DeepEqual(v, putMetadataProp)) {
		obj["putMetadata"] = putMetadataProp
	}
	rewriteObjectProp, err := expandStorageBatchOperationsJobRewriteObject(d.Get("rewrite_object"), d, config)
	if err != nil {
		return err
	} else if v, ok := d.GetOkExists("rewrite_object"); !tpgresource.IsEmptyValue(reflect.ValueOf(rewriteObjectProp)) && (ok || !reflect.DeepEqual(v, rewriteObjectProp)) {
		obj["rewriteObject"] = rewriteObjectProp
	}
	putObjectHoldProp, err := expandStorageBatchOperationsJobPutObjectHold(d.Get("put_object_hold"), d, config)
	if err != nil {
		return err
	} else if v, ok := d.GetOkExists("put_object_hold"); !tpgresource.IsEmptyValue(reflect.ValueOf(putObjectHoldProp)) && (ok || !reflect.DeepEqual(v, putObjectHoldProp)) {
		obj["putObjectHold"] = putObjectHoldProp
	}

	url, err := tpgresource.ReplaceVars(d, config, "{{StorageBatchOperationsBasePath}}projects/{{project}}/locations/global/jobs?jobId={{job_id}}")
	if err != nil {
		return err
	}

	log.Printf("[DEBUG] Creating new Job: %#v", obj)
	billingProject := ""

	project, err := tpgresource.GetProject(d, config)
	if err != nil {
		return fmt.Errorf("Error fetching project for Job: %s", err)
	}
	billingProject = project

	// err == nil indicates that the billing_project value was found
	if bp, err := tpgresource.GetBillingProject(d, config); err == nil {
		billingProject = bp
	}

	headers := make(http.Header)
	res, err := transport_tpg.SendRequest(transport_tpg.SendRequestOptions{
		Config:    config,
		Method:    "POST",
		Project:   billingProject,
		RawURL:    url,
		UserAgent: userAgent,
		Body:      obj,
		Timeout:   d.Timeout(schema.TimeoutCreate),
		Headers:   headers,
	})
	if err != nil {
		return fmt.Errorf("Error creating Job: %s", err)
	}

	// Store the ID now
	id, err := tpgresource.ReplaceVars(d, config, "projects/{{project}}/locations/global/jobs/{{job_id}}")
	if err != nil {
		return fmt.Errorf("Error constructing id: %s", err)
	}
	d.SetId(id)

	err = StorageBatchOperationsOperationWaitTime(
		config, res, project, "Creating Job", userAgent,
		d.Timeout(schema.TimeoutCreate))

	if err != nil {
		// The resource didn't actually create
		d.SetId("")
		return fmt.Errorf("Error waiting to create Job: %s", err)
	}

	log.Printf("[DEBUG] Finished creating Job %q: %#v", d.Id(), res)

	return resourceStorageBatchOperationsJobRead(d, meta)
}

func resourceStorageBatchOperationsJobRead(d *schema.ResourceData, meta interface{}) error {
	config := meta.(*transport_tpg.Config)
	userAgent, err := tpgresource.GenerateUserAgentString(d, config.UserAgent)
	if err != nil {
		return err
	}

	url, err := tpgresource.ReplaceVars(d, config, "{{StorageBatchOperationsBasePath}}projects/{{project}}/locations/global/jobs/{{job_id}}")
	if err != nil {
		return err
	}

	billingProject := ""

	project, err := tpgresource.GetProject(d, config)
	if err != nil {
		return fmt.Errorf("Error fetching project for Job: %s", err)
	}
	billingProject = project

	// err == nil indicates that the billing_project value was found
	if bp, err := tpgresource.GetBillingProject(d, config); err == nil {
		billingProject = bp
	}

	headers := make(http.Header)
	res, err := transport_tpg.SendRequest(transport_tpg.SendRequestOptions{
		Config:    config,
		Method:    "GET",
		Project:   billingProject,
		RawURL:    url,
		UserAgent: userAgent,
		Headers:   headers,
	})
	if err != nil {
		return transport_tpg.HandleNotFoundError(err, d, fmt.Sprintf("StorageBatchOperationsJob %q", d.Id()))
	}

	// Explicitly set virtual fields to default values if unset
	if _, ok := d.GetOkExists("delete_protection"); !ok {
		if err := d.Set("delete_protection", true); err != nil {
			return fmt.Errorf("Error setting delete_protection: %s", err)
		}
	}
	if err := d.Set("project", project); err != nil {
		return fmt.Errorf("Error reading Job: %s", err)
	}

	if err := d.Set("create_time", flattenStorageBatchOperationsJobCreateTime(res["createTime"], d, config)); err != nil {
		return fmt.Errorf("Error reading Job: %s", err)
	}
	if err := d.Set("update_time", flattenStorageBatchOperationsJobUpdateTime(res["updateTime"], d, config)); err != nil {
		return fmt.Errorf("Error reading Job: %s", err)
	}
	if err := d.Set("schedule_time", flattenStorageBatchOperationsJobScheduleTime(res["scheduleTime"], d, config)); err != nil {
		return fmt.Errorf("Error reading Job: %s", err)
	}
	if err := d.Set("complete_time", flattenStorageBatchOperationsJobCompleteTime(res["completeTime"], d, config)); err != nil {
		return fmt.Errorf("Error reading Job: %s", err)
	}
	if err := d.Set("state", flattenStorageBatchOperationsJobState(res["state"], d, config)); err != nil {
		return fmt.Errorf("Error reading Job: %s", err)
	}
	if err := d.Set("bucket_list", flattenStorageBatchOperationsJobBucketList(res["bucketList"], d, config)); err != nil {
		return fmt.Errorf("Error reading Job: %s", err)
	}
	if err := d.Set("delete_object", flattenStorageBatchOperationsJobDeleteObject(res["deleteObject"], d, config)); err != nil {
		return fmt.Errorf("Error reading Job: %s", err)
	}
	if err := d.Set("put_metadata", flattenStorageBatchOperationsJobPutMetadata(res["putMetadata"], d, config)); err != nil {
		return fmt.Errorf("Error reading Job: %s", err)
	}
	if err := d.Set("rewrite_object", flattenStorageBatchOperationsJobRewriteObject(res["rewriteObject"], d, config)); err != nil {
		return fmt.Errorf("Error reading Job: %s", err)
	}
	if err := d.Set("put_object_hold", flattenStorageBatchOperationsJobPutObjectHold(res["putObjectHold"], d, config)); err != nil {
		return fmt.Errorf("Error reading Job: %s", err)
	}

	return nil
}

func resourceStorageBatchOperationsJobUpdate(d *schema.ResourceData, meta interface{}) error {
	config := meta.(*transport_tpg.Config)
	_ = config
	// we can only get here if delete_protection was updated
	if d.Get("delete_protection") != nil {
		if err := d.Set("delete_protection", d.Get("delete_protection")); err != nil {
			return fmt.Errorf("Error updating delete_protection: %s", err)
		}
	}

	// all other fields are immutable, don't do anything else
	return nil
}

func resourceStorageBatchOperationsJobDelete(d *schema.ResourceData, meta interface{}) error {
	config := meta.(*transport_tpg.Config)
	userAgent, err := tpgresource.GenerateUserAgentString(d, config.UserAgent)
	if err != nil {
		return err
	}

	billingProject := ""

	project, err := tpgresource.GetProject(d, config)
	if err != nil {
		return fmt.Errorf("Error fetching project for Job: %s", err)
	}
	billingProject = project

	url, err := tpgresource.ReplaceVars(d, config, "{{StorageBatchOperationsBasePath}}projects/{{project}}/locations/global/jobs/{{job_id}}")
	if err != nil {
		return err
	}

	var obj map[string]interface{}

	// err == nil indicates that the billing_project value was found
	if bp, err := tpgresource.GetBillingProject(d, config); err == nil {
		billingProject = bp
	}

	headers := make(http.Header)
	if d.Get("delete_protection").(bool) {
		return fmt.Errorf("[ERROR] delete_protection set to true, existing resource on cloud will not be deleted")
	}

	log.Printf("[DEBUG] Deleting Job %q", d.Id())
	res, err := transport_tpg.SendRequest(transport_tpg.SendRequestOptions{
		Config:    config,
		Method:    "DELETE",
		Project:   billingProject,
		RawURL:    url,
		UserAgent: userAgent,
		Body:      obj,
		Timeout:   d.Timeout(schema.TimeoutDelete),
		Headers:   headers,
	})
	if err != nil {
		return transport_tpg.HandleNotFoundError(err, d, "Job")
	}

	log.Printf("[DEBUG] Finished deleting Job %q: %#v", d.Id(), res)
	return nil
}

func resourceStorageBatchOperationsJobImport(d *schema.ResourceData, meta interface{}) ([]*schema.ResourceData, error) {
	config := meta.(*transport_tpg.Config)
	if err := tpgresource.ParseImportId([]string{
		"^projects/(?P<project>[^/]+)/locations/global/jobs/(?P<job_id>[^/]+)$",
		"^(?P<project>[^/]+)/(?P<job_id>[^/]+)$",
		"^(?P<job_id>[^/]+)$",
	}, d, config); err != nil {
		return nil, err
	}

	// Replace import id for the resource id
	id, err := tpgresource.ReplaceVars(d, config, "projects/{{project}}/locations/global/jobs/{{job_id}}")
	if err != nil {
		return nil, fmt.Errorf("Error constructing id: %s", err)
	}
	d.SetId(id)

	// Explicitly set virtual fields to default values on import
	if err := d.Set("delete_protection", true); err != nil {
		return nil, fmt.Errorf("Error setting delete_protection: %s", err)
	}

	return []*schema.ResourceData{d}, nil
}

func flattenStorageBatchOperationsJobCreateTime(v interface{}, d *schema.ResourceData, config *transport_tpg.Config) interface{} {
	return v
}

func flattenStorageBatchOperationsJobUpdateTime(v interface{}, d *schema.ResourceData, config *transport_tpg.Config) interface{} {
	return v
}

func flattenStorageBatchOperationsJobScheduleTime(v interface{}, d *schema.ResourceData, config *transport_tpg.Config) interface{} {
	return v
}

func flattenStorageBatchOperationsJobCompleteTime(v interface{}, d *schema.ResourceData, config *transport_tpg.Config) interface{} {
	return v
}

func flattenStorageBatchOperationsJobState(v interface{}, d *schema.ResourceData, config *transport_tpg.Config) interface{} {
	return v
}

func flattenStorageBatchOperationsJobBucketList(v interface{}, d *schema.ResourceData, config *transport_tpg.Config) interface{} {
	if v == nil {
		return nil
	}
	original := v.(map[string]interface{})
	if len(original) == 0 {
		return nil
	}
	transformed := make(map[string]interface{})
	transformed["buckets"] =
		flattenStorageBatchOperationsJobBucketListBuckets(original["buckets"], d, config)
	return []interface{}{transformed}
}
func flattenStorageBatchOperationsJobBucketListBuckets(v interface{}, d *schema.ResourceData, config *transport_tpg.Config) interface{} {
	if v == nil {
		return v
	}
	l := v.([]interface{})
	transformed := make([]interface{}, 0, len(l))
	for _, raw := range l {
		original := raw.(map[string]interface{})
		if len(original) < 1 {
			// Do not include empty json objects coming back from the api
			continue
		}
		transformed = append(transformed, map[string]interface{}{
			"bucket":      flattenStorageBatchOperationsJobBucketListBucketsBucket(original["bucket"], d, config),
			"prefix_list": flattenStorageBatchOperationsJobBucketListBucketsPrefixList(original["prefixList"], d, config),
			"manifest":    flattenStorageBatchOperationsJobBucketListBucketsManifest(original["manifest"], d, config),
		})
	}
	return transformed
}
func flattenStorageBatchOperationsJobBucketListBucketsBucket(v interface{}, d *schema.ResourceData, config *transport_tpg.Config) interface{} {
	return v
}

func flattenStorageBatchOperationsJobBucketListBucketsPrefixList(v interface{}, d *schema.ResourceData, config *transport_tpg.Config) interface{} {
	if v == nil {
		return nil
	}
	original := v.(map[string]interface{})
	if len(original) == 0 {
		return nil
	}
	transformed := make(map[string]interface{})
	transformed["included_object_prefixes"] =
		flattenStorageBatchOperationsJobBucketListBucketsPrefixListIncludedObjectPrefixes(original["includedObjectPrefixes"], d, config)
	return []interface{}{transformed}
}
func flattenStorageBatchOperationsJobBucketListBucketsPrefixListIncludedObjectPrefixes(v interface{}, d *schema.ResourceData, config *transport_tpg.Config) interface{} {
	return v
}

func flattenStorageBatchOperationsJobBucketListBucketsManifest(v interface{}, d *schema.ResourceData, config *transport_tpg.Config) interface{} {
	if v == nil {
		return nil
	}
	original := v.(map[string]interface{})
	if len(original) == 0 {
		return nil
	}
	transformed := make(map[string]interface{})
	transformed["manifest_location"] =
		flattenStorageBatchOperationsJobBucketListBucketsManifestManifestLocation(original["manifestLocation"], d, config)
	return []interface{}{transformed}
}
func flattenStorageBatchOperationsJobBucketListBucketsManifestManifestLocation(v interface{}, d *schema.ResourceData, config *transport_tpg.Config) interface{} {
	return v
}

func flattenStorageBatchOperationsJobDeleteObject(v interface{}, d *schema.ResourceData, config *transport_tpg.Config) interface{} {
	if v == nil {
		return nil
	}
	original := v.(map[string]interface{})
	transformed := make(map[string]interface{})
	if len(original) == 0 {
		transformed["permanent_object_deletion_enabled"] = false
		return []interface{}{transformed}
	}
	transformed["permanent_object_deletion_enabled"] =
		flattenStorageBatchOperationsJobsDeleteObjectPermanentObjectDeletionEnabled(original["permanentObjectDeletionEnabled"], d, config)
	return []interface{}{transformed}
}
func flattenStorageBatchOperationsJobsDeleteObjectPermanentObjectDeletionEnabled(v interface{}, d *schema.ResourceData, config *transport_tpg.Config) interface{} {
	return v
}

func flattenStorageBatchOperationsJobPutMetadata(v interface{}, d *schema.ResourceData, config *transport_tpg.Config) interface{} {
	if v == nil {
		return nil
	}
	original := v.(map[string]interface{})
	if len(original) == 0 {
		return nil
	}
	transformed := make(map[string]interface{})
	transformed["custom_time"] =
		flattenStorageBatchOperationsJobPutMetadataCustomTime(original["customTime"], d, config)
	transformed["content_disposition"] =
		flattenStorageBatchOperationsJobPutMetadataContentDisposition(original["contentDisposition"], d, config)
	transformed["content_encoding"] =
		flattenStorageBatchOperationsJobPutMetadataContentEncoding(original["contentEncoding"], d, config)
	transformed["content_type"] =
		flattenStorageBatchOperationsJobPutMetadataContentType(original["contentType"], d, config)
	transformed["content_language"] =
		flattenStorageBatchOperationsJobPutMetadataContentLanguage(original["contentLanguage"], d, config)
	transformed["cache_control"] =
		flattenStorageBatchOperationsJobPutMetadataCacheControl(original["cacheControl"], d, config)
	transformed["custom_metadata"] =
		flattenStorageBatchOperationsJobPutMetadataCustomMetadata(original["customMetadata"], d, config)
	return []interface{}{transformed}
}
func flattenStorageBatchOperationsJobPutMetadataCustomTime(v interface{}, d *schema.ResourceData, config *transport_tpg.Config) interface{} {
	return v
}

func flattenStorageBatchOperationsJobPutMetadataContentDisposition(v interface{}, d *schema.ResourceData, config *transport_tpg.Config) interface{} {
	return v
}

func flattenStorageBatchOperationsJobPutMetadataContentEncoding(v interface{}, d *schema.ResourceData, config *transport_tpg.Config) interface{} {
	return v
}

func flattenStorageBatchOperationsJobPutMetadataContentType(v interface{}, d *schema.ResourceData, config *transport_tpg.Config) interface{} {
	return v
}

func flattenStorageBatchOperationsJobPutMetadataContentLanguage(v interface{}, d *schema.ResourceData, config *transport_tpg.Config) interface{} {
	return v
}

func flattenStorageBatchOperationsJobPutMetadataCacheControl(v interface{}, d *schema.ResourceData, config *transport_tpg.Config) interface{} {
	return v
}

func flattenStorageBatchOperationsJobPutMetadataCustomMetadata(v interface{}, d *schema.ResourceData, config *transport_tpg.Config) interface{} {
	return v
}

func flattenStorageBatchOperationsJobRewriteObject(v interface{}, d *schema.ResourceData, config *transport_tpg.Config) interface{} {
	if v == nil {
		return nil
	}
	original := v.(map[string]interface{})
	if len(original) == 0 {
		return nil
	}
	transformed := make(map[string]interface{})
	transformed["kms_key"] =
		flattenStorageBatchOperationsJobRewriteObjectKmsKey(original["kmsKey"], d, config)
	return []interface{}{transformed}
}
func flattenStorageBatchOperationsJobRewriteObjectKmsKey(v interface{}, d *schema.ResourceData, config *transport_tpg.Config) interface{} {
	return v
}

func flattenStorageBatchOperationsJobPutObjectHold(v interface{}, d *schema.ResourceData, config *transport_tpg.Config) interface{} {
	if v == nil {
		return nil
	}
	original := v.(map[string]interface{})
	if len(original) == 0 {
		return nil
	}
	transformed := make(map[string]interface{})
	transformed["event_based_hold"] =
		flattenStorageBatchOperationsJobPutObjectHoldEventBasedHold(original["eventBasedHold"], d, config)
	transformed["temporary_hold"] =
		flattenStorageBatchOperationsJobPutObjectHoldTemporaryHold(original["temporaryHold"], d, config)
	return []interface{}{transformed}
}
func flattenStorageBatchOperationsJobPutObjectHoldEventBasedHold(v interface{}, d *schema.ResourceData, config *transport_tpg.Config) interface{} {
	return v
}

func flattenStorageBatchOperationsJobPutObjectHoldTemporaryHold(v interface{}, d *schema.ResourceData, config *transport_tpg.Config) interface{} {
	return v
}

func expandStorageBatchOperationsJobBucketList(v interface{}, d tpgresource.TerraformResourceData, config *transport_tpg.Config) (interface{}, error) {
	l := v.([]interface{})
	if len(l) == 0 || l[0] == nil {
		return nil, nil
	}
	raw := l[0]
	original := raw.(map[string]interface{})
	transformed := make(map[string]interface{})

	transformedBuckets, err := expandStorageBatchOperationsJobBucketListBuckets(original["buckets"], d, config)
	if err != nil {
		return nil, err
	} else if val := reflect.ValueOf(transformedBuckets); val.IsValid() && !tpgresource.IsEmptyValue(val) {
		transformed["buckets"] = transformedBuckets
	}

	return transformed, nil
}

func expandStorageBatchOperationsJobBucketListBuckets(v interface{}, d tpgresource.TerraformResourceData, config *transport_tpg.Config) (interface{}, error) {
	l := v.([]interface{})
	req := make([]interface{}, 0, len(l))
	for _, raw := range l {
		if raw == nil {
			continue
		}
		original := raw.(map[string]interface{})
		transformed := make(map[string]interface{})

		transformedBucket, err := expandStorageBatchOperationsJobBucketListBucketsBucket(original["bucket"], d, config)
		if err != nil {
			return nil, err
		} else if val := reflect.ValueOf(transformedBucket); val.IsValid() && !tpgresource.IsEmptyValue(val) {
			transformed["bucket"] = transformedBucket
		}

		transformedPrefixList, err := expandStorageBatchOperationsJobBucketListBucketsPrefixList(original["prefix_list"], d, config)
		if err != nil {
			return nil, err
		} else if val := reflect.ValueOf(transformedPrefixList); val.IsValid() && !tpgresource.IsEmptyValue(val) {
			transformed["prefixList"] = transformedPrefixList
		}

		transformedManifest, err := expandStorageBatchOperationsJobBucketListBucketsManifest(original["manifest"], d, config)
		if err != nil {
			return nil, err
		} else if val := reflect.ValueOf(transformedManifest); val.IsValid() && !tpgresource.IsEmptyValue(val) {
			transformed["manifest"] = transformedManifest
		}

		req = append(req, transformed)
	}
	return req, nil
}

func expandStorageBatchOperationsJobBucketListBucketsBucket(v interface{}, d tpgresource.TerraformResourceData, config *transport_tpg.Config) (interface{}, error) {
	return v, nil
}

func expandStorageBatchOperationsJobBucketListBucketsPrefixList(v interface{}, d tpgresource.TerraformResourceData, config *transport_tpg.Config) (interface{}, error) {
	l := v.([]interface{})
	if len(l) == 0 || l[0] == nil {
		return nil, nil
	}
	raw := l[0]
	original := raw.(map[string]interface{})
	transformed := make(map[string]interface{})

	transformedIncludedObjectPrefixes, err := expandStorageBatchOperationsJobBucketListBucketsPrefixListIncludedObjectPrefixes(original["included_object_prefixes"], d, config)
	if err != nil {
		return nil, err
	} else if val := reflect.ValueOf(transformedIncludedObjectPrefixes); val.IsValid() && !tpgresource.IsEmptyValue(val) {
		transformed["includedObjectPrefixes"] = transformedIncludedObjectPrefixes
	}

	return transformed, nil
}

func expandStorageBatchOperationsJobBucketListBucketsPrefixListIncludedObjectPrefixes(v interface{}, d tpgresource.TerraformResourceData, config *transport_tpg.Config) (interface{}, error) {
	return v, nil
}

func expandStorageBatchOperationsJobBucketListBucketsManifest(v interface{}, d tpgresource.TerraformResourceData, config *transport_tpg.Config) (interface{}, error) {
	l := v.([]interface{})
	if len(l) == 0 || l[0] == nil {
		return nil, nil
	}
	raw := l[0]
	original := raw.(map[string]interface{})
	transformed := make(map[string]interface{})

	transformedManifestLocation, err := expandStorageBatchOperationsJobBucketListBucketsManifestManifestLocation(original["manifest_location"], d, config)
	if err != nil {
		return nil, err
	} else if val := reflect.ValueOf(transformedManifestLocation); val.IsValid() && !tpgresource.IsEmptyValue(val) {
		transformed["manifestLocation"] = transformedManifestLocation
	}

	return transformed, nil
}

func expandStorageBatchOperationsJobBucketListBucketsManifestManifestLocation(v interface{}, d tpgresource.TerraformResourceData, config *transport_tpg.Config) (interface{}, error) {
	return v, nil
}

func expandStorageBatchOperationsJobDeleteObject(v interface{}, d tpgresource.TerraformResourceData, config *transport_tpg.Config) (interface{}, error) {
	l := v.([]interface{})
	if len(l) == 0 || l[0] == nil {
		return nil, nil
	}
	raw := l[0]
	original := raw.(map[string]interface{})
	transformed := make(map[string]interface{})

	transformedPermanentObjectDeletionEnabled, err := expandStorageBatchOperationsJobDeleteObjectPermanentObjectDeletionEnabled(original["permanent_object_deletion_enabled"], d, config)
	if err != nil {
		return nil, err
	} else {
		transformed["permanentObjectDeletionEnabled"] = transformedPermanentObjectDeletionEnabled
	}

	return transformed, nil
}

func expandStorageBatchOperationsJobDeleteObjectPermanentObjectDeletionEnabled(v interface{}, d tpgresource.TerraformResourceData, config *transport_tpg.Config) (interface{}, error) {
	return v, nil
}

func expandStorageBatchOperationsJobPutMetadata(v interface{}, d tpgresource.TerraformResourceData, config *transport_tpg.Config) (interface{}, error) {
	l := v.([]interface{})
	if len(l) == 0 || l[0] == nil {
		return nil, nil
	}
	raw := l[0]
	original := raw.(map[string]interface{})
	transformed := make(map[string]interface{})

	transformedCustomTime, err := expandStorageBatchOperationsJobPutMetadataCustomTime(original["custom_time"], d, config)
	if err != nil {
		return nil, err
	} else if val := reflect.ValueOf(transformedCustomTime); val.IsValid() && !tpgresource.IsEmptyValue(val) {
		transformed["customTime"] = transformedCustomTime
	}

	transformedContentDisposition, err := expandStorageBatchOperationsJobPutMetadataContentDisposition(original["content_disposition"], d, config)
	if err != nil {
		return nil, err
	} else if val := reflect.ValueOf(transformedContentDisposition); val.IsValid() && !tpgresource.IsEmptyValue(val) {
		transformed["contentDisposition"] = transformedContentDisposition
	}

	transformedContentEncoding, err := expandStorageBatchOperationsJobPutMetadataContentEncoding(original["content_encoding"], d, config)
	if err != nil {
		return nil, err
	} else if val := reflect.ValueOf(transformedContentEncoding); val.IsValid() && !tpgresource.IsEmptyValue(val) {
		transformed["contentEncoding"] = transformedContentEncoding
	}

	transformedContentType, err := expandStorageBatchOperationsJobPutMetadataContentType(original["content_type"], d, config)
	if err != nil {
		return nil, err
	} else if val := reflect.ValueOf(transformedContentType); val.IsValid() && !tpgresource.IsEmptyValue(val) {
		transformed["contentType"] = transformedContentType
	}

	transformedContentLanguage, err := expandStorageBatchOperationsJobPutMetadataContentLanguage(original["content_language"], d, config)
	if err != nil {
		return nil, err
	} else if val := reflect.ValueOf(transformedContentLanguage); val.IsValid() && !tpgresource.IsEmptyValue(val) {
		transformed["contentLanguage"] = transformedContentLanguage
	}

	transformedCacheControl, err := expandStorageBatchOperationsJobPutMetadataCacheControl(original["cache_control"], d, config)
	if err != nil {
		return nil, err
	} else if val := reflect.ValueOf(transformedCacheControl); val.IsValid() && !tpgresource.IsEmptyValue(val) {
		transformed["cacheControl"] = transformedCacheControl
	}

	transformedCustomMetadata, err := expandStorageBatchOperationsJobPutMetadataCustomMetadata(original["custom_metadata"], d, config)
	if err != nil {
		return nil, err
	} else if val := reflect.ValueOf(transformedCustomMetadata); val.IsValid() && !tpgresource.IsEmptyValue(val) {
		transformed["customMetadata"] = transformedCustomMetadata
	}

	return transformed, nil
}

func expandStorageBatchOperationsJobPutMetadataCustomTime(v interface{}, d tpgresource.TerraformResourceData, config *transport_tpg.Config) (interface{}, error) {
	return v, nil
}

func expandStorageBatchOperationsJobPutMetadataContentDisposition(v interface{}, d tpgresource.TerraformResourceData, config *transport_tpg.Config) (interface{}, error) {
	return v, nil
}

func expandStorageBatchOperationsJobPutMetadataContentEncoding(v interface{}, d tpgresource.TerraformResourceData, config *transport_tpg.Config) (interface{}, error) {
	return v, nil
}

func expandStorageBatchOperationsJobPutMetadataContentType(v interface{}, d tpgresource.TerraformResourceData, config *transport_tpg.Config) (interface{}, error) {
	return v, nil
}

func expandStorageBatchOperationsJobPutMetadataContentLanguage(v interface{}, d tpgresource.TerraformResourceData, config *transport_tpg.Config) (interface{}, error) {
	return v, nil
}

func expandStorageBatchOperationsJobPutMetadataCacheControl(v interface{}, d tpgresource.TerraformResourceData, config *transport_tpg.Config) (interface{}, error) {
	return v, nil
}

func expandStorageBatchOperationsJobPutMetadataCustomMetadata(v interface{}, d tpgresource.TerraformResourceData, config *transport_tpg.Config) (map[string]string, error) {
	if v == nil {
		return map[string]string{}, nil
	}
	m := make(map[string]string)
	for k, val := range v.(map[string]interface{}) {
		m[k] = val.(string)
	}
	return m, nil
}

func expandStorageBatchOperationsJobRewriteObject(v interface{}, d tpgresource.TerraformResourceData, config *transport_tpg.Config) (interface{}, error) {
	l := v.([]interface{})
	if len(l) == 0 || l[0] == nil {
		return nil, nil
	}
	raw := l[0]
	original := raw.(map[string]interface{})
	transformed := make(map[string]interface{})

	transformedKmsKey, err := expandStorageBatchOperationsJobRewriteObjectKmsKey(original["kms_key"], d, config)
	if err != nil {
		return nil, err
	} else if val := reflect.ValueOf(transformedKmsKey); val.IsValid() && !tpgresource.IsEmptyValue(val) {
		transformed["kmsKey"] = transformedKmsKey
	}

	return transformed, nil
}

func expandStorageBatchOperationsJobRewriteObjectKmsKey(v interface{}, d tpgresource.TerraformResourceData, config *transport_tpg.Config) (interface{}, error) {
	return v, nil
}

func expandStorageBatchOperationsJobPutObjectHold(v interface{}, d tpgresource.TerraformResourceData, config *transport_tpg.Config) (interface{}, error) {
	l := v.([]interface{})
	if len(l) == 0 || l[0] == nil {
		return nil, nil
	}
	raw := l[0]
	original := raw.(map[string]interface{})
	transformed := make(map[string]interface{})

	transformedEventBasedHold, err := expandStorageBatchOperationsJobPutObjectHoldEventBasedHold(original["event_based_hold"], d, config)
	if err != nil {
		return nil, err
	} else if val := reflect.ValueOf(transformedEventBasedHold); val.IsValid() && !tpgresource.IsEmptyValue(val) {
		transformed["eventBasedHold"] = transformedEventBasedHold
	}

	transformedTemporaryHold, err := expandStorageBatchOperationsJobPutObjectHoldTemporaryHold(original["temporary_hold"], d, config)
	if err != nil {
		return nil, err
	} else if val := reflect.ValueOf(transformedTemporaryHold); val.IsValid() && !tpgresource.IsEmptyValue(val) {
		transformed["temporaryHold"] = transformedTemporaryHold
	}

	return transformed, nil
}

func expandStorageBatchOperationsJobPutObjectHoldEventBasedHold(v interface{}, d tpgresource.TerraformResourceData, config *transport_tpg.Config) (interface{}, error) {
	return v, nil
}

func expandStorageBatchOperationsJobPutObjectHoldTemporaryHold(v interface{}, d tpgresource.TerraformResourceData, config *transport_tpg.Config) (interface{}, error) {
	return v, nil
}
