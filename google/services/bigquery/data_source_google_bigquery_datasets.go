// Copyright (c) HashiCorp, Inc.
// SPDX-License-Identifier: MPL-2.0
// ----------------------------------------------------------------------------
//
//	***     AUTO GENERATED CODE    ***    Type: Handwritten     ***
//
// ----------------------------------------------------------------------------
//
//	This code is generated by Magic Modules using the following:
//
//	Source file: https://github.com/GoogleCloudPlatform/magic-modules/tree/main/mmv1/third_party/terraform/services/bigquery/data_source_google_bigquery_datasets.go
//
//	DO NOT EDIT this file directly. Any changes made to this file will be
//	overwritten during the next generation cycle.
//
// ----------------------------------------------------------------------------
package bigquery

import (
	"fmt"

	"github.com/hashicorp/terraform-plugin-sdk/v2/helper/schema"
	"github.com/hashicorp/terraform-provider-google/google/tpgresource"
	transport_tpg "github.com/hashicorp/terraform-provider-google/google/transport"
)

func DataSourceGoogleBigqueryDatasets() *schema.Resource {
	dsSchema := map[string]*schema.Schema{
		"project": {
			Type:        schema.TypeString,
			Optional:    true,
			Description: "The ID of the project in which the datasets are located. If it is not provided, the provider project is used.",
		},
		"datasets": {
			Type:     schema.TypeList,
			Computed: true,
			Elem: &schema.Resource{
				Schema: map[string]*schema.Schema{
					"labels": {
						Type:     schema.TypeMap,
						Computed: true,
						Elem: &schema.Schema{
							Type: schema.TypeString,
						},
						Description: "The labels associated with this dataset. You can use these to organize and group your datasets.",
					},
					"friendly_name": {
						Type:        schema.TypeString,
						Computed:    true,
						Description: "A user-friendly name for the dataset.",
					},
					"dataset_id": {
						Type:        schema.TypeString,
						Computed:    true,
						Description: "A unique ID for this dataset, without the project name. The ID must contain only letters (a-z, A-Z), numbers (0-9), or underscores (_).",
					},
					"location": {
						Type:        schema.TypeString,
						Computed:    true,
						Description: "The geographic location where the dataset resides.",
					},
				},
			},
		},
	}

	return &schema.Resource{
		Read:   DataSourceGoogleBigQueryDatasetsRead,
		Schema: dsSchema,
	}
}

func DataSourceGoogleBigQueryDatasetsRead(d *schema.ResourceData, meta interface{}) error {
	config := meta.(*transport_tpg.Config)
	userAgent, err := tpgresource.GenerateUserAgentString(d, config.UserAgent)
	if err != nil {
		return err
	}

	project, err := tpgresource.GetProject(d, config)

	if err != nil {
		return fmt.Errorf("Error fetching project: %s", err)
	}

	params := make(map[string]string)
	datasets := make([]map[string]interface{}, 0)

	for {
		url, err := tpgresource.ReplaceVars(d, config, "{{BigQueryBasePath}}projects/{{project}}/datasets")
		if err != nil {
			return err
		}

		url, err = transport_tpg.AddQueryParams(url, params)
		if err != nil {
			return err
		}

		res, err := transport_tpg.SendRequest(transport_tpg.SendRequestOptions{
			Config:    config,
			Method:    "GET",
			RawURL:    url,
			UserAgent: userAgent,
		})
		if err != nil {
			return fmt.Errorf("Error retrieving datasets: %s", err)
		}

		pageDatasets := flattenDataSourceGoogleBigQueryDatasetsList(res["datasets"])
		datasets = append(datasets, pageDatasets...)

		pToken, ok := res["nextPageToken"]
		if ok && pToken != nil && pToken.(string) != "" {
			params["pageToken"] = pToken.(string)
		} else {
			break
		}
	}

	if err := d.Set("datasets", datasets); err != nil {
		return fmt.Errorf("Error retrieving datasets: %s", err)
	}

	id := fmt.Sprintf("projects/%s/datasets", project)
	d.SetId(id)

	return nil
}

func flattenDataSourceGoogleBigQueryDatasetsList(res interface{}) []map[string]interface{} {
	if res == nil {
		return make([]map[string]interface{}, 0)
	}

	ls := res.([]interface{})

	datasets := make([]map[string]interface{}, 0, len(ls))

	for _, raw := range ls {
		output := raw.(map[string]interface{})

		var mLabels map[string]interface{}
		var mDatasetID string
		var mFriendlyName string
		var mLocation string

		if oLabels, ok := output["labels"].(map[string]interface{}); ok {
			mLabels = oLabels
		} else {
			mLabels = make(map[string]interface{}) // Initialize as an empty map if labels are missing
		}

		if oFriendlyName, ok := output["friendlyName"].(string); ok {
			mFriendlyName = oFriendlyName
		}

		if oDatasetReference, ok := output["datasetReference"].(map[string]interface{}); ok {
			if datasetID, ok := oDatasetReference["datasetId"].(string); ok {
				mDatasetID = datasetID
			}
		}

		if oLocation, ok := output["location"].(string); ok {
			mLocation = oLocation
		}

		datasets = append(datasets, map[string]interface{}{
			"labels":        mLabels,
			"friendly_name": mFriendlyName,
			"dataset_id":    mDatasetID,
			"location":      mLocation,
		})
	}

	return datasets
}
