// Copyright (c) HashiCorp, Inc.
// SPDX-License-Identifier: MPL-2.0
// ----------------------------------------------------------------------------
//
//	***     AUTO GENERATED CODE    ***    Type: Handwritten     ***
//
// ----------------------------------------------------------------------------
//
//	This code is generated by Magic Modules using the following:
//
//	Source file: https://github.com/GoogleCloudPlatform/magic-modules/tree/main/mmv1/third_party/terraform/services/container/node_config.go.tmpl
//
//	DO NOT EDIT this file directly. Any changes made to this file will be
//	overwritten during the next generation cycle.
//
// ----------------------------------------------------------------------------
package container

import (
	"fmt"
	"log"
	"strconv"
	"strings"
	"time"

	"github.com/hashicorp/go-cty/cty"
	"github.com/hashicorp/terraform-plugin-sdk/v2/helper/schema"
	"github.com/hashicorp/terraform-plugin-sdk/v2/helper/validation"

	"github.com/hashicorp/terraform-provider-google/google/tpgresource"
	transport_tpg "github.com/hashicorp/terraform-provider-google/google/transport"

	"github.com/hashicorp/terraform-provider-google/google/verify"

	"google.golang.org/api/container/v1"
)

// Matches gke-default scope from https://cloud.google.com/sdk/gcloud/reference/container/clusters/create
var defaultOauthScopes = []string{
	"https://www.googleapis.com/auth/devstorage.read_only",
	"https://www.googleapis.com/auth/logging.write",
	"https://www.googleapis.com/auth/monitoring",
	"https://www.googleapis.com/auth/service.management.readonly",
	"https://www.googleapis.com/auth/servicecontrol",
	"https://www.googleapis.com/auth/trace.append",
}

func schemaContainerdConfig() *schema.Schema {
	return &schema.Schema{
		Type:        schema.TypeList,
		Optional:    true,
		Computed:    true,
		Description: "Parameters for containerd configuration.",
		MaxItems:    1,
		Elem: &schema.Resource{Schema: map[string]*schema.Schema{
			"private_registry_access_config": {
				Type:        schema.TypeList,
				Optional:    true,
				Description: "Parameters for private container registries configuration.",
				MaxItems:    1,
				Elem: &schema.Resource{Schema: map[string]*schema.Schema{
					"enabled": {
						Type:        schema.TypeBool,
						Required:    true,
						Description: "Whether or not private registries are configured.",
					},
					"certificate_authority_domain_config": {
						Type:        schema.TypeList,
						Optional:    true,
						Description: "Parameters for configuring CA certificate and domains.",
						Elem: &schema.Resource{Schema: map[string]*schema.Schema{
							"fqdns": {
								Type:        schema.TypeList,
								Required:    true,
								Description: "List of fully-qualified-domain-names. IPv4s and port specification are supported.",
								Elem:        &schema.Schema{Type: schema.TypeString},
							},
							"gcp_secret_manager_certificate_config": {
								Type:        schema.TypeList,
								Required:    true,
								Description: "Parameters for configuring a certificate hosted in GCP SecretManager.",
								MaxItems:    1,
								Elem: &schema.Resource{Schema: map[string]*schema.Schema{
									"secret_uri": {
										Type:        schema.TypeString,
										Required:    true,
										Description: "URI for the secret that hosts a certificate. Must be in the format 'projects/PROJECT_NUM/secrets/SECRET_NAME/versions/VERSION_OR_LATEST'.",
									},
								}},
							},
						}},
					},
				}},
			},
			"writable_cgroups": {
				Type:        schema.TypeList,
				Description: `Parameters for writable cgroups configuration.`,
				Optional:    true,
				MaxItems:    1,
				Elem: &schema.Resource{
					Schema: map[string]*schema.Schema{
						"enabled": {
							Type:        schema.TypeBool,
							Required:    true,
							Description: `Whether writable cgroups are enabled.`,
						},
					},
				},
			},
			"registry_hosts": {
				Type:        schema.TypeList,
				Optional:    true,
				Description: "Configures containerd registry host configuration. Each registry_hosts entry represents a hosts.toml file.",
				Elem: &schema.Resource{
					Schema: map[string]*schema.Schema{
						"server": {
							Type:        schema.TypeString,
							Required:    true,
							Description: "Defines the host name of the registry server.",
						},
						"hosts": {
							Type:        schema.TypeList,
							Optional:    true,
							Description: "Configures a list of host-specific configurations for the server.",
							Elem: &schema.Resource{Schema: map[string]*schema.Schema{
								"host": {
									Type:        schema.TypeString,
									Required:    true,
									Description: "Configures the registry host/mirror.",
								},
								"capabilities": {
									Type:        schema.TypeList,
									Optional:    true,
									Description: "Represent the capabilities of the registry host, specifying what operations a host is capable of performing.",
									Elem:        &schema.Schema{Type: schema.TypeString},
								},
								"override_path": {
									Type:        schema.TypeBool,
									Optional:    true,
									Description: "Indicate the host's API root endpoint is defined in the URL path rather than by the API specification.",
								},
								"dial_timeout": {
									Type:        schema.TypeString,
									Optional:    true,
									Description: "Specifies the maximum duration allowed for a connection attempt to complete.",
								},
								"header": {
									Type:        schema.TypeList,
									Optional:    true,
									Description: "Configures the registry host headers.",
									Elem: &schema.Resource{Schema: map[string]*schema.Schema{
										"key": {
											Type:        schema.TypeString,
											Required:    true,
											Description: "Configures the header key.",
										},
										"value": {
											Type:        schema.TypeList,
											Required:    true,
											Description: "Configures the header value.",
											Elem:        &schema.Schema{Type: schema.TypeString},
										},
									}},
								},
								"ca": {
									Type:        schema.TypeList,
									Optional:    true,
									Description: "Configures the registry host certificate.",
									Elem: &schema.Resource{Schema: map[string]*schema.Schema{
										"gcp_secret_manager_secret_uri": {
											Type:        schema.TypeString,
											Optional:    true,
											Description: "URI for the Secret Manager secret that hosts the certificate.",
										},
									}},
								},
								"client": {
									Type:        schema.TypeList,
									Optional:    true,
									Description: "Configures the registry host client certificate and key.",
									Elem: &schema.Resource{Schema: map[string]*schema.Schema{
										"cert": {
											Type:        schema.TypeList,
											Required:    true,
											MaxItems:    1,
											Description: "Configures the client certificate.",
											Elem: &schema.Resource{Schema: map[string]*schema.Schema{
												"gcp_secret_manager_secret_uri": {
													Type:        schema.TypeString,
													Optional:    true,
													Description: "URI for the Secret Manager secret that hosts the client certificate.",
												},
											}},
										},
										"key": {
											Type:        schema.TypeList,
											Optional:    true,
											MaxItems:    1,
											Description: "Configures the client private key.",
											Elem: &schema.Resource{Schema: map[string]*schema.Schema{
												"gcp_secret_manager_secret_uri": {
													Type:        schema.TypeString,
													Optional:    true,
													Description: "URI for the Secret Manager secret that hosts the private key.",
												},
											}},
										},
									}},
								},
							},
							},
						},
					}},
			},
		}},
	}
}

// Note: this is a bool internally, but implementing as an enum internally to
// make it easier to accept API level defaults.
func schemaInsecureKubeletReadonlyPortEnabled() *schema.Schema {
	return &schema.Schema{
		Type:         schema.TypeString,
		Optional:     true,
		Computed:     true,
		Description:  "Controls whether the kubelet read-only port is enabled. It is strongly recommended to set this to `FALSE`. Possible values: `TRUE`, `FALSE`.",
		ValidateFunc: validation.StringInSlice([]string{"FALSE", "TRUE"}, false),
	}
}

func schemaLoggingVariant() *schema.Schema {
	return &schema.Schema{
		Type:         schema.TypeString,
		Optional:     true,
		Computed:     true,
		Description:  `Type of logging agent that is used as the default value for node pools in the cluster. Valid values include DEFAULT and MAX_THROUGHPUT.`,
		ValidateFunc: validation.StringInSlice([]string{"DEFAULT", "MAX_THROUGHPUT"}, false),
	}
}

func schemaGcfsConfig() *schema.Schema {
	return &schema.Schema{
		Type:        schema.TypeList,
		Optional:    true,
		Computed:    true,
		MaxItems:    1,
		Description: `GCFS configuration for this node.`,
		Elem: &schema.Resource{
			Schema: map[string]*schema.Schema{
				"enabled": {
					Type:        schema.TypeBool,
					Required:    true,
					Description: `Whether or not GCFS is enabled`,
				},
			},
		},
	}
}

func schemaNodeConfig() *schema.Schema {
	return &schema.Schema{
		Type:        schema.TypeList,
		Optional:    true,
		Computed:    true,
		ForceNew:    true,
		Description: `The configuration of the nodepool`,
		MaxItems:    1,
		Elem: &schema.Resource{
			Schema: map[string]*schema.Schema{
				"containerd_config": schemaContainerdConfig(),
				"disk_size_gb": {
					Type:         schema.TypeInt,
					Optional:     true,
					Computed:     true,
					ValidateFunc: validation.IntAtLeast(10),
					Description:  `Size of the disk attached to each node, specified in GB. The smallest allowed disk size is 10GB.`,
				},

				"disk_type": {
					Type:        schema.TypeString,
					Optional:    true,
					Computed:    true,
					Description: `Type of the disk attached to each node. Such as pd-standard, pd-balanced or pd-ssd`,
				},

				"boot_disk": schemaBootDiskConfig(),

				"guest_accelerator": {
					Type:        schema.TypeList,
					Optional:    true,
					Computed:    true,
					ForceNew:    true,
					Description: `List of the type and count of accelerator cards attached to the instance.`,
					Elem: &schema.Resource{
						Schema: map[string]*schema.Schema{
							"count": {
								Type:        schema.TypeInt,
								Required:    true,
								ForceNew:    true,
								Description: `The number of the accelerator cards exposed to an instance.`,
							},
							"type": {
								Type:             schema.TypeString,
								Required:         true,
								ForceNew:         true,
								DiffSuppressFunc: tpgresource.CompareSelfLinkOrResourceName,
								Description:      `The accelerator type resource name.`,
							},
							"gpu_driver_installation_config": {
								Type:        schema.TypeList,
								MaxItems:    1,
								Optional:    true,
								Computed:    true,
								ForceNew:    true,
								Description: `Configuration for auto installation of GPU driver.`,
								Elem: &schema.Resource{
									Schema: map[string]*schema.Schema{
										"gpu_driver_version": {
											Type:         schema.TypeString,
											Required:     true,
											ForceNew:     true,
											Description:  `Mode for how the GPU driver is installed.`,
											ValidateFunc: validation.StringInSlice([]string{"GPU_DRIVER_VERSION_UNSPECIFIED", "INSTALLATION_DISABLED", "DEFAULT", "LATEST"}, false),
										},
									},
								},
							},
							"gpu_partition_size": {
								Type:        schema.TypeString,
								Optional:    true,
								ForceNew:    true,
								Description: `Size of partitions to create on the GPU. Valid values are described in the NVIDIA mig user guide (https://docs.nvidia.com/datacenter/tesla/mig-user-guide/#partitioning)`,
							},
							"gpu_sharing_config": {
								Type:        schema.TypeList,
								MaxItems:    1,
								Optional:    true,
								ForceNew:    true,
								Description: `Configuration for GPU sharing.`,
								Elem: &schema.Resource{
									Schema: map[string]*schema.Schema{
										"gpu_sharing_strategy": {
											Type:        schema.TypeString,
											Required:    true,
											ForceNew:    true,
											Description: `The type of GPU sharing strategy to enable on the GPU node. Possible values are described in the API package (https://pkg.go.dev/google.golang.org/api/container/v1#GPUSharingConfig)`,
										},
										"max_shared_clients_per_gpu": {
											Type:        schema.TypeInt,
											Required:    true,
											ForceNew:    true,
											Description: `The maximum number of containers that can share a GPU.`,
										},
									},
								},
							},
						},
					},
				},

				"image_type": {
					Type:             schema.TypeString,
					Optional:         true,
					Computed:         true,
					DiffSuppressFunc: tpgresource.CaseDiffSuppress,
					Description:      `The image type to use for this node. Note that for a given image type, the latest version of it will be used.`,
				},

				"labels": {
					Type:     schema.TypeMap,
					Optional: true,
					// Computed=true because GKE Sandbox will automatically add labels to nodes that can/cannot run sandboxed pods.
					Computed:    true,
					Elem:        &schema.Schema{Type: schema.TypeString},
					Description: `The map of Kubernetes labels (key/value pairs) to be applied to each node. These will added in addition to any default label(s) that Kubernetes may apply to the node.`,
				},

				"resource_labels": {
					Type:             schema.TypeMap,
					Optional:         true,
					Elem:             &schema.Schema{Type: schema.TypeString},
					DiffSuppressFunc: containerNodePoolResourceLabelsDiffSuppress,
					Description:      `The GCE resource labels (a map of key/value pairs) to be applied to the node pool.`,
				},

				"local_ssd_count": {
					Type:         schema.TypeInt,
					Optional:     true,
					Computed:     true,
					ForceNew:     true,
					ValidateFunc: validation.IntAtLeast(0),
					Description:  `The number of local SSD disks to be attached to the node.`,
				},

				"logging_variant": schemaLoggingVariant(),

				"ephemeral_storage_local_ssd_config": {
					Type:        schema.TypeList,
					Optional:    true,
					MaxItems:    1,
					Description: `Parameters for the ephemeral storage filesystem. If unspecified, ephemeral storage is backed by the boot disk.`,
					ForceNew:    true,
					Elem: &schema.Resource{
						Schema: map[string]*schema.Schema{
							"local_ssd_count": {
								Type:         schema.TypeInt,
								Required:     true,
								ForceNew:     true,
								ValidateFunc: validation.IntAtLeast(0),
								Description:  `Number of local SSDs to use to back ephemeral storage. Uses NVMe interfaces. Each local SSD must be 375 or 3000 GB in size, and all local SSDs must share the same size.`,
							},
							"data_cache_count": {
								Type:         schema.TypeInt,
								Optional:     true,
								ForceNew:     true,
								ValidateFunc: validation.IntAtLeast(0),
								Description:  `Number of local SSDs to be utilized for GKE Data Cache. Uses NVMe interfaces.`,
							},
						},
					},
				},

				"local_nvme_ssd_block_config": {
					Type:        schema.TypeList,
					Optional:    true,
					MaxItems:    1,
					Description: `Parameters for raw-block local NVMe SSDs.`,
					ForceNew:    true,
					Elem: &schema.Resource{
						Schema: map[string]*schema.Schema{
							"local_ssd_count": {
								Type:         schema.TypeInt,
								Required:     true,
								ForceNew:     true,
								ValidateFunc: validation.IntAtLeast(0),
								Description:  `Number of raw-block local NVMe SSD disks to be attached to the node. Each local SSD is 375 GB in size.`,
							},
						},
					},
				},

				"secondary_boot_disks": {
					Type:        schema.TypeList,
					Optional:    true,
					MaxItems:    127,
					Description: `Secondary boot disks for preloading data or container images.`,
					ForceNew:    true,
					Elem: &schema.Resource{
						Schema: map[string]*schema.Schema{
							"disk_image": {
								Type:        schema.TypeString,
								Required:    true,
								ForceNew:    true,
								Description: `Disk image to create the secondary boot disk from`,
							},
							"mode": {
								Type:        schema.TypeString,
								Optional:    true,
								ForceNew:    true,
								Description: `Mode for how the secondary boot disk is used.`,
							},
						},
					},
				},

				"gcfs_config": schemaGcfsConfig(),

				"gvnic": {
					Type:        schema.TypeList,
					Optional:    true,
					MaxItems:    1,
					Description: `Enable or disable gvnic in the node pool.`,
					Elem: &schema.Resource{
						Schema: map[string]*schema.Schema{
							"enabled": {
								Type:        schema.TypeBool,
								Required:    true,
								Description: `Whether or not gvnic is enabled`,
							},
						},
					},
				},

				"machine_type": {
					Type:        schema.TypeString,
					Optional:    true,
					Computed:    true,
					Description: `The name of a Google Compute Engine machine type.`,
				},

				"metadata": {
					Type:        schema.TypeMap,
					Optional:    true,
					Computed:    true,
					ForceNew:    true,
					Elem:        &schema.Schema{Type: schema.TypeString},
					Description: `The metadata key/value pairs assigned to instances in the cluster.`,
				},

				"min_cpu_platform": {
					Type:        schema.TypeString,
					Optional:    true,
					Computed:    true,
					ForceNew:    true,
					Description: `Minimum CPU platform to be used by this instance. The instance may be scheduled on the specified or newer CPU platform.`,
				},

				"oauth_scopes": {
					Type:        schema.TypeSet,
					Optional:    true,
					Computed:    true,
					ForceNew:    true,
					Description: `The set of Google API scopes to be made available on all of the node VMs.`,
					Elem: &schema.Schema{
						Type: schema.TypeString,
						StateFunc: func(v interface{}) string {
							return tpgresource.CanonicalizeServiceScope(v.(string))
						},
					},
					DiffSuppressFunc: containerClusterAddedScopesSuppress,
					Set:              tpgresource.StringScopeHashcode,
				},

				"preemptible": {
					Type:        schema.TypeBool,
					Optional:    true,
					ForceNew:    true,
					Default:     false,
					Description: `Whether the nodes are created as preemptible VM instances.`,
				},
				"reservation_affinity": {
					Type:        schema.TypeList,
					Optional:    true,
					MaxItems:    1,
					Description: `The reservation affinity configuration for the node pool.`,
					ForceNew:    true,
					Elem: &schema.Resource{
						Schema: map[string]*schema.Schema{
							"consume_reservation_type": {
								Type:         schema.TypeString,
								Required:     true,
								ForceNew:     true,
								Description:  `Corresponds to the type of reservation consumption.`,
								ValidateFunc: validation.StringInSlice([]string{"UNSPECIFIED", "NO_RESERVATION", "ANY_RESERVATION", "SPECIFIC_RESERVATION"}, false),
							},
							"key": {
								Type:        schema.TypeString,
								Optional:    true,
								ForceNew:    true,
								Description: `The label key of a reservation resource.`,
							},
							"values": {
								Type:        schema.TypeSet,
								Description: "The label values of the reservation resource.",
								ForceNew:    true,
								Optional:    true,
								Elem: &schema.Schema{
									Type: schema.TypeString,
								},
							},
						},
					},
				},
				"spot": {
					Type:        schema.TypeBool,
					Optional:    true,
					ForceNew:    true,
					Default:     false,
					Description: `Whether the nodes are created as spot VM instances.`,
				},

				"service_account": {
					Type:        schema.TypeString,
					Optional:    true,
					Computed:    true,
					ForceNew:    true,
					Description: `The Google Cloud Platform Service Account to be used by the node VMs.`,
				},

				"tags": {
					Type:        schema.TypeList,
					Optional:    true,
					Elem:        &schema.Schema{Type: schema.TypeString},
					Description: `The list of instance tags applied to all nodes.`,
				},

				"storage_pools": {
					Type:        schema.TypeList,
					Optional:    true,
					Elem:        &schema.Schema{Type: schema.TypeString},
					Description: `The list of Storage Pools where boot disks are provisioned.`,
				},

				"shielded_instance_config": {
					Type:        schema.TypeList,
					Optional:    true,
					Computed:    true,
					ForceNew:    true,
					Description: `Shielded Instance options.`,
					MaxItems:    1,
					Elem: &schema.Resource{
						Schema: map[string]*schema.Schema{
							"enable_secure_boot": {
								Type:        schema.TypeBool,
								Optional:    true,
								ForceNew:    true,
								Default:     false,
								Description: `Defines whether the instance has Secure Boot enabled.`,
							},
							"enable_integrity_monitoring": {
								Type:        schema.TypeBool,
								Optional:    true,
								ForceNew:    true,
								Default:     true,
								Description: `Defines whether the instance has integrity monitoring enabled.`,
							},
						},
					},
				},

				"taint": {
					Type:        schema.TypeList,
					Optional:    true,
					Description: `List of Kubernetes taints to be applied to each node.`,
					Elem: &schema.Resource{
						Schema: map[string]*schema.Schema{
							"key": {
								Type:        schema.TypeString,
								Required:    true,
								Description: `Key for taint.`,
							},
							"value": {
								Type:        schema.TypeString,
								Required:    true,
								Description: `Value for taint.`,
							},
							"effect": {
								Type:         schema.TypeString,
								Required:     true,
								ValidateFunc: validation.StringInSlice([]string{"NO_SCHEDULE", "PREFER_NO_SCHEDULE", "NO_EXECUTE"}, false),
								Description:  `Effect for taint.`,
							},
						},
					},
				},

				"effective_taints": {
					Type:        schema.TypeList,
					Computed:    true,
					Description: `List of kubernetes taints applied to each node.`,
					Elem: &schema.Resource{
						Schema: map[string]*schema.Schema{
							"key": {
								Type:        schema.TypeString,
								Computed:    true,
								Description: `Key for taint.`,
							},
							"value": {
								Type:        schema.TypeString,
								Computed:    true,
								Description: `Value for taint.`,
							},
							"effect": {
								Type:        schema.TypeString,
								Computed:    true,
								Description: `Effect for taint.`,
							},
						},
					},
				},

				"workload_metadata_config": {
					Computed:    true,
					Type:        schema.TypeList,
					Optional:    true,
					MaxItems:    1,
					Description: `The workload metadata configuration for this node.`,
					Elem: &schema.Resource{
						Schema: map[string]*schema.Schema{
							"mode": {
								Type:         schema.TypeString,
								Required:     true,
								ValidateFunc: validation.StringInSlice([]string{"MODE_UNSPECIFIED", "GCE_METADATA", "GKE_METADATA"}, false),
								Description:  `Mode is the configuration for how to expose metadata to workloads running on the node.`,
							},
						},
					},
				},

				"boot_disk_kms_key": {
					Type:        schema.TypeString,
					Optional:    true,
					ForceNew:    true,
					Description: `The Customer Managed Encryption Key used to encrypt the boot disk attached to each node in the node pool.`,
				},
				// Note that AtLeastOneOf can't be set because this schema is reused by
				// two different resources.
				"kubelet_config": {
					Type:        schema.TypeList,
					Optional:    true,
					Computed:    true,
					MaxItems:    1,
					Description: `Node kubelet configs.`,
					Elem: &schema.Resource{
						Schema: map[string]*schema.Schema{
							"cpu_manager_policy": {
								Type:         schema.TypeString,
								Optional:     true,
								ValidateFunc: validation.StringInSlice([]string{"static", "none", ""}, false),
								Description:  `Control the CPU management policy on the node.`,
							},
							"memory_manager": {
								Type:        schema.TypeList,
								Optional:    true,
								MaxItems:    1,
								Description: `Configuration for the Memory Manager on the node. The memory manager optimizes memory and hugepages allocation for pods, especially those in the Guaranteed QoS class, by influencing NUMA affinity.`,
								Elem: &schema.Resource{
									Schema: map[string]*schema.Schema{
										"policy": {
											Type:         schema.TypeString,
											Optional:     true,
											Computed:     true,
											Description:  `The Memory Manager policy to use. This policy guides how memory and hugepages are allocated and managed for pods on the node, influencing NUMA affinity.`,
											ValidateFunc: validation.StringInSlice([]string{"None", "Static", ""}, false),
										},
									},
								},
							},
							"topology_manager": {
								Type:        schema.TypeList,
								Optional:    true,
								MaxItems:    1,
								Description: `Configuration for the Topology Manager on the node. The Topology Manager aligns CPU, memory, and device resources on a node to optimize performance, especially for NUMA-aware workloads, by ensuring resource co-location.`,
								Elem: &schema.Resource{
									Schema: map[string]*schema.Schema{
										"policy": {
											Type:         schema.TypeString,
											Optional:     true,
											Computed:     true,
											Description:  `The Topology Manager policy to use. This policy dictates how resource alignment is handled on the node.`,
											ValidateFunc: validation.StringInSlice([]string{"none", "restricted", "single-numa-node", "best-effort", ""}, false),
										},
										"scope": {
											Type:         schema.TypeString,
											Optional:     true,
											Computed:     true,
											Description:  `The Topology Manager scope, defining the granularity at which policy decisions are applied. Valid values are "container" (resources are aligned per container within a pod) or "pod" (resources are aligned for the entire pod).`,
											ValidateFunc: validation.StringInSlice([]string{"container", "pod", ""}, false),
										},
									},
								},
							},
							"cpu_cfs_quota": {
								Type:        schema.TypeBool,
								Computed:    true,
								Optional:    true,
								Description: `Enable CPU CFS quota enforcement for containers that specify CPU limits.`,
							},
							"cpu_cfs_quota_period": {
								Type:        schema.TypeString,
								Optional:    true,
								Description: `Set the CPU CFS quota period value 'cpu.cfs_period_us'.`,
							},
							"insecure_kubelet_readonly_port_enabled": schemaInsecureKubeletReadonlyPortEnabled(),
							"pod_pids_limit": {
								Type:        schema.TypeInt,
								Optional:    true,
								Description: `Controls the maximum number of processes allowed to run in a pod.`,
							},
							"max_parallel_image_pulls": {
								Type:        schema.TypeInt,
								Optional:    true,
								Computed:    true,
								Description: `Set the maximum number of image pulls in parallel.`,
							},
							"container_log_max_size": {
								Type:        schema.TypeString,
								Optional:    true,
								Description: `Defines the maximum size of the container log file before it is rotated.`,
							},
							"container_log_max_files": {
								Type:        schema.TypeInt,
								Optional:    true,
								Description: `Defines the maximum number of container log files that can be present for a container.`,
							},
							"image_gc_low_threshold_percent": {
								Type:        schema.TypeInt,
								Optional:    true,
								Description: `Defines the percent of disk usage before which image garbage collection is never run. Lowest disk usage to garbage collect to.`,
							},
							"image_gc_high_threshold_percent": {
								Type:        schema.TypeInt,
								Optional:    true,
								Description: `Defines the percent of disk usage after which image garbage collection is always run.`,
							},
							"image_minimum_gc_age": {
								Type:        schema.TypeString,
								Optional:    true,
								Description: `Defines the minimum age for an unused image before it is garbage collected.`,
							},
							"image_maximum_gc_age": {
								Type:        schema.TypeString,
								Optional:    true,
								Description: `Defines the maximum age an image can be unused before it is garbage collected.`,
							},
							"allowed_unsafe_sysctls": {
								Type:        schema.TypeList,
								Optional:    true,
								Description: `Defines a comma-separated allowlist of unsafe sysctls or sysctl patterns which can be set on the Pods.`,
								Elem:        &schema.Schema{Type: schema.TypeString},
							},
							"single_process_oom_kill": {
								Type:        schema.TypeBool,
								Optional:    true,
								Description: `Defines whether to enable single process OOM killer.`,
							},
							"eviction_max_pod_grace_period_seconds": {
								Type:        schema.TypeInt,
								Optional:    true,
								Description: `Defines the maximum allowed grace period (in seconds) to use when terminating pods in response to a soft eviction threshold being met.`,
							},
							"eviction_soft": {
								Type:        schema.TypeList,
								Optional:    true,
								MaxItems:    1,
								Description: `Defines a map of signal names to quantities or percentage that defines soft eviction thresholds.`,
								Elem: &schema.Resource{
									Schema: map[string]*schema.Schema{
										"memory_available": {
											Type:        schema.TypeString,
											Optional:    true,
											Description: `Defines quantity of soft eviction threshold for memory.available.`,
										},
										"nodefs_available": {
											Type:        schema.TypeString,
											Optional:    true,
											Description: `Defines percentage of soft eviction threshold for nodefs.available.`,
										},
										"nodefs_inodes_free": {
											Type:        schema.TypeString,
											Optional:    true,
											Description: `Defines percentage of soft eviction threshold for nodefs.inodesFree.`,
										},
										"imagefs_available": {
											Type:        schema.TypeString,
											Optional:    true,
											Description: `Defines percentage of soft eviction threshold for imagefs.available.`,
										},
										"imagefs_inodes_free": {
											Type:        schema.TypeString,
											Optional:    true,
											Description: `Defines percentage of soft eviction threshold for imagefs.inodesFree.`,
										},
										"pid_available": {
											Type:        schema.TypeString,
											Optional:    true,
											Description: `Defines percentage of soft eviction threshold for pid.available.`,
										},
									},
								},
							},
							"eviction_soft_grace_period": {
								Type:        schema.TypeList,
								Optional:    true,
								MaxItems:    1,
								Description: `Defines a map of signal names to durations that defines grace periods for soft eviction thresholds. Each soft eviction threshold must have a corresponding grace period.`,
								Elem: &schema.Resource{
									Schema: map[string]*schema.Schema{
										"memory_available": {
											Type:        schema.TypeString,
											Optional:    true,
											Description: `Defines grace period for the memory.available soft eviction threshold.`,
										},
										"nodefs_available": {
											Type:        schema.TypeString,
											Optional:    true,
											Description: `Defines grace period for the nodefs.available soft eviction threshold.`,
										},
										"nodefs_inodes_free": {
											Type:        schema.TypeString,
											Optional:    true,
											Description: `Defines grace period for the nodefs.inodesFree soft eviction threshold.`,
										},
										"imagefs_available": {
											Type:        schema.TypeString,
											Optional:    true,
											Description: `Defines grace period for the imagefs.available soft eviction threshold`,
										},
										"imagefs_inodes_free": {
											Type:        schema.TypeString,
											Optional:    true,
											Description: `Defines grace period for the imagefs.inodesFree soft eviction threshold.`,
										},
										"pid_available": {
											Type:        schema.TypeString,
											Optional:    true,
											Description: `Defines grace period for the pid.available soft eviction threshold.`,
										},
									},
								},
							},
							"eviction_minimum_reclaim": {
								Type:        schema.TypeList,
								Optional:    true,
								MaxItems:    1,
								Description: `Defines a map of signal names to percentage that defines minimum reclaims. It describes the minimum amount of a given resource the kubelet will reclaim when performing a pod eviction.`,
								Elem: &schema.Resource{
									Schema: map[string]*schema.Schema{
										"memory_available": {
											Type:        schema.TypeString,
											Optional:    true,
											Description: `Defines percentage of minimum reclaim for memory.available.`,
										},
										"nodefs_available": {
											Type:        schema.TypeString,
											Optional:    true,
											Description: `Defines percentage of minimum reclaim for nodefs.available.`,
										},
										"nodefs_inodes_free": {
											Type:        schema.TypeString,
											Optional:    true,
											Description: `Defines percentage of minimum reclaim for nodefs.inodesFree.`,
										},
										"imagefs_available": {
											Type:        schema.TypeString,
											Optional:    true,
											Description: `Defines percentage of minimum reclaim for imagefs.available.`,
										},
										"imagefs_inodes_free": {
											Type:        schema.TypeString,
											Optional:    true,
											Description: `Defines percentage of minimum reclaim for imagefs.inodesFree.`,
										},
										"pid_available": {
											Type:        schema.TypeString,
											Optional:    true,
											Description: `Defines percentage of minimum reclaim for pid.available.`,
										},
									},
								},
							},
						},
					},
				},
				"linux_node_config": {
					Type:        schema.TypeList,
					Optional:    true,
					MaxItems:    1,
					Computed:    true,
					Description: `Parameters that can be configured on Linux nodes.`,
					Elem: &schema.Resource{
						Schema: map[string]*schema.Schema{
							"sysctls": {
								Type:        schema.TypeMap,
								Optional:    true,
								Elem:        &schema.Schema{Type: schema.TypeString},
								Description: `The Linux kernel parameters to be applied to the nodes and all pods running on the nodes.`,
							},
							"cgroup_mode": {
								Type:             schema.TypeString,
								Optional:         true,
								Computed:         true,
								ValidateFunc:     validation.StringInSlice([]string{"CGROUP_MODE_UNSPECIFIED", "CGROUP_MODE_V1", "CGROUP_MODE_V2"}, false),
								Description:      `cgroupMode specifies the cgroup mode to be used on the node.`,
								DiffSuppressFunc: tpgresource.EmptyOrDefaultStringSuppress("CGROUP_MODE_UNSPECIFIED"),
							},
							"node_kernel_module_loading": {
								Type:        schema.TypeList,
								Optional:    true,
								MaxItems:    1,
								Description: `The settings for kernel module loading.`,
								Elem: &schema.Resource{
									Schema: map[string]*schema.Schema{
										"policy": {
											Type:             schema.TypeString,
											Optional:         true,
											ValidateFunc:     validation.StringInSlice([]string{"POLICY_UNSPECIFIED", "ENFORCE_SIGNED_MODULES", "DO_NOT_ENFORCE_SIGNED_MODULES"}, false),
											Description:      `The policy for kernel module loading.`,
											DiffSuppressFunc: tpgresource.EmptyOrDefaultStringSuppress("POLICY_UNSPECIFIED"),
										},
									},
								},
							},
							"transparent_hugepage_enabled": {
								Type:             schema.TypeString,
								Optional:         true,
								Computed:         true,
								ValidateFunc:     validation.StringInSlice([]string{"TRANSPARENT_HUGEPAGE_ENABLED_ALWAYS", "TRANSPARENT_HUGEPAGE_ENABLED_MADVISE", "TRANSPARENT_HUGEPAGE_ENABLED_NEVER", "TRANSPARENT_HUGEPAGE_ENABLED_UNSPECIFIED"}, false),
								Description:      `The Linux kernel transparent hugepage setting.`,
								DiffSuppressFunc: tpgresource.EmptyOrDefaultStringSuppress("TRANSPARENT_HUGEPAGE_ENABLED_UNSPECIFIED"),
							},
							"transparent_hugepage_defrag": {
								Type:             schema.TypeString,
								Optional:         true,
								ValidateFunc:     validation.StringInSlice([]string{"TRANSPARENT_HUGEPAGE_DEFRAG_ALWAYS", "TRANSPARENT_HUGEPAGE_DEFRAG_DEFER", "TRANSPARENT_HUGEPAGE_DEFRAG_DEFER_WITH_MADVISE", "TRANSPARENT_HUGEPAGE_DEFRAG_MADVISE", "TRANSPARENT_HUGEPAGE_DEFRAG_NEVER", "TRANSPARENT_HUGEPAGE_DEFRAG_UNSPECIFIED"}, false),
								Description:      `The Linux kernel transparent hugepage defrag setting.`,
								DiffSuppressFunc: tpgresource.EmptyOrDefaultStringSuppress("TRANSPARENT_HUGEPAGE_DEFRAG_UNSPECIFIED"),
							},
							"hugepages_config": {
								Type:        schema.TypeList,
								Optional:    true,
								MaxItems:    1,
								Description: `Amounts for 2M and 1G hugepages.`,
								Elem: &schema.Resource{
									Schema: map[string]*schema.Schema{
										"hugepage_size_2m": {
											Type:        schema.TypeInt,
											Optional:    true,
											Description: `Amount of 2M hugepages.`,
										},
										"hugepage_size_1g": {
											Type:        schema.TypeInt,
											Optional:    true,
											Description: `Amount of 1G hugepages.`,
										},
									},
								},
							},
						},
					},
				},
				"windows_node_config": {
					Type:        schema.TypeList,
					Optional:    true,
					Computed:    true,
					MaxItems:    1,
					Description: `Parameters that can be configured on Windows nodes.`,
					Elem: &schema.Resource{
						Schema: map[string]*schema.Schema{
							"osversion": {
								Type:         schema.TypeString,
								Optional:     true,
								Default:      "OS_VERSION_UNSPECIFIED",
								Description:  `The OS Version of the windows nodepool.Values are OS_VERSION_UNSPECIFIED,OS_VERSION_LTSC2019 and OS_VERSION_LTSC2022`,
								ValidateFunc: validation.StringInSlice([]string{"OS_VERSION_UNSPECIFIED", "OS_VERSION_LTSC2019", "OS_VERSION_LTSC2022"}, false),
							},
						},
					},
				},
				"node_group": {
					Type:        schema.TypeString,
					Optional:    true,
					ForceNew:    true,
					Description: `Setting this field will assign instances of this pool to run on the specified node group. This is useful for running workloads on sole tenant nodes.`,
				},

				"advanced_machine_features": {
					Type:        schema.TypeList,
					Optional:    true,
					MaxItems:    1,
					Description: `Specifies options for controlling advanced machine features.`,
					ForceNew:    true,
					Elem: &schema.Resource{
						Schema: map[string]*schema.Schema{
							"threads_per_core": {
								Type:        schema.TypeInt,
								Required:    true,
								ForceNew:    true,
								Description: `The number of threads per physical core. To disable simultaneous multithreading (SMT) set this to 1. If unset, the maximum number of threads supported per core by the underlying processor is assumed.`,
							},
							"enable_nested_virtualization": {
								Type:        schema.TypeBool,
								Optional:    true,
								ForceNew:    true,
								Description: `Whether the node should have nested virtualization enabled.`,
							},
							"performance_monitoring_unit": {
								Type:         schema.TypeString,
								Optional:     true,
								ValidateFunc: verify.ValidateEnum([]string{"ARCHITECTURAL", "STANDARD", "ENHANCED"}),
								Description:  `Level of Performance Monitoring Unit (PMU) requested. If unset, no access to the PMU is assumed.`,
							},
						},
					},
				},
				"sole_tenant_config": {
					Type:        schema.TypeList,
					Optional:    true,
					Description: `Node affinity options for sole tenant node pools.`,
					ForceNew:    true,
					MaxItems:    1,
					Elem: &schema.Resource{
						Schema: map[string]*schema.Schema{
							"node_affinity": {
								Type:        schema.TypeSet,
								Required:    true,
								ForceNew:    true,
								Description: `.`,
								Elem: &schema.Resource{
									Schema: map[string]*schema.Schema{
										"key": {
											Type:        schema.TypeString,
											Required:    true,
											ForceNew:    true,
											Description: `.`,
										},
										"operator": {
											Type:         schema.TypeString,
											Required:     true,
											ForceNew:     true,
											Description:  `.`,
											ValidateFunc: validation.StringInSlice([]string{"IN", "NOT_IN"}, false),
										},
										"values": {
											Type:        schema.TypeList,
											Required:    true,
											ForceNew:    true,
											Description: `.`,
											Elem:        &schema.Schema{Type: schema.TypeString},
										},
									},
								},
							},
							"min_node_cpus": {
								Type:        schema.TypeInt,
								Optional:    true,
								Description: `Specifies the minimum number of vCPUs that each sole tenant node must have to use CPU overcommit. If not specified, the CPU overcommit feature is disabled.`,
							},
						},
					},
				},
				"host_maintenance_policy": {
					Type:        schema.TypeList,
					Optional:    true,
					Description: `The maintenance policy for the hosts on which the GKE VMs run on.`,
					ForceNew:    true,
					MaxItems:    1,
					Elem: &schema.Resource{
						Schema: map[string]*schema.Schema{
							"maintenance_interval": {
								Type:         schema.TypeString,
								Required:     true,
								ForceNew:     true,
								Description:  `.`,
								ValidateFunc: validation.StringInSlice([]string{"MAINTENANCE_INTERVAL_UNSPECIFIED", "AS_NEEDED", "PERIODIC"}, false),
							},
						},
					},
				},
				"confidential_nodes": {
					Type:        schema.TypeList,
					Optional:    true,
					Computed:    true,
					MaxItems:    1,
					Description: `Configuration for the confidential nodes feature, which makes nodes run on confidential VMs.`,
					Elem: &schema.Resource{
						Schema: map[string]*schema.Schema{
							"enabled": {
								Type:        schema.TypeBool,
								Required:    true,
								Description: `Whether Confidential Nodes feature is enabled for all nodes in this pool.`,
							},
							"confidential_instance_type": {
								Type:             schema.TypeString,
								Optional:         true,
								ForceNew:         true,
								DiffSuppressFunc: suppressDiffForConfidentialNodes,
								Description:      `Defines the type of technology used by the confidential node.`,
								ValidateFunc:     validation.StringInSlice([]string{"SEV", "SEV_SNP", "TDX"}, false),
							},
						},
					},
				},
				"fast_socket": {
					Type:        schema.TypeList,
					Optional:    true,
					MaxItems:    1,
					Description: `Enable or disable NCCL Fast Socket in the node pool.`,
					Elem: &schema.Resource{
						Schema: map[string]*schema.Schema{
							"enabled": {
								Type:        schema.TypeBool,
								Required:    true,
								Description: `Whether or not NCCL Fast Socket is enabled`,
							},
						},
					},
				},
				"resource_manager_tags": {
					Type:        schema.TypeMap,
					Optional:    true,
					Description: `A map of resource manager tags. Resource manager tag keys and values have the same definition as resource manager tags. Keys must be in the format tagKeys/{tag_key_id}, and values are in the format tagValues/456. The field is ignored (both PUT & PATCH) when empty.`,
				},
				"enable_confidential_storage": {
					Type:        schema.TypeBool,
					Optional:    true,
					ForceNew:    true,
					Description: `If enabled boot disks are configured with confidential mode.`,
				},
				"local_ssd_encryption_mode": {
					Type:         schema.TypeString,
					Optional:     true,
					ForceNew:     true,
					ValidateFunc: validation.StringInSlice([]string{"STANDARD_ENCRYPTION", "EPHEMERAL_KEY_ENCRYPTION"}, false),
					Description:  `LocalSsdEncryptionMode specified the method used for encrypting the local SSDs attached to the node.`,
				},
				"max_run_duration": {
					Type:        schema.TypeString,
					Optional:    true,
					ForceNew:    true,
					Description: `The runtime of each node in the node pool in seconds, terminated by 's'. Example: "3600s".`,
				},
				"flex_start": {
					Type:        schema.TypeBool,
					Optional:    true,
					ForceNew:    true,
					Description: `Enables Flex Start provisioning model for the node pool`,
				},
			},
		},
	}
}

func schemaBootDiskConfig() *schema.Schema {
	return &schema.Schema{
		Type:        schema.TypeList,
		Optional:    true,
		Computed:    true,
		MaxItems:    1,
		Description: `Boot disk configuration for node pools nodes.`,
		Elem: &schema.Resource{
			Schema: map[string]*schema.Schema{
				"disk_type": {
					Type:        schema.TypeString,
					Optional:    true,
					Computed:    true,
					Description: `Type of the disk attached to each node. Such as pd-standard, pd-balanced or pd-ssd`,
				},
				"size_gb": {
					Type:         schema.TypeInt,
					Optional:     true,
					Computed:     true,
					ValidateFunc: validation.IntAtLeast(10),
					Description:  `Size of the disk attached to each node, specified in GB. The smallest allowed disk size is 10GB.`,
				},
				"provisioned_iops": {
					Type:        schema.TypeInt,
					Optional:    true,
					Computed:    true,
					Description: `Configured IOPs provisioning. Only valid with disk type hyperdisk-balanced.`,
				},
				"provisioned_throughput": {
					Type:        schema.TypeInt,
					Optional:    true,
					Computed:    true,
					Description: `Configured throughput provisioning. Only valid with disk type hyperdisk-balanced.`,
				},
			},
		},
	}
}

// Separate since this currently only supports a single value -- a subset of
// the overall NodeKubeletConfig
func schemaNodePoolAutoConfigNodeKubeletConfig() *schema.Schema {
	return &schema.Schema{
		Type:        schema.TypeList,
		Optional:    true,
		Computed:    true,
		MaxItems:    1,
		Description: `Node kubelet configs.`,
		Elem: &schema.Resource{
			Schema: map[string]*schema.Schema{
				"insecure_kubelet_readonly_port_enabled": schemaInsecureKubeletReadonlyPortEnabled(),
			},
		},
	}
}

// Separate since this currently only supports a subset of the overall
// LinuxNodeConfig
func schemaNodePoolAutoConfigLinuxNodeConfig() *schema.Schema {
	return &schema.Schema{
		Type:        schema.TypeList,
		Optional:    true,
		MaxItems:    1,
		Description: `Linux node configuration options.`,
		Elem: &schema.Resource{
			Schema: map[string]*schema.Schema{
				"cgroup_mode": {
					Type:             schema.TypeString,
					Optional:         true,
					Computed:         true,
					ValidateFunc:     validation.StringInSlice([]string{"CGROUP_MODE_UNSPECIFIED", "CGROUP_MODE_V1", "CGROUP_MODE_V2"}, false),
					Description:      `cgroupMode specifies the cgroup mode to be used on the node.`,
					DiffSuppressFunc: tpgresource.EmptyOrDefaultStringSuppress("CGROUP_MODE_UNSPECIFIED"),
				},
				"node_kernel_module_loading": {
					Type:        schema.TypeList,
					Optional:    true,
					MaxItems:    1,
					Description: `The settings for kernel module loading.`,
					Elem: &schema.Resource{
						Schema: map[string]*schema.Schema{
							"policy": {
								Type:             schema.TypeString,
								Optional:         true,
								ValidateFunc:     validation.StringInSlice([]string{"POLICY_UNSPECIFIED", "ENFORCE_SIGNED_MODULES", "DO_NOT_ENFORCE_SIGNED_MODULES"}, false),
								Description:      `The policy for kernel module loading.`,
								DiffSuppressFunc: tpgresource.EmptyOrDefaultStringSuppress("POLICY_UNSPECIFIED"),
							},
						},
					},
				},
			},
		},
	}
}

func expandNodeConfigDefaults(configured interface{}) *container.NodeConfigDefaults {
	configs := configured.([]interface{})
	if len(configs) == 0 || configs[0] == nil {
		return nil
	}
	config := configs[0].(map[string]interface{})

	nodeConfigDefaults := &container.NodeConfigDefaults{}
	nodeConfigDefaults.ContainerdConfig = expandContainerdConfig(config["containerd_config"])
	if v, ok := config["insecure_kubelet_readonly_port_enabled"]; ok {
		nodeConfigDefaults.NodeKubeletConfig = &container.NodeKubeletConfig{
			InsecureKubeletReadonlyPortEnabled: expandInsecureKubeletReadonlyPortEnabled(v),
			ForceSendFields:                    []string{"InsecureKubeletReadonlyPortEnabled"},
		}
	}
	if variant, ok := config["logging_variant"]; ok {
		nodeConfigDefaults.LoggingConfig = &container.NodePoolLoggingConfig{
			VariantConfig: &container.LoggingVariantConfig{
				Variant: variant.(string),
			},
		}
	}

	if v, ok := config["gcfs_config"]; ok && len(v.([]interface{})) > 0 {
		gcfsConfig := v.([]interface{})[0].(map[string]interface{})
		nodeConfigDefaults.GcfsConfig = &container.GcfsConfig{
			Enabled: gcfsConfig["enabled"].(bool),
		}
	}

	return nodeConfigDefaults
}

func expandNodeConfig(d *schema.ResourceData, prefix string, v interface{}) *container.NodeConfig {
	nodeConfigs := v.([]interface{})
	nc := &container.NodeConfig{
		// Defaults can't be set on a list/set in the schema, so set the default on create here.
		OauthScopes: defaultOauthScopes,
	}
	if len(nodeConfigs) == 0 {
		return nc
	}

	nodeConfig := nodeConfigs[0].(map[string]interface{})

	if v, ok := nodeConfig["containerd_config"]; ok {
		nc.ContainerdConfig = expandContainerdConfig(v)
	}

	if v, ok := nodeConfig["machine_type"]; ok {
		nc.MachineType = v.(string)
	}

	if v, ok := nodeConfig["guest_accelerator"]; ok {
		accels := v.([]interface{})
		guestAccelerators := make([]*container.AcceleratorConfig, 0, len(accels))
		for _, raw := range accels {
			data := raw.(map[string]interface{})
			if data["count"].(int) == 0 {
				continue
			}
			guestAcceleratorConfig := &container.AcceleratorConfig{
				AcceleratorCount: int64(data["count"].(int)),
				AcceleratorType:  data["type"].(string),
				GpuPartitionSize: data["gpu_partition_size"].(string),
			}

			if v, ok := data["gpu_driver_installation_config"]; ok && len(v.([]interface{})) > 0 {
				gpuDriverInstallationConfig := data["gpu_driver_installation_config"].([]interface{})[0].(map[string]interface{})
				guestAcceleratorConfig.GpuDriverInstallationConfig = &container.GPUDriverInstallationConfig{
					GpuDriverVersion: gpuDriverInstallationConfig["gpu_driver_version"].(string),
				}
			}

			if v, ok := data["gpu_sharing_config"]; ok && len(v.([]interface{})) > 0 {
				gpuSharingConfig := data["gpu_sharing_config"].([]interface{})[0].(map[string]interface{})
				guestAcceleratorConfig.GpuSharingConfig = &container.GPUSharingConfig{
					GpuSharingStrategy:     gpuSharingConfig["gpu_sharing_strategy"].(string),
					MaxSharedClientsPerGpu: int64(gpuSharingConfig["max_shared_clients_per_gpu"].(int)),
				}
			}

			guestAccelerators = append(guestAccelerators, guestAcceleratorConfig)
		}
		nc.Accelerators = guestAccelerators
	}

	if v, ok := nodeConfig["disk_size_gb"]; ok {
		nc.DiskSizeGb = int64(v.(int))
	}

	if v, ok := nodeConfig["disk_type"]; ok {
		nc.DiskType = v.(string)
	}

	if v, ok := nodeConfig["boot_disk"]; ok {
		nc.BootDisk = expandBootDiskConfig(v)
	}

	if v, ok := nodeConfig["local_ssd_count"]; ok {
		nc.LocalSsdCount = int64(v.(int))
	}

	if v, ok := nodeConfig["logging_variant"]; ok {
		nc.LoggingConfig = &container.NodePoolLoggingConfig{
			VariantConfig: &container.LoggingVariantConfig{
				Variant: v.(string),
			},
		}
	}

	if v, ok := nodeConfig["local_nvme_ssd_block_config"]; ok && len(v.([]interface{})) > 0 {
		conf := v.([]interface{})[0].(map[string]interface{})
		nc.LocalNvmeSsdBlockConfig = &container.LocalNvmeSsdBlockConfig{
			LocalSsdCount: int64(conf["local_ssd_count"].(int)),
		}
	}

	if v, ok := nodeConfig["ephemeral_storage_local_ssd_config"]; ok && len(v.([]interface{})) > 0 {
		conf := v.([]interface{})[0].(map[string]interface{})
		nc.EphemeralStorageLocalSsdConfig = &container.EphemeralStorageLocalSsdConfig{
			LocalSsdCount: int64(conf["local_ssd_count"].(int)),
		}
		dataCacheCount, ok := conf["data_cache_count"]
		if ok {
			nc.EphemeralStorageLocalSsdConfig.DataCacheCount = int64(dataCacheCount.(int))
		}

	}

	if v, ok := nodeConfig["secondary_boot_disks"]; ok && len(v.([]interface{})) > 0 {
		conf, confOK := v.([]interface{})[0].(map[string]interface{})
		if confOK {
			modeValue, modeOK := conf["mode"]
			diskImage := conf["disk_image"].(string)
			if modeOK {
				nc.SecondaryBootDisks = append(nc.SecondaryBootDisks, &container.SecondaryBootDisk{
					DiskImage: diskImage,
					Mode:      modeValue.(string),
				})
			} else {
				nc.SecondaryBootDisks = append(nc.SecondaryBootDisks, &container.SecondaryBootDisk{
					DiskImage: diskImage,
				})
			}
		} else {
			nc.SecondaryBootDisks = append(nc.SecondaryBootDisks, &container.SecondaryBootDisk{
				DiskImage: "",
			})
		}
	}

	if v, ok := nodeConfig["gcfs_config"]; ok && len(v.([]interface{})) > 0 {
		conf := v.([]interface{})[0].(map[string]interface{})
		nc.GcfsConfig = &container.GcfsConfig{
			Enabled: conf["enabled"].(bool),
		}
	}

	if v, ok := nodeConfig["gvnic"]; ok && len(v.([]interface{})) > 0 {
		conf := v.([]interface{})[0].(map[string]interface{})
		nc.Gvnic = &container.VirtualNIC{
			Enabled: conf["enabled"].(bool),
		}
	}

	if v, ok := nodeConfig["fast_socket"]; ok && len(v.([]interface{})) > 0 {
		conf := v.([]interface{})[0].(map[string]interface{})
		nc.FastSocket = &container.FastSocket{
			Enabled: conf["enabled"].(bool),
		}
	}

	if v, ok := nodeConfig["reservation_affinity"]; ok && len(v.([]interface{})) > 0 {
		conf := v.([]interface{})[0].(map[string]interface{})
		valuesSet := conf["values"].(*schema.Set)
		values := make([]string, valuesSet.Len())
		for i, value := range valuesSet.List() {
			values[i] = value.(string)
		}

		nc.ReservationAffinity = &container.ReservationAffinity{
			ConsumeReservationType: conf["consume_reservation_type"].(string),
			Key:                    conf["key"].(string),
			Values:                 values,
		}
	}

	if scopes, ok := nodeConfig["oauth_scopes"]; ok {
		scopesSet := scopes.(*schema.Set)
		scopes := make([]string, scopesSet.Len())
		for i, scope := range scopesSet.List() {
			scopes[i] = tpgresource.CanonicalizeServiceScope(scope.(string))
		}

		nc.OauthScopes = scopes
	}

	if v, ok := nodeConfig["service_account"]; ok {
		nc.ServiceAccount = v.(string)
	}

	if v, ok := nodeConfig["metadata"]; ok {
		m := make(map[string]string)
		for k, val := range v.(map[string]interface{}) {
			m[k] = val.(string)
		}
		nc.Metadata = m
	}

	if v, ok := nodeConfig["image_type"]; ok {
		nc.ImageType = v.(string)
	}

	if v, ok := nodeConfig["labels"]; ok {
		m := make(map[string]string)
		for k, val := range v.(map[string]interface{}) {
			m[k] = val.(string)
		}
		nc.Labels = m
	}

	if v, ok := nodeConfig["resource_labels"]; ok {
		m := make(map[string]string)
		for k, val := range v.(map[string]interface{}) {
			m[k] = val.(string)
		}
		nc.ResourceLabels = m
	}

	if v, ok := nodeConfig["resource_manager_tags"]; ok && len(v.(map[string]interface{})) > 0 {
		nc.ResourceManagerTags = expandResourceManagerTags(v)
	}

	if v, ok := nodeConfig["tags"]; ok {
		tagsList := v.([]interface{})
		tags := []string{}
		for _, v := range tagsList {
			if v != nil {
				tags = append(tags, v.(string))
			}
		}
		nc.Tags = tags
	}

	if v, ok := nodeConfig["storage_pools"]; ok {
		spList := v.([]interface{})
		storagePools := []string{}
		for _, v := range spList {
			if v != nil {
				storagePools = append(storagePools, v.(string))
			}
		}
		nc.StoragePools = storagePools
	}
	if v, ok := nodeConfig["shielded_instance_config"]; ok && len(v.([]interface{})) > 0 {
		conf := v.([]interface{})[0].(map[string]interface{})
		nc.ShieldedInstanceConfig = &container.ShieldedInstanceConfig{
			EnableSecureBoot:          conf["enable_secure_boot"].(bool),
			EnableIntegrityMonitoring: conf["enable_integrity_monitoring"].(bool),
		}
	}

	// Preemptible Is Optional+Default, so it always has a value
	nc.Preemptible = nodeConfig["preemptible"].(bool)

	// Spot Is Optional+Default, so it always has a value
	nc.Spot = nodeConfig["spot"].(bool)

	if v, ok := nodeConfig["min_cpu_platform"]; ok {
		nc.MinCpuPlatform = v.(string)
	}

	if v, ok := nodeConfig["taint"]; ok && len(v.([]interface{})) > 0 {
		taints := v.([]interface{})
		nodeTaints := make([]*container.NodeTaint, 0, len(taints))
		for _, raw := range taints {
			data := raw.(map[string]interface{})
			taint := &container.NodeTaint{
				Key:    data["key"].(string),
				Value:  data["value"].(string),
				Effect: data["effect"].(string),
			}

			nodeTaints = append(nodeTaints, taint)
		}

		nc.Taints = nodeTaints
	}

	if v, ok := nodeConfig["workload_metadata_config"]; ok {
		nc.WorkloadMetadataConfig = expandWorkloadMetadataConfig(v)
	}

	if v, ok := nodeConfig["boot_disk_kms_key"]; ok {
		nc.BootDiskKmsKey = v.(string)
	}

	if v, ok := nodeConfig["kubelet_config"]; ok {
		nc.KubeletConfig = expandKubeletConfig(v)

		// start cpu_cfs_quota fix https://github.com/hashicorp/terraform-provider-google/issues/15767
		// this makes the field conditional on appearance in configuration. This allows the API `true` default
		// to override null, where currently we force-send null as false, which is wrong.
		rawConfigNPRoot := d.GetRawConfig()
		// if we have a prefix, we're in `node_pool.N.` in GKE Cluster. Traverse the RawConfig object to reach that
		// root, at which point local references work going forwards.
		if prefix != "" {
			parts := strings.Split(prefix, ".") // "node_pool.N." -> ["node_pool" "N", ""]
			npIndex, err := strconv.Atoi(parts[1])
			if err != nil { // no error return from expander
				panic(fmt.Errorf("unexpected format for node pool path prefix: %w. value: %v", err, prefix))
			}

			rawConfigNPRoot = rawConfigNPRoot.GetAttr("node_pool").Index(cty.NumberIntVal(int64(npIndex)))
		}

		if vNC := rawConfigNPRoot.GetAttr("node_config"); vNC.LengthInt() > 0 {
			if vKC := vNC.Index(cty.NumberIntVal(0)).GetAttr("kubelet_config"); vKC.LengthInt() > 0 {
				v := vKC.Index(cty.NumberIntVal(0)).GetAttr("cpu_cfs_quota")
				if v == cty.NullVal(cty.Bool) {
					nc.KubeletConfig.CpuCfsQuota = true
				} else if v.False() { // force-send explicit false to API
					nc.KubeletConfig.ForceSendFields = append(nc.KubeletConfig.ForceSendFields, "CpuCfsQuota")
				}
			}
		}
		// end cpu_cfs_quota fix
	}

	if v, ok := nodeConfig["linux_node_config"]; ok {
		nc.LinuxNodeConfig = expandLinuxNodeConfig(v)
	}

	if v, ok := nodeConfig["windows_node_config"]; ok {
		nc.WindowsNodeConfig = expandWindowsNodeConfig(v)
	}

	if v, ok := nodeConfig["node_group"]; ok {
		nc.NodeGroup = v.(string)
	}

	if v, ok := nodeConfig["advanced_machine_features"]; ok && len(v.([]interface{})) > 0 {
		advanced_machine_features := v.([]interface{})[0].(map[string]interface{})
		nc.AdvancedMachineFeatures = &container.AdvancedMachineFeatures{
			ThreadsPerCore:             int64(advanced_machine_features["threads_per_core"].(int)),
			EnableNestedVirtualization: advanced_machine_features["enable_nested_virtualization"].(bool),
			PerformanceMonitoringUnit:  advanced_machine_features["performance_monitoring_unit"].(string),
		}
	}

	if v, ok := nodeConfig["sole_tenant_config"]; ok && len(v.([]interface{})) > 0 {
		nc.SoleTenantConfig = expandSoleTenantConfig(v)
	}

	if v, ok := nodeConfig["enable_confidential_storage"]; ok {
		nc.EnableConfidentialStorage = v.(bool)
	}

	if v, ok := nodeConfig["local_ssd_encryption_mode"]; ok {
		nc.LocalSsdEncryptionMode = v.(string)
	}

	if v, ok := nodeConfig["max_run_duration"]; ok {
		nc.MaxRunDuration = v.(string)
	}

	if v, ok := nodeConfig["flex_start"]; ok {
		nc.FlexStart = v.(bool)
	}

	if v, ok := nodeConfig["confidential_nodes"]; ok {
		nc.ConfidentialNodes = expandConfidentialNodes(v)
	}

	return nc
}

func expandBootDiskConfig(v interface{}) *container.BootDisk {
	bd := &container.BootDisk{}
	if v == nil {
		return nil
	}
	ls := v.([]interface{})
	if len(ls) == 0 {
		return nil
	}
	cfg := ls[0].(map[string]interface{})

	if v, ok := cfg["disk_type"]; ok {
		bd.DiskType = v.(string)
	}

	if v, ok := cfg["size_gb"]; ok {
		bd.SizeGb = int64(v.(int))
	}

	if v, ok := cfg["provisioned_iops"]; ok {
		bd.ProvisionedIops = int64(v.(int))
	}

	if v, ok := cfg["provisioned_throughput"]; ok {
		bd.ProvisionedThroughput = int64(v.(int))
	}

	return bd
}

func expandResourceManagerTags(v interface{}) *container.ResourceManagerTags {
	if v == nil {
		return nil
	}

	rmts := make(map[string]string)

	if v != nil {
		rmts = tpgresource.ConvertStringMap(v.(map[string]interface{}))
	}

	return &container.ResourceManagerTags{
		Tags:            rmts,
		ForceSendFields: []string{"Tags"},
	}
}

func expandWorkloadMetadataConfig(v interface{}) *container.WorkloadMetadataConfig {
	if v == nil {
		return nil
	}
	ls := v.([]interface{})
	if len(ls) == 0 {
		return nil
	}
	wmc := &container.WorkloadMetadataConfig{}

	cfg := ls[0].(map[string]interface{})

	if v, ok := cfg["mode"]; ok {
		wmc.Mode = v.(string)
	}

	return wmc
}

func expandInsecureKubeletReadonlyPortEnabled(v interface{}) bool {
	if v == "TRUE" {
		return true
	}
	return false
}

func expandKubeletConfig(v interface{}) *container.NodeKubeletConfig {
	if v == nil {
		return nil
	}
	ls := v.([]interface{})
	if len(ls) == 0 {
		return nil
	}
	cfg := ls[0].(map[string]interface{})
	kConfig := &container.NodeKubeletConfig{}
	if cpuManagerPolicy, ok := cfg["cpu_manager_policy"]; ok {
		kConfig.CpuManagerPolicy = cpuManagerPolicy.(string)
	}
	if cpuCfsQuota, ok := cfg["cpu_cfs_quota"]; ok {
		kConfig.CpuCfsQuota = cpuCfsQuota.(bool)
	}
	if cpuCfsQuotaPeriod, ok := cfg["cpu_cfs_quota_period"]; ok {
		kConfig.CpuCfsQuotaPeriod = cpuCfsQuotaPeriod.(string)
	}
	if insecureKubeletReadonlyPortEnabled, ok := cfg["insecure_kubelet_readonly_port_enabled"]; ok {
		kConfig.InsecureKubeletReadonlyPortEnabled = expandInsecureKubeletReadonlyPortEnabled(insecureKubeletReadonlyPortEnabled)
		kConfig.ForceSendFields = append(kConfig.ForceSendFields, "InsecureKubeletReadonlyPortEnabled")
	}
	if podPidsLimit, ok := cfg["pod_pids_limit"]; ok {
		kConfig.PodPidsLimit = int64(podPidsLimit.(int))
	}
	if maxParallelImagePulls, ok := cfg["max_parallel_image_pulls"]; ok {
		kConfig.MaxParallelImagePulls = int64(maxParallelImagePulls.(int))
	}
	if containerLogMaxSize, ok := cfg["container_log_max_size"]; ok {
		kConfig.ContainerLogMaxSize = containerLogMaxSize.(string)
	}
	if containerLogMaxFiles, ok := cfg["container_log_max_files"]; ok {
		kConfig.ContainerLogMaxFiles = int64(containerLogMaxFiles.(int))
	}
	if imageGcLowThresholdPercent, ok := cfg["image_gc_low_threshold_percent"]; ok {
		kConfig.ImageGcLowThresholdPercent = int64(imageGcLowThresholdPercent.(int))
	}
	if imageGcHighThresholdPercent, ok := cfg["image_gc_high_threshold_percent"]; ok {
		kConfig.ImageGcHighThresholdPercent = int64(imageGcHighThresholdPercent.(int))
	}
	if imageMinimumGcAge, ok := cfg["image_minimum_gc_age"]; ok {
		kConfig.ImageMinimumGcAge = imageMinimumGcAge.(string)
	}
	if imageMaximumGcAge, ok := cfg["image_maximum_gc_age"]; ok {
		kConfig.ImageMaximumGcAge = imageMaximumGcAge.(string)
	}
	if allowedUnsafeSysctls, ok := cfg["allowed_unsafe_sysctls"]; ok {
		sysctls := allowedUnsafeSysctls.([]interface{})
		kConfig.AllowedUnsafeSysctls = make([]string, len(sysctls))
		for i, s := range sysctls {
			kConfig.AllowedUnsafeSysctls[i] = s.(string)
		}
	}
	if singleProcessOomKill, ok := cfg["single_process_oom_kill"]; ok {
		kConfig.SingleProcessOomKill = singleProcessOomKill.(bool)
	}
	if evictionMaxPodGracePeriodSeconds, ok := cfg["eviction_max_pod_grace_period_seconds"]; ok {
		kConfig.EvictionMaxPodGracePeriodSeconds = int64(evictionMaxPodGracePeriodSeconds.(int))
	}
	if v, ok := cfg["eviction_soft"]; ok && len(v.([]interface{})) > 0 {
		es := v.([]interface{})[0].(map[string]interface{})
		evictionSoft := &container.EvictionSignals{}
		if val, ok := es["memory_available"]; ok {
			evictionSoft.MemoryAvailable = val.(string)
		}
		if val, ok := es["nodefs_available"]; ok {
			evictionSoft.NodefsAvailable = val.(string)
		}
		if val, ok := es["imagefs_available"]; ok {
			evictionSoft.ImagefsAvailable = val.(string)
		}
		if val, ok := es["imagefs_inodes_free"]; ok {
			evictionSoft.ImagefsInodesFree = val.(string)
		}
		if val, ok := es["nodefs_inodes_free"]; ok {
			evictionSoft.NodefsInodesFree = val.(string)
		}
		if val, ok := es["pid_available"]; ok {
			evictionSoft.PidAvailable = val.(string)
		}
		kConfig.EvictionSoft = evictionSoft
	}

	if v, ok := cfg["memory_manager"]; ok {
		kConfig.MemoryManager = expandMemoryManager(v)
	}
	if v, ok := cfg["topology_manager"]; ok {
		kConfig.TopologyManager = expandTopologyManager(v)
	}

	if v, ok := cfg["eviction_soft_grace_period"]; ok && len(v.([]interface{})) > 0 {
		es := v.([]interface{})[0].(map[string]interface{})
		periods := &container.EvictionGracePeriod{}
		if val, ok := es["memory_available"]; ok {
			periods.MemoryAvailable = val.(string)
		}
		if val, ok := es["nodefs_available"]; ok {
			periods.NodefsAvailable = val.(string)
		}
		if val, ok := es["imagefs_available"]; ok {
			periods.ImagefsAvailable = val.(string)
		}
		if val, ok := es["imagefs_inodes_free"]; ok {
			periods.ImagefsInodesFree = val.(string)
		}
		if val, ok := es["nodefs_inodes_free"]; ok {
			periods.NodefsInodesFree = val.(string)
		}
		if val, ok := es["pid_available"]; ok {
			periods.PidAvailable = val.(string)
		}
		kConfig.EvictionSoftGracePeriod = periods
	}
	if v, ok := cfg["eviction_minimum_reclaim"]; ok && len(v.([]interface{})) > 0 {
		es := v.([]interface{})[0].(map[string]interface{})
		reclaim := &container.EvictionMinimumReclaim{}
		if val, ok := es["memory_available"]; ok {
			reclaim.MemoryAvailable = val.(string)
		}
		if val, ok := es["nodefs_available"]; ok {
			reclaim.NodefsAvailable = val.(string)
		}
		if val, ok := es["imagefs_available"]; ok {
			reclaim.ImagefsAvailable = val.(string)
		}
		if val, ok := es["imagefs_inodes_free"]; ok {
			reclaim.ImagefsInodesFree = val.(string)
		}
		if val, ok := es["nodefs_inodes_free"]; ok {
			reclaim.NodefsInodesFree = val.(string)
		}
		if val, ok := es["pid_available"]; ok {
			reclaim.PidAvailable = val.(string)
		}
		kConfig.EvictionMinimumReclaim = reclaim
	}
	return kConfig
}

func expandTopologyManager(v interface{}) *container.TopologyManager {
	if v == nil {
		return nil
	}
	ls := v.([]interface{})
	if len(ls) == 0 {
		return nil
	}
	if ls[0] == nil {
		return &container.TopologyManager{}
	}
	cfg := ls[0].(map[string]interface{})

	topologyManager := &container.TopologyManager{}

	if v, ok := cfg["policy"]; ok {
		topologyManager.Policy = v.(string)
	}

	if v, ok := cfg["scope"]; ok {
		topologyManager.Scope = v.(string)
	}

	return topologyManager
}

func expandMemoryManager(v interface{}) *container.MemoryManager {
	if v == nil {
		return nil
	}
	ls := v.([]interface{})
	if len(ls) == 0 {
		return nil
	}
	if ls[0] == nil {
		return &container.MemoryManager{}
	}
	cfg := ls[0].(map[string]interface{})

	memoryManager := &container.MemoryManager{}

	if v, ok := cfg["policy"]; ok {
		memoryManager.Policy = v.(string)
	}

	return memoryManager
}

func expandLinuxNodeConfig(v interface{}) *container.LinuxNodeConfig {
	if v == nil {
		return nil
	}
	ls := v.([]interface{})
	if len(ls) == 0 {
		return nil
	}
	if ls[0] == nil {
		return &container.LinuxNodeConfig{}
	}
	cfg := ls[0].(map[string]interface{})

	linuxNodeConfig := &container.LinuxNodeConfig{}
	sysctls := expandSysctls(cfg)
	if sysctls != nil {
		linuxNodeConfig.Sysctls = sysctls
	}
	cgroupMode := expandCgroupMode(cfg)
	if len(cgroupMode) != 0 {
		linuxNodeConfig.CgroupMode = cgroupMode
	}

	if v, ok := cfg["transparent_hugepage_enabled"]; ok {
		linuxNodeConfig.TransparentHugepageEnabled = v.(string)
	}
	if v, ok := cfg["transparent_hugepage_defrag"]; ok {
		linuxNodeConfig.TransparentHugepageDefrag = v.(string)
	}

	if v, ok := cfg["hugepages_config"]; ok {
		linuxNodeConfig.Hugepages = expandHugepagesConfig(v)
	}

	if v, ok := cfg["node_kernel_module_loading"]; ok {
		linuxNodeConfig.NodeKernelModuleLoading = expandNodeKernelModuleLoading(v)
	}

	return linuxNodeConfig
}

func expandWindowsNodeConfig(v interface{}) *container.WindowsNodeConfig {
	if v == nil {
		return nil
	}
	ls := v.([]interface{})
	if len(ls) == 0 {
		return nil
	}
	cfg := ls[0].(map[string]interface{})
	osversionRaw, ok := cfg["osversion"]
	if !ok {
		return nil
	}
	return &container.WindowsNodeConfig{
		OsVersion: osversionRaw.(string),
	}
}

func expandSysctls(cfg map[string]interface{}) map[string]string {
	sysCfgRaw, ok := cfg["sysctls"]
	if !ok {
		return nil
	}
	sysctls := make(map[string]string)
	for k, v := range sysCfgRaw.(map[string]interface{}) {
		sysctls[k] = v.(string)
	}
	return sysctls
}

func expandCgroupMode(cfg map[string]interface{}) string {
	cgroupMode, ok := cfg["cgroup_mode"]
	if !ok {
		return ""
	}

	return cgroupMode.(string)
}

func expandHugepagesConfig(v interface{}) *container.HugepagesConfig {
	if v == nil {
		return nil
	}
	ls := v.([]interface{})
	if len(ls) == 0 {
		return nil
	}
	if ls[0] == nil {
		return &container.HugepagesConfig{}
	}
	cfg := ls[0].(map[string]interface{})

	hugepagesConfig := &container.HugepagesConfig{}

	if v, ok := cfg["hugepage_size_2m"]; ok {
		hugepagesConfig.HugepageSize2m = int64(v.(int))
	}

	if v, ok := cfg["hugepage_size_1g"]; ok {
		hugepagesConfig.HugepageSize1g = int64(v.(int))
	}

	return hugepagesConfig
}

func expandNodeKernelModuleLoading(v interface{}) *container.NodeKernelModuleLoading {
	if v == nil {
		return nil
	}
	ls := v.([]interface{})
	if len(ls) == 0 {
		return nil
	}
	if ls[0] == nil {
		return &container.NodeKernelModuleLoading{}
	}
	cfg := ls[0].(map[string]interface{})

	NodeKernelModuleLoading := &container.NodeKernelModuleLoading{}

	if v, ok := cfg["policy"]; ok {
		NodeKernelModuleLoading.Policy = v.(string)
	}

	return NodeKernelModuleLoading
}

func expandContainerdConfig(v interface{}) *container.ContainerdConfig {
	if v == nil {
		return nil
	}
	ls := v.([]interface{})
	if len(ls) == 0 {
		return nil
	}
	if ls[0] == nil {
		return &container.ContainerdConfig{}
	}
	cfg := ls[0].(map[string]interface{})

	cc := &container.ContainerdConfig{}
	cc.PrivateRegistryAccessConfig = expandPrivateRegistryAccessConfig(cfg["private_registry_access_config"])
	cc.WritableCgroups = expandWritableCgroups(cfg["writable_cgroups"])
	cc.RegistryHosts = expandRegistryHosts(cfg["registry_hosts"])
	return cc
}

func expandPrivateRegistryAccessConfig(v interface{}) *container.PrivateRegistryAccessConfig {
	if v == nil {
		return nil
	}
	ls := v.([]interface{})
	if len(ls) == 0 {
		return nil
	}
	if ls[0] == nil {
		return &container.PrivateRegistryAccessConfig{}
	}
	cfg := ls[0].(map[string]interface{})

	pracc := &container.PrivateRegistryAccessConfig{}
	if enabled, ok := cfg["enabled"]; ok {
		pracc.Enabled = enabled.(bool)
	}
	if caCfgRaw, ok := cfg["certificate_authority_domain_config"]; ok {
		ls := caCfgRaw.([]interface{})
		pracc.CertificateAuthorityDomainConfig = make([]*container.CertificateAuthorityDomainConfig, len(ls))
		for i, caCfg := range ls {
			pracc.CertificateAuthorityDomainConfig[i] = expandCADomainConfig(caCfg)
		}
	}

	return pracc
}

func expandCADomainConfig(v interface{}) *container.CertificateAuthorityDomainConfig {
	if v == nil {
		return nil
	}
	cfg := v.(map[string]interface{})

	caConfig := &container.CertificateAuthorityDomainConfig{}
	if v, ok := cfg["fqdns"]; ok {
		fqdns := v.([]interface{})
		caConfig.Fqdns = make([]string, len(fqdns))
		for i, dn := range fqdns {
			caConfig.Fqdns[i] = dn.(string)
		}
	}

	caConfig.GcpSecretManagerCertificateConfig = expandGCPSecretManagerCertificateConfig(cfg["gcp_secret_manager_certificate_config"])

	return caConfig
}

func expandGCPSecretManagerCertificateConfig(v interface{}) *container.GCPSecretManagerCertificateConfig {
	if v == nil {
		return nil
	}
	ls := v.([]interface{})
	if len(ls) == 0 {
		return nil
	}
	if ls[0] == nil {
		return &container.GCPSecretManagerCertificateConfig{}
	}
	cfg := ls[0].(map[string]interface{})

	gcpSMConfig := &container.GCPSecretManagerCertificateConfig{}
	if v, ok := cfg["secret_uri"]; ok {
		gcpSMConfig.SecretUri = v.(string)
	}
	return gcpSMConfig
}

func expandWritableCgroups(v interface{}) *container.WritableCgroups {
	if v == nil {
		return nil
	}
	ls := v.([]interface{})
	if len(ls) == 0 {
		return nil
	}
	if ls[0] == nil {
		return &container.WritableCgroups{}
	}
	cfg := ls[0].(map[string]interface{})

	wcg := &container.WritableCgroups{}
	if enabled, ok := cfg["enabled"]; ok {
		wcg.Enabled = enabled.(bool)
	}
	return wcg
}

func expandRegistryHosts(v interface{}) []*container.RegistryHostConfig {
	if v == nil {
		return nil
	}
	ls := v.([]interface{})
	if len(ls) == 0 {
		return nil
	}
	registryHosts := make([]*container.RegistryHostConfig, 0, len(ls))
	for _, raw := range ls {
		data := raw.(map[string]interface{})
		rh := &container.RegistryHostConfig{
			Server: data["server"].(string),
		}
		if v, ok := data["hosts"]; ok {
			hosts := v.([]interface{})
			rh.Hosts = make([]*container.HostConfig, 0, len(hosts))
			for _, rawHost := range hosts {
				hostData := rawHost.(map[string]interface{})
				h := &container.HostConfig{
					Host: hostData["host"].(string),
				}
				if v, ok := hostData["override_path"]; ok {
					h.OverridePath = v.(bool)
				}
				if v, ok := hostData["dial_timeout"]; ok {
					h.DialTimeout = v.(string)
				}
				if v, ok := hostData["capabilities"]; ok {
					cap := v.([]interface{})
					h.Capabilities = make([]string, len(cap))
					for i, c := range cap {
						h.Capabilities[i] = c.(string)
					}
				}
				if v, ok := hostData["header"]; ok {
					headers := v.([]interface{})
					h.Header = make([]*container.RegistryHeader, len(headers))
					for i, headerRaw := range headers {
						h.Header[i] = expandRegistryHeader(headerRaw)
					}
				}
				if v, ok := hostData["ca"]; ok {
					ca := v.([]interface{})
					h.Ca = make([]*container.CertificateConfig, len(ca))
					for i, caRaw := range ca {
						h.Ca[i] = expandRegistryCertificateConfig(caRaw)
					}
				}
				if v, ok := hostData["client"]; ok {
					client := v.([]interface{})
					h.Client = make([]*container.CertificateConfigPair, len(client))
					for i, clientRaw := range client {
						h.Client[i] = expandRegistryCertificateConfigPair(clientRaw)
					}
				}
				rh.Hosts = append(rh.Hosts, h)
			}
		}
		registryHosts = append(registryHosts, rh)
	}
	return registryHosts
}

func expandRegistryHeader(v interface{}) *container.RegistryHeader {
	header := &container.RegistryHeader{}
	if v == nil {
		return header
	}
	ls := v.(map[string]interface{})
	if val, ok := ls["key"]; ok {
		header.Key = val.(string)
	}
	if val, ok := ls["value"]; ok {
		headerVal := val.([]interface{})
		header.Value = make([]string, len(headerVal))
		for i, hv := range headerVal {
			header.Value[i] = hv.(string)
		}
	}
	return header
}

func expandRegistryCertificateConfig(v interface{}) *container.CertificateConfig {
	cfg := &container.CertificateConfig{}
	if v == nil {
		return cfg
	}
	ls := v.(map[string]interface{})
	if val, ok := ls["gcp_secret_manager_secret_uri"]; ok {
		cfg.GcpSecretManagerSecretUri = val.(string)
	}
	return cfg
}

func expandRegistryCertificateConfigPair(v interface{}) *container.CertificateConfigPair {
	cfg := &container.CertificateConfigPair{}
	if v == nil {
		return cfg
	}
	ls := v.(map[string]interface{})
	if val, ok := ls["cert"]; ok {
		certRaw := val.([]interface{})
		if len(certRaw) > 0 {
			cfg.Cert = expandRegistryCertificateConfig(certRaw[0])
		}
	}
	if val, ok := ls["key"]; ok {
		keyRaw := val.([]interface{})
		if len(keyRaw) > 0 {
			cfg.Key = expandRegistryCertificateConfig(keyRaw[0])
		}
	}
	return cfg
}

func expandSoleTenantConfig(v interface{}) *container.SoleTenantConfig {
	if v == nil {
		return nil
	}
	ls := v.([]interface{})
	if len(ls) == 0 {
		return nil
	}
	stConfig := &container.SoleTenantConfig{}
	cfg := ls[0].(map[string]interface{})
	if affinitiesRaw, ok := cfg["node_affinity"]; ok {
		affinities := make([]*container.NodeAffinity, 0)
		for _, v := range affinitiesRaw.(*schema.Set).List() {
			na := v.(map[string]interface{})
			affinities = append(affinities, &container.NodeAffinity{
				Key:      na["key"].(string),
				Operator: na["operator"].(string),
				Values:   tpgresource.ConvertStringArr(na["values"].([]interface{})),
			})
		}
		stConfig.NodeAffinities = affinities
	}
	if v, ok := cfg["min_node_cpus"]; ok {
		stConfig.MinNodeCpus = int64(v.(int))
	}
	return stConfig
}

func expandConfidentialNodes(configured interface{}) *container.ConfidentialNodes {
	l := configured.([]interface{})
	if len(l) == 0 || l[0] == nil {
		return nil
	}
	config := l[0].(map[string]interface{})
	return &container.ConfidentialNodes{
		Enabled:                  config["enabled"].(bool),
		ConfidentialInstanceType: config["confidential_instance_type"].(string),
	}
}

func flattenNodeConfigDefaults(c *container.NodeConfigDefaults) []map[string]interface{} {
	result := make([]map[string]interface{}, 0, 1)

	if c == nil {
		return result
	}

	result = append(result, map[string]interface{}{})

	result[0]["containerd_config"] = flattenContainerdConfig(c.ContainerdConfig)

	result[0]["insecure_kubelet_readonly_port_enabled"] = flattenInsecureKubeletReadonlyPortEnabled(c.NodeKubeletConfig)

	result[0]["logging_variant"] = flattenLoggingVariant(c.LoggingConfig)

	result[0]["gcfs_config"] = flattenGcfsConfig(c.GcfsConfig)

	return result
}

// v == old state of `node_config`
func flattenNodeConfig(c *container.NodeConfig, v interface{}) []map[string]interface{} {
	config := make([]map[string]interface{}, 0, 1)

	if c == nil {
		return config
	}

	// default to no prior taint state if there are any issues
	oldTaints := []interface{}{}
	oldNodeConfigSchemaContainer := v.([]interface{})
	if len(oldNodeConfigSchemaContainer) != 0 {
		oldNodeConfigSchema := oldNodeConfigSchemaContainer[0].(map[string]interface{})
		if vt, ok := oldNodeConfigSchema["taint"]; ok && len(vt.([]interface{})) > 0 {
			oldTaints = vt.([]interface{})
		}
	}

	config = append(config, map[string]interface{}{
		"machine_type":                       c.MachineType,
		"containerd_config":                  flattenContainerdConfig(c.ContainerdConfig),
		"disk_size_gb":                       c.DiskSizeGb,
		"disk_type":                          c.DiskType,
		"boot_disk":                          flattenBootDiskConfig(c.BootDisk),
		"guest_accelerator":                  flattenContainerGuestAccelerators(c.Accelerators),
		"local_ssd_count":                    c.LocalSsdCount,
		"logging_variant":                    flattenLoggingVariant(c.LoggingConfig),
		"local_nvme_ssd_block_config":        flattenLocalNvmeSsdBlockConfig(c.LocalNvmeSsdBlockConfig),
		"ephemeral_storage_local_ssd_config": flattenEphemeralStorageLocalSsdConfig(c.EphemeralStorageLocalSsdConfig),
		"gcfs_config":                        flattenGcfsConfig(c.GcfsConfig),
		"gvnic":                              flattenGvnic(c.Gvnic),
		"reservation_affinity":               flattenGKEReservationAffinity(c.ReservationAffinity),
		"service_account":                    c.ServiceAccount,
		"metadata":                           c.Metadata,
		"image_type":                         c.ImageType,
		"labels":                             c.Labels,
		"resource_labels":                    c.ResourceLabels,
		"tags":                               c.Tags,
		"preemptible":                        c.Preemptible,
		"secondary_boot_disks":               flattenSecondaryBootDisks(c.SecondaryBootDisks),
		"storage_pools":                      c.StoragePools,
		"spot":                               c.Spot,
		"min_cpu_platform":                   c.MinCpuPlatform,
		"shielded_instance_config":           flattenShieldedInstanceConfig(c.ShieldedInstanceConfig),
		"taint":                              flattenTaints(c.Taints, oldTaints),
		"effective_taints":                   flattenEffectiveTaints(c.Taints),
		"workload_metadata_config":           flattenWorkloadMetadataConfig(c.WorkloadMetadataConfig),
		"confidential_nodes":                 flattenConfidentialNodes(c.ConfidentialNodes),
		"boot_disk_kms_key":                  c.BootDiskKmsKey,
		"kubelet_config":                     flattenKubeletConfig(c.KubeletConfig),
		"linux_node_config":                  flattenLinuxNodeConfig(c.LinuxNodeConfig),
		"windows_node_config":                flattenWindowsNodeConfig(c.WindowsNodeConfig),
		"node_group":                         c.NodeGroup,
		"advanced_machine_features":          flattenAdvancedMachineFeaturesConfig(c.AdvancedMachineFeatures),
		"max_run_duration":                   c.MaxRunDuration,
		"flex_start":                         c.FlexStart,
		"sole_tenant_config":                 flattenSoleTenantConfig(c.SoleTenantConfig),
		"fast_socket":                        flattenFastSocket(c.FastSocket),
		"resource_manager_tags":              flattenResourceManagerTags(c.ResourceManagerTags),
		"enable_confidential_storage":        c.EnableConfidentialStorage,
		"local_ssd_encryption_mode":          c.LocalSsdEncryptionMode,
	})

	if len(c.OauthScopes) > 0 {
		config[0]["oauth_scopes"] = schema.NewSet(tpgresource.StringScopeHashcode, tpgresource.ConvertStringArrToInterface(c.OauthScopes))
	}

	return config
}

func flattenBootDiskConfig(c *container.BootDisk) []map[string]interface{} {
	config := []map[string]interface{}{}

	if c == nil {
		return config
	}

	config = append(config, map[string]interface{}{
		"disk_type":              c.DiskType,
		"size_gb":                c.SizeGb,
		"provisioned_iops":       c.ProvisionedIops,
		"provisioned_throughput": c.ProvisionedThroughput,
	})

	return config
}

func flattenResourceManagerTags(c *container.ResourceManagerTags) map[string]interface{} {
	if c == nil {
		return nil
	}

	rmt := make(map[string]interface{})

	for k, v := range c.Tags {
		rmt[k] = v
	}

	return rmt
}

func flattenAdvancedMachineFeaturesConfig(c *container.AdvancedMachineFeatures) []map[string]interface{} {
	result := []map[string]interface{}{}
	if c != nil {
		result = append(result, map[string]interface{}{
			"threads_per_core":             c.ThreadsPerCore,
			"enable_nested_virtualization": c.EnableNestedVirtualization,
			"performance_monitoring_unit":  c.PerformanceMonitoringUnit,
		})
	}
	return result
}

func flattenContainerGuestAccelerators(c []*container.AcceleratorConfig) []map[string]interface{} {
	result := []map[string]interface{}{}
	for _, accel := range c {
		accelerator := map[string]interface{}{
			"count":              accel.AcceleratorCount,
			"type":               accel.AcceleratorType,
			"gpu_partition_size": accel.GpuPartitionSize,
		}
		if accel.GpuDriverInstallationConfig != nil {
			accelerator["gpu_driver_installation_config"] = []map[string]interface{}{
				{
					"gpu_driver_version": accel.GpuDriverInstallationConfig.GpuDriverVersion,
				},
			}
		}
		if accel.GpuSharingConfig != nil {
			accelerator["gpu_sharing_config"] = []map[string]interface{}{
				{
					"gpu_sharing_strategy":       accel.GpuSharingConfig.GpuSharingStrategy,
					"max_shared_clients_per_gpu": accel.GpuSharingConfig.MaxSharedClientsPerGpu,
				},
			}
		}
		result = append(result, accelerator)
	}
	return result
}

func flattenShieldedInstanceConfig(c *container.ShieldedInstanceConfig) []map[string]interface{} {
	result := []map[string]interface{}{}
	if c != nil {
		result = append(result, map[string]interface{}{
			"enable_secure_boot":          c.EnableSecureBoot,
			"enable_integrity_monitoring": c.EnableIntegrityMonitoring,
		})
	}
	return result
}

func flattenLocalNvmeSsdBlockConfig(c *container.LocalNvmeSsdBlockConfig) []map[string]interface{} {
	result := []map[string]interface{}{}
	if c != nil {
		result = append(result, map[string]interface{}{
			"local_ssd_count": c.LocalSsdCount,
		})
	}
	return result
}

func flattenEphemeralStorageLocalSsdConfig(c *container.EphemeralStorageLocalSsdConfig) []map[string]interface{} {
	result := []map[string]interface{}{}
	if c != nil {
		result = append(result, map[string]interface{}{
			"local_ssd_count":  c.LocalSsdCount,
			"data_cache_count": c.DataCacheCount,
		})
	}
	return result
}

func flattenSecondaryBootDisks(c []*container.SecondaryBootDisk) []map[string]interface{} {
	result := []map[string]interface{}{}
	if c != nil {
		for _, disk := range c {
			secondaryBootDisk := map[string]interface{}{
				"disk_image": disk.DiskImage,
				"mode":       disk.Mode,
			}
			result = append(result, secondaryBootDisk)
		}
	}
	return result
}

func flattenInsecureKubeletReadonlyPortEnabled(c *container.NodeKubeletConfig) string {
	// Convert bool from the API to the enum values used internally
	if c != nil && c.InsecureKubeletReadonlyPortEnabled {
		return "TRUE"
	}
	return "FALSE"
}

func flattenLoggingVariant(c *container.NodePoolLoggingConfig) string {
	variant := "DEFAULT"
	if c != nil && c.VariantConfig != nil && c.VariantConfig.Variant != "" {
		variant = c.VariantConfig.Variant
	}
	return variant
}

func flattenGcfsConfig(c *container.GcfsConfig) []map[string]interface{} {
	result := []map[string]interface{}{}
	if c != nil {
		result = append(result, map[string]interface{}{
			"enabled": c.Enabled,
		})
	}
	return result
}

func flattenGvnic(c *container.VirtualNIC) []map[string]interface{} {
	result := []map[string]interface{}{}
	if c != nil {
		result = append(result, map[string]interface{}{
			"enabled": c.Enabled,
		})
	}
	return result
}

func flattenGKEReservationAffinity(c *container.ReservationAffinity) []map[string]interface{} {
	result := []map[string]interface{}{}
	if c != nil {
		result = append(result, map[string]interface{}{
			"consume_reservation_type": c.ConsumeReservationType,
			"key":                      c.Key,
			"values":                   c.Values,
		})
	}
	return result
}

// flattenTaints records the set of taints already present in state.
func flattenTaints(c []*container.NodeTaint, oldTaints []interface{}) []map[string]interface{} {
	taintKeys := map[string]struct{}{}
	for _, raw := range oldTaints {
		data := raw.(map[string]interface{})
		taintKey := data["key"].(string)
		taintKeys[taintKey] = struct{}{}
	}

	result := []map[string]interface{}{}
	for _, taint := range c {
		if _, ok := taintKeys[taint.Key]; ok {
			result = append(result, map[string]interface{}{
				"key":    taint.Key,
				"value":  taint.Value,
				"effect": taint.Effect,
			})
		}
	}

	return result
}

// flattenEffectiveTaints records the complete set of taints returned from GKE.
func flattenEffectiveTaints(c []*container.NodeTaint) []map[string]interface{} {
	result := []map[string]interface{}{}
	for _, taint := range c {
		result = append(result, map[string]interface{}{
			"key":    taint.Key,
			"value":  taint.Value,
			"effect": taint.Effect,
		})
	}

	return result
}

func flattenWorkloadMetadataConfig(c *container.WorkloadMetadataConfig) []map[string]interface{} {
	result := []map[string]interface{}{}
	if c != nil {
		result = append(result, map[string]interface{}{
			"mode": c.Mode,
		})
	}
	return result
}

func containerNodePoolResourceLabelsDiffSuppress(k, old, new string, d *schema.ResourceData) bool {
	// Suppress diffs for server-specified labels prefixed with "goog-gke"
	if strings.Contains(k, "resource_labels.goog-gke") && new == "" {
		return true
	}

	// Let diff be determined by resource_labels (above)
	if strings.Contains(k, "resource_labels.%") {
		return true
	}

	// For other keys, don't suppress diff.
	return false
}

func flattenKubeletConfig(c *container.NodeKubeletConfig) []map[string]interface{} {
	result := []map[string]interface{}{}
	if c != nil {
		result = append(result, map[string]interface{}{
			"cpu_cfs_quota":                          c.CpuCfsQuota,
			"cpu_cfs_quota_period":                   c.CpuCfsQuotaPeriod,
			"cpu_manager_policy":                     c.CpuManagerPolicy,
			"memory_manager":                         flattenMemoryManager(c.MemoryManager),
			"topology_manager":                       flattenTopologyManager(c.TopologyManager),
			"insecure_kubelet_readonly_port_enabled": flattenInsecureKubeletReadonlyPortEnabled(c),
			"pod_pids_limit":                         c.PodPidsLimit,
			"container_log_max_size":                 c.ContainerLogMaxSize,
			"container_log_max_files":                c.ContainerLogMaxFiles,
			"image_gc_low_threshold_percent":         c.ImageGcLowThresholdPercent,
			"image_gc_high_threshold_percent":        c.ImageGcHighThresholdPercent,
			"image_minimum_gc_age":                   c.ImageMinimumGcAge,
			"image_maximum_gc_age":                   c.ImageMaximumGcAge,
			"allowed_unsafe_sysctls":                 c.AllowedUnsafeSysctls,
			"single_process_oom_kill":                c.SingleProcessOomKill,
			"max_parallel_image_pulls":               c.MaxParallelImagePulls,
			"eviction_max_pod_grace_period_seconds":  c.EvictionMaxPodGracePeriodSeconds,
			"eviction_soft":                          flattenEvictionSignals(c.EvictionSoft),
			"eviction_soft_grace_period":             flattenEvictionGracePeriod(c.EvictionSoftGracePeriod),
			"eviction_minimum_reclaim":               flattenEvictionMinimumReclaim(c.EvictionMinimumReclaim),
		})
	}
	return result
}

func flattenTopologyManager(c *container.TopologyManager) []map[string]interface{} {
	result := []map[string]interface{}{}
	if c != nil {
		result = append(result, map[string]interface{}{
			"policy": c.Policy,
			"scope":  c.Scope,
		})
	}
	return result
}

func flattenMemoryManager(c *container.MemoryManager) []map[string]interface{} {
	result := []map[string]interface{}{}
	if c != nil {
		result = append(result, map[string]interface{}{
			"policy": c.Policy,
		})
	}
	return result
}

func flattenNodePoolAutoConfigNodeKubeletConfig(c *container.NodeKubeletConfig) []map[string]interface{} {
	result := []map[string]interface{}{}
	if c != nil {
		result = append(result, map[string]interface{}{
			"insecure_kubelet_readonly_port_enabled": flattenInsecureKubeletReadonlyPortEnabled(c),
		})
	}
	return result
}

func flattenEvictionSignals(c *container.EvictionSignals) []map[string]interface{} {
	result := []map[string]interface{}{}
	if c != nil {
		result = append(result, map[string]interface{}{
			"memory_available":    c.MemoryAvailable,
			"nodefs_available":    c.NodefsAvailable,
			"nodefs_inodes_free":  c.NodefsInodesFree,
			"imagefs_available":   c.ImagefsAvailable,
			"imagefs_inodes_free": c.ImagefsInodesFree,
			"pid_available":       c.PidAvailable,
		})
	}
	return result
}

func flattenEvictionGracePeriod(c *container.EvictionGracePeriod) []map[string]interface{} {
	result := []map[string]interface{}{}
	if c != nil {
		result = append(result, map[string]interface{}{
			"memory_available":    c.MemoryAvailable,
			"nodefs_available":    c.NodefsAvailable,
			"nodefs_inodes_free":  c.NodefsInodesFree,
			"imagefs_available":   c.ImagefsAvailable,
			"imagefs_inodes_free": c.ImagefsInodesFree,
			"pid_available":       c.PidAvailable,
		})
	}
	return result
}

func flattenEvictionMinimumReclaim(c *container.EvictionMinimumReclaim) []map[string]interface{} {
	result := []map[string]interface{}{}
	if c != nil {
		result = append(result, map[string]interface{}{
			"memory_available":    c.MemoryAvailable,
			"nodefs_available":    c.NodefsAvailable,
			"nodefs_inodes_free":  c.NodefsInodesFree,
			"imagefs_available":   c.ImagefsAvailable,
			"imagefs_inodes_free": c.ImagefsInodesFree,
			"pid_available":       c.PidAvailable,
		})
	}
	return result
}

func flattenLinuxNodeConfig(c *container.LinuxNodeConfig) []map[string]interface{} {
	result := []map[string]interface{}{}
	if c != nil {
		result = append(result, map[string]interface{}{
			"sysctls":                      c.Sysctls,
			"cgroup_mode":                  c.CgroupMode,
			"hugepages_config":             flattenHugepagesConfig(c.Hugepages),
			"transparent_hugepage_enabled": c.TransparentHugepageEnabled,
			"transparent_hugepage_defrag":  c.TransparentHugepageDefrag,
			"node_kernel_module_loading":   flattenNodeKernelModuleLoading(c.NodeKernelModuleLoading),
		})
	}
	return result
}

func flattenWindowsNodeConfig(c *container.WindowsNodeConfig) []map[string]interface{} {
	result := []map[string]interface{}{}
	if c != nil {
		result = append(result, map[string]interface{}{
			"osversion": c.OsVersion,
		})
	}
	return result
}

func flattenHugepagesConfig(c *container.HugepagesConfig) []map[string]interface{} {
	result := []map[string]interface{}{}
	if c != nil {
		result = append(result, map[string]interface{}{
			"hugepage_size_2m": c.HugepageSize2m,
			"hugepage_size_1g": c.HugepageSize1g,
		})
	}
	return result
}

func flattenNodeKernelModuleLoading(c *container.NodeKernelModuleLoading) []map[string]interface{} {
	result := []map[string]interface{}{}
	if c != nil {
		result = append(result, map[string]interface{}{
			"policy": c.Policy,
		})
	}
	return result
}

func flattenContainerdConfig(c *container.ContainerdConfig) []map[string]interface{} {
	result := []map[string]interface{}{}
	if c == nil {
		return result
	}
	r := map[string]interface{}{}
	if c.PrivateRegistryAccessConfig != nil {
		r["private_registry_access_config"] = flattenPrivateRegistryAccessConfig(c.PrivateRegistryAccessConfig)
	}
	if c.WritableCgroups != nil {
		r["writable_cgroups"] = flattenWritableCgroups(c.WritableCgroups)
	}
	if c.RegistryHosts != nil {
		r["registry_hosts"] = flattenRegistryHosts(c.RegistryHosts)
	}
	return append(result, r)
}

func flattenRegistryHosts(registryHosts []*container.RegistryHostConfig) []map[string]interface{} {
	items := []map[string]interface{}{}
	if len(registryHosts) == 0 {
		return items
	}

	for _, host := range registryHosts {
		item := make(map[string]interface{})
		item["server"] = host.Server
		item["hosts"] = flattenHostInRegistryHosts(host.Hosts)
		items = append(items, item)
	}
	return items
}

func flattenHostInRegistryHosts(hosts []*container.HostConfig) []map[string]interface{} {
	items := make([]map[string]interface{}, 0, len(hosts))
	if len(hosts) == 0 {
		return items
	}
	for _, h := range hosts {
		item := make(map[string]interface{})
		item["host"] = h.Host
		item["capabilities"] = h.Capabilities
		item["override_path"] = h.OverridePath
		item["dial_timeout"] = h.DialTimeout

		if h.Header != nil {
			tmp := make([]interface{}, len(h.Header))
			for i, val := range h.Header {
				tmp[i] = map[string]interface{}{
					"key":   val.Key,
					"value": val.Value,
				}
			}
			item["header"] = tmp
		}

		if h.Ca != nil {
			tmp := make([]interface{}, len(h.Ca))
			for i, val := range h.Ca {
				if val != nil && val.GcpSecretManagerSecretUri != "" {
					tmp[i] = map[string]interface{}{
						"gcp_secret_manager_secret_uri": val.GcpSecretManagerSecretUri,
					}
				}
			}
			item["ca"] = tmp
		}

		if h.Client != nil {
			tmp := make([]interface{}, len(h.Client))
			for i, val := range h.Client {
				currentClient := map[string]interface{}{}
				if val != nil && val.Cert != nil && val.Cert.GcpSecretManagerSecretUri != "" {
					currentClient["cert"] = []interface{}{
						map[string]interface{}{
							"gcp_secret_manager_secret_uri": val.Cert.GcpSecretManagerSecretUri,
						},
					}
				}
				if val != nil && val.Key != nil && val.Key.GcpSecretManagerSecretUri != "" {
					currentClient["key"] = []interface{}{
						map[string]interface{}{
							"gcp_secret_manager_secret_uri": val.Key.GcpSecretManagerSecretUri,
						},
					}
				}
				tmp[i] = currentClient
			}
			item["client"] = tmp
		}
		items = append(items, item)
	}
	return items
}

func flattenPrivateRegistryAccessConfig(c *container.PrivateRegistryAccessConfig) []map[string]interface{} {
	result := []map[string]interface{}{}
	if c == nil {
		return result
	}
	r := map[string]interface{}{
		"enabled": c.Enabled,
	}
	if c.CertificateAuthorityDomainConfig != nil {
		caConfigs := make([]interface{}, len(c.CertificateAuthorityDomainConfig))
		for i, caCfg := range c.CertificateAuthorityDomainConfig {
			caConfigs[i] = flattenCADomainConfig(caCfg)
		}
		r["certificate_authority_domain_config"] = caConfigs
	}
	return append(result, r)
}

//  func flattenCADomainConfig(c *container.CertificateAuthorityDomainConfig) []map[string]interface{} {
//  	result := []map[string]interface{}{}
//  	if c == nil {
//  		return result
//  	}
//  	r := map[string]interface{}{
//  		"fqdns": c.Fqdns,
//  	}
//  	if c.GcpSecretManagerCertificateConfig != nil {
//  		r["gcp_secret_manager_certificate_config"] = flattenGCPSecretManagerCertificateConfig(c.GcpSecretManagerCertificateConfig)
//  	}
//  	return append(result, r)
//  }

func flattenCADomainConfig(c *container.CertificateAuthorityDomainConfig) map[string]interface{} {
	if c == nil {
		return nil
	}
	r := map[string]interface{}{
		"fqdns": c.Fqdns,
	}
	if c.GcpSecretManagerCertificateConfig != nil {
		r["gcp_secret_manager_certificate_config"] = flattenGCPSecretManagerCertificateConfig(c.GcpSecretManagerCertificateConfig)
	}
	return r
}

func flattenGCPSecretManagerCertificateConfig(c *container.GCPSecretManagerCertificateConfig) []map[string]interface{} {
	result := []map[string]interface{}{}
	if c == nil {
		return result
	}
	r := map[string]interface{}{
		"secret_uri": c.SecretUri,
	}
	return append(result, r)
}

func flattenWritableCgroups(c *container.WritableCgroups) []map[string]interface{} {
	result := []map[string]interface{}{}
	if c == nil {
		return result
	}
	r := map[string]interface{}{
		"enabled": c.Enabled,
	}
	return append(result, r)
}

func flattenConfidentialNodes(c *container.ConfidentialNodes) []map[string]interface{} {
	result := []map[string]interface{}{}
	if c != nil {
		result = append(result, map[string]interface{}{
			"enabled":                    c.Enabled,
			"confidential_instance_type": c.ConfidentialInstanceType,
		})
	}
	return result
}

func flattenSoleTenantConfig(c *container.SoleTenantConfig) []map[string]interface{} {
	result := []map[string]interface{}{}
	if c == nil {
		return result
	}
	affinities := []map[string]interface{}{}
	for _, affinity := range c.NodeAffinities {
		affinities = append(affinities, map[string]interface{}{
			"key":      affinity.Key,
			"operator": affinity.Operator,
			"values":   affinity.Values,
		})
	}
	return append(result, map[string]interface{}{
		"node_affinity": affinities,
		"min_node_cpus": c.MinNodeCpus,
	})
}

func flattenFastSocket(c *container.FastSocket) []map[string]interface{} {
	result := []map[string]interface{}{}
	if c != nil {
		result = append(result, map[string]interface{}{
			"enabled": c.Enabled,
		})
	}
	return result
}

// This portion of nodePoolUpdate() is moved here to be shared with
// node pool updates in `resource_container_cluster`
func nodePoolNodeConfigUpdate(d *schema.ResourceData, config *transport_tpg.Config, nodePoolInfo *NodePoolInformation, prefix, name string, timeout time.Duration) error {

	// Nodepool write-lock will be acquired when update function is called.
	npLockKey := nodePoolInfo.nodePoolLockKey(name)

	userAgent, err := tpgresource.GenerateUserAgentString(d, config.UserAgent)
	if err != nil {
		return err
	}

	if d.HasChange(prefix + "node_config") {

		if d.HasChange(prefix + "node_config.0.logging_variant") {
			if v, ok := d.GetOk(prefix + "node_config.0.logging_variant"); ok {
				loggingVariant := v.(string)
				req := &container.UpdateNodePoolRequest{
					Name: name,
					LoggingConfig: &container.NodePoolLoggingConfig{
						VariantConfig: &container.LoggingVariantConfig{
							Variant: loggingVariant,
						},
					},
				}

				updateF := func() error {
					clusterNodePoolsUpdateCall := config.NewContainerClient(userAgent).Projects.Locations.Clusters.NodePools.Update(nodePoolInfo.fullyQualifiedName(name), req)
					if config.UserProjectOverride {
						clusterNodePoolsUpdateCall.Header().Add("X-Goog-User-Project", nodePoolInfo.project)
					}
					op, err := clusterNodePoolsUpdateCall.Do()
					if err != nil {
						return err
					}

					// Wait until it's updated
					return ContainerOperationWait(config, op,
						nodePoolInfo.project,
						nodePoolInfo.location,
						"updating GKE node pool logging_variant", userAgent,
						timeout)
				}

				if err := retryWhileIncompatibleOperation(timeout, npLockKey, updateF); err != nil {
					return err
				}

				log.Printf("[INFO] Updated logging_variant for node pool %s", name)
			}
		}

		if d.HasChange(prefix + "node_config.0.containerd_config") {
			if _, ok := d.GetOk(prefix + "node_config.0.containerd_config"); ok {
				req := &container.UpdateNodePoolRequest{
					Name:             name,
					ContainerdConfig: expandContainerdConfig(d.Get(prefix + "node_config.0.containerd_config")),
				}
				if req.ContainerdConfig == nil {
					req.ContainerdConfig = &container.ContainerdConfig{}
					req.ForceSendFields = []string{"ContainerdConfig"}
				}
				updateF := func() error {
					clusterNodePoolsUpdateCall := config.NewContainerClient(userAgent).Projects.Locations.Clusters.NodePools.Update(nodePoolInfo.fullyQualifiedName(name), req)
					if config.UserProjectOverride {
						clusterNodePoolsUpdateCall.Header().Add("X-Goog-User-Project", nodePoolInfo.project)
					}
					op, err := clusterNodePoolsUpdateCall.Do()
					if err != nil {
						return err
					}

					// Wait until it's updated
					return ContainerOperationWait(config, op,
						nodePoolInfo.project,
						nodePoolInfo.location,
						"updating GKE node pool containerd_config", userAgent,
						timeout)
				}

				if err := retryWhileIncompatibleOperation(timeout, npLockKey, updateF); err != nil {
					return err
				}

				log.Printf("[INFO] Updated containerd_config for node pool %s", name)
			}
		}

		if d.HasChange(prefix + "node_config.0.confidential_nodes") {
			if _, ok := d.GetOk(prefix + "node_config.0.confidential_nodes"); ok {
				req := &container.UpdateNodePoolRequest{
					Name:              name,
					ConfidentialNodes: expandConfidentialNodes(d.Get(prefix + "node_config.0.confidential_nodes")),
				}
				if req.ConfidentialNodes == nil {
					req.ConfidentialNodes = &container.ConfidentialNodes{}
					req.ForceSendFields = []string{"ConfidentialNodes"}
				}
				updateF := func() error {
					clusterNodePoolsUpdateCall := config.NewContainerClient(userAgent).Projects.Locations.Clusters.NodePools.Update(nodePoolInfo.fullyQualifiedName(name), req)
					if config.UserProjectOverride {
						clusterNodePoolsUpdateCall.Header().Add("X-Goog-User-Project", nodePoolInfo.project)
					}
					op, err := clusterNodePoolsUpdateCall.Do()
					if err != nil {
						return err
					}

					// Wait until it's updated
					return ContainerOperationWait(config, op,
						nodePoolInfo.project,
						nodePoolInfo.location,
						"updating GKE node pool confidential_nodes", userAgent,
						timeout)
				}

				if err := retryWhileIncompatibleOperation(timeout, npLockKey, updateF); err != nil {
					return err
				}

				log.Printf("[INFO] Updated confidential_nodes for node pool %s", name)
			}
		}

		if d.HasChange("node_config.0.disk_size_gb") ||
			d.HasChange("node_config.0.disk_type") ||
			d.HasChange("node_config.0.machine_type") ||
			d.HasChange("node_config.0.storage_pools") ||
			d.HasChange("node_config.0.boot_disk") {

			req := &container.UpdateNodePoolRequest{
				Name:        name,
				DiskSizeGb:  int64(d.Get("node_config.0.disk_size_gb").(int)),
				DiskType:    d.Get("node_config.0.disk_type").(string),
				MachineType: d.Get("node_config.0.machine_type").(string),
			}
			if v, ok := d.GetOk("node_config.0.storage_pools"); ok {
				spList := v.([]interface{})
				storagePools := []string{}
				for _, v := range spList {
					if v != nil {
						storagePools = append(storagePools, v.(string))
					}
				}
				req.StoragePools = storagePools
			}

			if v, ok := d.GetOk("node_config.0.boot_disk"); ok {
				bd := expandBootDiskConfig(v)
				req.BootDisk = bd

				// The following checks are to ensure that the migrating fields are handled properly.
				// Migrating fields are disk_type -> boot_disk.disk_type and disk_size_gb -> boot_disk.size_gb
				// If the legacy (top level) disk_type field is not changing, nil it out to allow the API to fill it in.
				legacyDiskTypeOld, legacyDiskTypeNew := d.GetChange("node_config.0.disk_type")
				if legacyDiskTypeOld == legacyDiskTypeNew {
					req.DiskType = ""
				}
				// If the new boot disk configuration disk_filed is not changing, nil it out to allow the API to fill it in.
				bootDiskTypeOld, bootDiskTypeNew := d.GetChange("node_config.0.boot_disk.0.disk_type")
				if bootDiskTypeOld == bootDiskTypeNew {
					req.BootDisk.DiskType = ""
				}
				// If the legacy (top level) disk_size_gb field is not changing, nil it out to allow the API to fill it in.
				legacyDiskSizeGbOld, legacyDiskSizeGbNew := d.GetChange("node_config.0.disk_size_gb")
				if legacyDiskSizeGbOld == legacyDiskSizeGbNew {
					req.DiskSizeGb = 0
				}
				// if the new boot disk configuration size_gb field is not changing, nil it out to allow the API to fill it in.
				bootDiskSizeGbOld, bootDiskSizeGbNew := d.GetChange("node_config.0.boot_disk.0.size_gb")
				if bootDiskSizeGbOld == bootDiskSizeGbNew {
					req.BootDisk.SizeGb = 0
				}
			}

			updateF := func() error {
				clusterNodePoolsUpdateCall := config.NewContainerClient(userAgent).Projects.Locations.Clusters.NodePools.Update(nodePoolInfo.fullyQualifiedName(name), req)
				if config.UserProjectOverride {
					clusterNodePoolsUpdateCall.Header().Add("X-Goog-User-Project", nodePoolInfo.project)
				}
				op, err := clusterNodePoolsUpdateCall.Do()
				if err != nil {
					return err
				}

				// Wait until it's updated
				return ContainerOperationWait(config, op,
					nodePoolInfo.project,
					nodePoolInfo.location,
					"updating GKE node pool disk_size_gb/disk_type/machine_type/storage_pools/boot_disk", userAgent,
					timeout)
			}

			if err := retryWhileIncompatibleOperation(timeout, npLockKey, updateF); err != nil {
				return err
			}
			log.Printf("[INFO] Updated disk disk_size_gb/disk_type/machine_type/storage_pools/boot_disk for Node Pool %s", d.Id())
		}

		if d.HasChange(prefix + "node_config.0.taint") {
			req := &container.UpdateNodePoolRequest{
				Name: name,
			}
			if v, ok := d.GetOk(prefix + "node_config.0.taint"); ok {
				taintsList := v.([]interface{})
				taints := make([]*container.NodeTaint, 0, len(taintsList))
				for _, v := range taintsList {
					if v != nil {
						data := v.(map[string]interface{})
						taint := &container.NodeTaint{
							Key:    data["key"].(string),
							Value:  data["value"].(string),
							Effect: data["effect"].(string),
						}
						taints = append(taints, taint)
					}
				}
				ntaints := &container.NodeTaints{
					Taints: taints,
				}
				req.Taints = ntaints
			}

			if req.Taints == nil {
				taints := make([]*container.NodeTaint, 0, 0)
				ntaints := &container.NodeTaints{
					Taints: taints,
				}
				req.Taints = ntaints
			}

			updateF := func() error {
				clusterNodePoolsUpdateCall := config.NewContainerClient(userAgent).Projects.Locations.Clusters.NodePools.Update(nodePoolInfo.fullyQualifiedName(name), req)
				if config.UserProjectOverride {
					clusterNodePoolsUpdateCall.Header().Add("X-Goog-User-Project", nodePoolInfo.project)
				}
				op, err := clusterNodePoolsUpdateCall.Do()
				if err != nil {
					return err
				}

				// Wait until it's updated
				return ContainerOperationWait(config, op,
					nodePoolInfo.project,
					nodePoolInfo.location,
					"updating GKE node pool taints", userAgent,
					timeout)
			}

			if err := retryWhileIncompatibleOperation(timeout, npLockKey, updateF); err != nil {
				return err
			}
			log.Printf("[INFO] Updated taints for Node Pool %s", d.Id())
		}

		if d.HasChange(prefix + "node_config.0.tags") {
			req := &container.UpdateNodePoolRequest{
				Name: name,
			}
			if v, ok := d.GetOk(prefix + "node_config.0.tags"); ok {
				tagsList := v.([]interface{})
				tags := []string{}
				for _, v := range tagsList {
					if v != nil {
						tags = append(tags, v.(string))
					}
				}
				ntags := &container.NetworkTags{
					Tags: tags,
				}
				req.Tags = ntags
			}

			// sets tags to the empty list when user removes a previously defined list of tags entriely
			// aka the node pool goes from having tags to no longer having any
			if req.Tags == nil {
				tags := []string{}
				ntags := &container.NetworkTags{
					Tags: tags,
				}
				req.Tags = ntags
			}

			updateF := func() error {
				clusterNodePoolsUpdateCall := config.NewContainerClient(userAgent).Projects.Locations.Clusters.NodePools.Update(nodePoolInfo.fullyQualifiedName(name), req)
				if config.UserProjectOverride {
					clusterNodePoolsUpdateCall.Header().Add("X-Goog-User-Project", nodePoolInfo.project)
				}
				op, err := clusterNodePoolsUpdateCall.Do()
				if err != nil {
					return err
				}

				// Wait until it's updated
				return ContainerOperationWait(config, op,
					nodePoolInfo.project,
					nodePoolInfo.location,
					"updating GKE node pool tags", userAgent,
					timeout)
			}

			if err := retryWhileIncompatibleOperation(timeout, npLockKey, updateF); err != nil {
				return err
			}
			log.Printf("[INFO] Updated tags for node pool %s", name)
		}

		if d.HasChange(prefix + "node_config.0.resource_manager_tags") {
			req := &container.UpdateNodePoolRequest{
				Name: name,
			}
			if v, ok := d.GetOk(prefix + "node_config.0.resource_manager_tags"); ok {
				req.ResourceManagerTags = expandResourceManagerTags(v)
			}

			// sets resource manager tags to the empty list when user removes a previously defined list of tags entriely
			// aka the node pool goes from having tags to no longer having any
			if req.ResourceManagerTags == nil {
				tags := make(map[string]string)
				rmTags := &container.ResourceManagerTags{
					Tags: tags,
				}
				req.ResourceManagerTags = rmTags
			}

			updateF := func() error {
				clusterNodePoolsUpdateCall := config.NewContainerClient(userAgent).Projects.Locations.Clusters.NodePools.Update(nodePoolInfo.fullyQualifiedName(name), req)
				if config.UserProjectOverride {
					clusterNodePoolsUpdateCall.Header().Add("X-Goog-User-Project", nodePoolInfo.project)
				}
				op, err := clusterNodePoolsUpdateCall.Do()
				if err != nil {
					return err
				}

				// Wait until it's updated
				return ContainerOperationWait(config, op,
					nodePoolInfo.project,
					nodePoolInfo.location,
					"updating GKE node pool resource manager tags", userAgent,
					timeout)
			}

			if err := retryWhileIncompatibleOperation(timeout, npLockKey, updateF); err != nil {
				return err
			}
			log.Printf("[INFO] Updated resource manager tags for node pool %s", name)
		}

		if d.HasChange(prefix + "node_config.0.resource_labels") {
			req := &container.UpdateNodePoolRequest{
				Name: name,
			}

			if v, ok := d.GetOk(prefix + "node_config.0.resource_labels"); ok {
				resourceLabels := v.(map[string]interface{})
				req.ResourceLabels = &container.ResourceLabels{
					Labels: tpgresource.ConvertStringMap(resourceLabels),
				}
			}

			updateF := func() error {
				clusterNodePoolsUpdateCall := config.NewContainerClient(userAgent).Projects.Locations.Clusters.NodePools.Update(nodePoolInfo.fullyQualifiedName(name), req)
				if config.UserProjectOverride {
					clusterNodePoolsUpdateCall.Header().Add("X-Goog-User-Project", nodePoolInfo.project)
				}
				op, err := clusterNodePoolsUpdateCall.Do()
				if err != nil {
					return err
				}

				// Wait until it's updated
				return ContainerOperationWait(config, op,
					nodePoolInfo.project,
					nodePoolInfo.location,
					"updating GKE node pool resource labels", userAgent,
					timeout)
			}

			// Call update serially.
			if err := retryWhileIncompatibleOperation(timeout, npLockKey, updateF); err != nil {
				return err
			}

			log.Printf("[INFO] Updated resource labels for node pool %s", name)
		}

		if d.HasChange(prefix + "node_config.0.labels") {
			req := &container.UpdateNodePoolRequest{
				Name: name,
			}

			if v, ok := d.GetOk(prefix + "node_config.0.labels"); ok {
				labels := v.(map[string]interface{})
				req.Labels = &container.NodeLabels{
					Labels: tpgresource.ConvertStringMap(labels),
				}
			}

			updateF := func() error {
				clusterNodePoolsUpdateCall := config.NewContainerClient(userAgent).Projects.Locations.Clusters.NodePools.Update(nodePoolInfo.fullyQualifiedName(name), req)
				if config.UserProjectOverride {
					clusterNodePoolsUpdateCall.Header().Add("X-Goog-User-Project", nodePoolInfo.project)
				}
				op, err := clusterNodePoolsUpdateCall.Do()
				if err != nil {
					return err
				}

				// Wait until it's updated
				return ContainerOperationWait(config, op,
					nodePoolInfo.project,
					nodePoolInfo.location,
					"updating GKE node pool labels", userAgent,
					timeout)
			}

			// Call update serially.
			if err := retryWhileIncompatibleOperation(timeout, npLockKey, updateF); err != nil {
				return err
			}

			log.Printf("[INFO] Updated labels for node pool %s", name)
		}

		if d.HasChange(prefix + "node_config.0.image_type") {
			req := &container.UpdateClusterRequest{
				Update: &container.ClusterUpdate{
					DesiredNodePoolId: name,
					DesiredImageType:  d.Get(prefix + "node_config.0.image_type").(string),
				},
			}

			updateF := func() error {
				clusterUpdateCall := config.NewContainerClient(userAgent).Projects.Locations.Clusters.Update(nodePoolInfo.parent(), req)
				if config.UserProjectOverride {
					clusterUpdateCall.Header().Add("X-Goog-User-Project", nodePoolInfo.project)
				}
				op, err := clusterUpdateCall.Do()
				if err != nil {
					return err
				}

				// Wait until it's updated
				return ContainerOperationWait(config, op,
					nodePoolInfo.project,
					nodePoolInfo.location, "updating GKE node pool", userAgent,
					timeout)
			}

			if err := retryWhileIncompatibleOperation(timeout, npLockKey, updateF); err != nil {
				return err
			}
			log.Printf("[INFO] Updated image type in Node Pool %s", d.Id())
		}

		if d.HasChange(prefix + "node_config.0.workload_metadata_config") {
			req := &container.UpdateNodePoolRequest{
				NodePoolId: name,
				WorkloadMetadataConfig: expandWorkloadMetadataConfig(
					d.Get(prefix + "node_config.0.workload_metadata_config")),
			}
			if req.WorkloadMetadataConfig == nil {
				req.WorkloadMetadataConfig = &container.WorkloadMetadataConfig{}
				req.ForceSendFields = []string{"WorkloadMetadataConfig"}
			}
			updateF := func() error {
				clusterNodePoolsUpdateCall := config.NewContainerClient(userAgent).Projects.Locations.Clusters.NodePools.Update(nodePoolInfo.fullyQualifiedName(name), req)
				if config.UserProjectOverride {
					clusterNodePoolsUpdateCall.Header().Add("X-Goog-User-Project", nodePoolInfo.project)
				}
				op, err := clusterNodePoolsUpdateCall.Do()

				if err != nil {
					return err
				}

				// Wait until it's updated
				return ContainerOperationWait(config, op,
					nodePoolInfo.project,
					nodePoolInfo.location,
					"updating GKE node pool workload_metadata_config", userAgent,
					timeout)
			}

			if err := retryWhileIncompatibleOperation(timeout, npLockKey, updateF); err != nil {
				return err
			}
			log.Printf("[INFO] Updated workload_metadata_config for node pool %s", name)
		}

		if d.HasChange(prefix + "node_config.0.gcfs_config") {
			gcfsEnabled := bool(d.Get(prefix + "node_config.0.gcfs_config.0.enabled").(bool))
			req := &container.UpdateNodePoolRequest{
				NodePoolId: name,
				GcfsConfig: &container.GcfsConfig{
					Enabled: gcfsEnabled,
				},
			}
			updateF := func() error {
				clusterNodePoolsUpdateCall := config.NewContainerClient(userAgent).Projects.Locations.Clusters.NodePools.Update(nodePoolInfo.fullyQualifiedName(name), req)
				if config.UserProjectOverride {
					clusterNodePoolsUpdateCall.Header().Add("X-Goog-User-Project", nodePoolInfo.project)
				}
				op, err := clusterNodePoolsUpdateCall.Do()
				if err != nil {
					return err
				}

				// Wait until it's updated
				return ContainerOperationWait(config, op,
					nodePoolInfo.project,
					nodePoolInfo.location,
					"updating GKE node pool gcfs_config", userAgent,
					timeout)
			}

			if err := retryWhileIncompatibleOperation(timeout, npLockKey, updateF); err != nil {
				return err
			}

			log.Printf("[INFO] Updated gcfs_config for node pool %s", name)
		}

		if d.HasChange(prefix + "node_config.0.gvnic") {
			gvnicEnabled := bool(d.Get(prefix + "node_config.0.gvnic.0.enabled").(bool))
			req := &container.UpdateNodePoolRequest{
				NodePoolId: name,
				Gvnic: &container.VirtualNIC{
					Enabled: gvnicEnabled,
				},
			}
			updateF := func() error {
				clusterNodePoolsUpdateCall := config.NewContainerClient(userAgent).Projects.Locations.Clusters.NodePools.Update(nodePoolInfo.fullyQualifiedName(name), req)
				if config.UserProjectOverride {
					clusterNodePoolsUpdateCall.Header().Add("X-Goog-User-Project", nodePoolInfo.project)
				}
				op, err := clusterNodePoolsUpdateCall.Do()
				if err != nil {
					return err
				}

				// Wait until it's updated
				return ContainerOperationWait(config, op,
					nodePoolInfo.project,
					nodePoolInfo.location,
					"updating GKE node pool gvnic", userAgent,
					timeout)
			}

			if err := retryWhileIncompatibleOperation(timeout, npLockKey, updateF); err != nil {
				return err
			}

			log.Printf("[INFO] Updated gvnic for node pool %s", name)
		}

		if d.HasChange(prefix + "node_config.0.kubelet_config") {
			req := &container.UpdateNodePoolRequest{
				NodePoolId: name,
				KubeletConfig: expandKubeletConfig(
					d.Get(prefix + "node_config.0.kubelet_config")),
			}
			if req.KubeletConfig == nil {
				req.KubeletConfig = &container.NodeKubeletConfig{}
				req.ForceSendFields = []string{"KubeletConfig"}
			}
			updateF := func() error {
				clusterNodePoolsUpdateCall := config.NewContainerClient(userAgent).Projects.Locations.Clusters.NodePools.Update(nodePoolInfo.fullyQualifiedName(name), req)
				if config.UserProjectOverride {
					clusterNodePoolsUpdateCall.Header().Add("X-Goog-User-Project", nodePoolInfo.project)
				}
				op, err := clusterNodePoolsUpdateCall.Do()
				if err != nil {
					return err
				}

				// Wait until it's updated
				return ContainerOperationWait(config, op,
					nodePoolInfo.project,
					nodePoolInfo.location,
					"updating GKE node pool kubelet_config", userAgent,
					timeout)
			}

			if err := retryWhileIncompatibleOperation(timeout, npLockKey, updateF); err != nil {
				return err
			}

			log.Printf("[INFO] Updated kubelet_config for node pool %s", name)
		}
		if d.HasChange(prefix + "node_config.0.linux_node_config") {
			req := &container.UpdateNodePoolRequest{
				NodePoolId: name,
				LinuxNodeConfig: expandLinuxNodeConfig(
					d.Get(prefix + "node_config.0.linux_node_config")),
			}
			if req.LinuxNodeConfig == nil {
				req.LinuxNodeConfig = &container.LinuxNodeConfig{}
				req.ForceSendFields = []string{"LinuxNodeConfig"}
			}
			updateF := func() error {
				clusterNodePoolsUpdateCall := config.NewContainerClient(userAgent).Projects.Locations.Clusters.NodePools.Update(nodePoolInfo.fullyQualifiedName(name), req)
				if config.UserProjectOverride {
					clusterNodePoolsUpdateCall.Header().Add("X-Goog-User-Project", nodePoolInfo.project)
				}
				op, err := clusterNodePoolsUpdateCall.Do()
				if err != nil {
					return err
				}

				// Wait until it's updated
				return ContainerOperationWait(config, op,
					nodePoolInfo.project,
					nodePoolInfo.location,
					"updating GKE node pool linux_node_config", userAgent,
					timeout)
			}

			if err := retryWhileIncompatibleOperation(timeout, npLockKey, updateF); err != nil {
				return err
			}

			log.Printf("[INFO] Updated linux_node_config for node pool %s", name)
		}
		if d.HasChange(prefix + "node_config.0.windows_node_config") {
			req := &container.UpdateNodePoolRequest{
				NodePoolId: name,
				WindowsNodeConfig: expandWindowsNodeConfig(
					d.Get(prefix + "node_config.0.windows_node_config")),
			}
			if req.WindowsNodeConfig == nil {
				req.WindowsNodeConfig = &container.WindowsNodeConfig{}
				req.ForceSendFields = []string{"WindowsNodeConfig"}
			}
			updateF := func() error {
				clusterNodePoolsUpdateCall := config.NewContainerClient(userAgent).Projects.Locations.Clusters.NodePools.Update(nodePoolInfo.fullyQualifiedName(name), req)
				if config.UserProjectOverride {
					clusterNodePoolsUpdateCall.Header().Add("X-Goog-User-Project", nodePoolInfo.project)
				}
				op, err := clusterNodePoolsUpdateCall.Do()
				if err != nil {
					return err
				}

				// Wait until it's updated
				return ContainerOperationWait(config, op,
					nodePoolInfo.project,
					nodePoolInfo.location,
					"updating GKE node pool windows_node_config", userAgent,
					timeout)
			}

			if err := retryWhileIncompatibleOperation(timeout, npLockKey, updateF); err != nil {
				return err
			}

			log.Printf("[INFO] Updated windows_node_config for node pool %s", name)
		}
		if d.HasChange(prefix + "node_config.0.fast_socket") {
			req := &container.UpdateNodePoolRequest{
				NodePoolId: name,
				FastSocket: &container.FastSocket{},
			}
			if v, ok := d.GetOk(prefix + "node_config.0.fast_socket"); ok {
				fastSocket := v.([]interface{})[0].(map[string]interface{})
				req.FastSocket = &container.FastSocket{
					Enabled: fastSocket["enabled"].(bool),
				}
			}
			updateF := func() error {
				clusterNodePoolsUpdateCall := config.NewContainerClient(userAgent).Projects.Locations.Clusters.NodePools.Update(nodePoolInfo.fullyQualifiedName(name), req)
				if config.UserProjectOverride {
					clusterNodePoolsUpdateCall.Header().Add("X-Goog-User-Project", nodePoolInfo.project)
				}
				op, err := clusterNodePoolsUpdateCall.Do()
				if err != nil {
					return err
				}

				// Wait until it's updated
				return ContainerOperationWait(config, op,
					nodePoolInfo.project,
					nodePoolInfo.location,
					"updating GKE node pool fast_socket", userAgent,
					timeout)
			}

			if err := retryWhileIncompatibleOperation(timeout, npLockKey, updateF); err != nil {
				return err
			}

			log.Printf("[INFO] Updated fast_socket for node pool %s", name)
		}
	}

	return nil
}
