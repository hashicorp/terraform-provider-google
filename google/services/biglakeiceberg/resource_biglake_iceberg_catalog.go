// Copyright (c) HashiCorp, Inc.
// SPDX-License-Identifier: MPL-2.0

// ----------------------------------------------------------------------------
//
//     ***     AUTO GENERATED CODE    ***    Type: MMv1     ***
//
// ----------------------------------------------------------------------------
//
//     This code is generated by Magic Modules using the following:
//
//     Configuration: https://github.com/GoogleCloudPlatform/magic-modules/tree/main/mmv1/products/biglakeiceberg/IcebergCatalog.yaml
//     Template:      https://github.com/GoogleCloudPlatform/magic-modules/tree/main/mmv1/templates/terraform/resource.go.tmpl
//
//     DO NOT EDIT this file directly. Any changes made to this file will be
//     overwritten during the next generation cycle.
//
// ----------------------------------------------------------------------------

package biglakeiceberg

import (
	"bytes"
	"context"
	"encoding/base64"
	"encoding/json"
	"fmt"
	"log"
	"net/http"
	"reflect"
	"regexp"
	"slices"
	"sort"
	"strconv"
	"strings"
	"time"

	"github.com/hashicorp/errwrap"
	"github.com/hashicorp/go-cty/cty"
	"github.com/hashicorp/terraform-plugin-sdk/v2/diag"
	"github.com/hashicorp/terraform-plugin-sdk/v2/helper/customdiff"
	"github.com/hashicorp/terraform-plugin-sdk/v2/helper/id"
	"github.com/hashicorp/terraform-plugin-sdk/v2/helper/logging"
	"github.com/hashicorp/terraform-plugin-sdk/v2/helper/retry"
	"github.com/hashicorp/terraform-plugin-sdk/v2/helper/schema"
	"github.com/hashicorp/terraform-plugin-sdk/v2/helper/structure"
	"github.com/hashicorp/terraform-plugin-sdk/v2/helper/validation"
	"github.com/hashicorp/terraform-plugin-sdk/v2/terraform"

	"github.com/hashicorp/terraform-provider-google/google/tpgresource"
	transport_tpg "github.com/hashicorp/terraform-provider-google/google/transport"
	"github.com/hashicorp/terraform-provider-google/google/verify"

	"google.golang.org/api/googleapi"
)

var (
	_ = bytes.Clone
	_ = context.WithCancel
	_ = base64.NewDecoder
	_ = json.Marshal
	_ = fmt.Sprintf
	_ = log.Print
	_ = http.Get
	_ = reflect.ValueOf
	_ = regexp.Match
	_ = slices.Min([]int{1})
	_ = sort.IntSlice{}
	_ = strconv.Atoi
	_ = strings.Trim
	_ = time.Now
	_ = errwrap.Wrap
	_ = cty.BoolVal
	_ = diag.Diagnostic{}
	_ = customdiff.All
	_ = id.UniqueId
	_ = logging.LogLevel
	_ = retry.Retry
	_ = schema.Noop
	_ = validation.All
	_ = structure.ExpandJsonFromString
	_ = terraform.State{}
	_ = tpgresource.SetLabels
	_ = transport_tpg.Config{}
	_ = verify.ValidateEnum
	_ = googleapi.Error{}
)

func ResourceBiglakeIcebergIcebergCatalog() *schema.Resource {
	return &schema.Resource{
		Create: resourceBiglakeIcebergIcebergCatalogCreate,
		Read:   resourceBiglakeIcebergIcebergCatalogRead,
		Update: resourceBiglakeIcebergIcebergCatalogUpdate,
		Delete: resourceBiglakeIcebergIcebergCatalogDelete,

		Importer: &schema.ResourceImporter{
			State: resourceBiglakeIcebergIcebergCatalogImport,
		},

		Timeouts: &schema.ResourceTimeout{
			Create: schema.DefaultTimeout(20 * time.Minute),
			Update: schema.DefaultTimeout(20 * time.Minute),
			Delete: schema.DefaultTimeout(20 * time.Minute),
		},

		CustomizeDiff: customdiff.All(
			tpgresource.DefaultProviderProject,
		),

		Identity: &schema.ResourceIdentity{
			Version: 1,
			SchemaFunc: func() map[string]*schema.Schema {
				return map[string]*schema.Schema{
					"name": {
						Type:              schema.TypeString,
						RequiredForImport: true,
					},
					"project": {
						Type:              schema.TypeString,
						OptionalForImport: true,
					},
				}
			},
		},
		Schema: map[string]*schema.Schema{
			"catalog_type": {
				Type:         schema.TypeString,
				Required:     true,
				ForceNew:     true,
				ValidateFunc: verify.ValidateEnum([]string{"CATALOG_TYPE_GCS_BUCKET"}),
				Description:  `The catalog type of the IcebergCatalog. Currently only supports the type for Google Cloud Storage Buckets. Possible values: ["CATALOG_TYPE_GCS_BUCKET"]`,
			},
			"name": {
				Type:     schema.TypeString,
				Required: true,
				ForceNew: true,
				Description: `The name of the IcebergCatalog. Format:
projects/{project_id_or_number}/catalogs/{iceberg_catalog_id}`,
			},
			"credential_mode": {
				Type:         schema.TypeString,
				Computed:     true,
				Optional:     true,
				ValidateFunc: verify.ValidateEnum([]string{"CREDENTIAL_MODE_END_USER", "CREDENTIAL_MODE_VENDED_CREDENTIALS", ""}),
				Description:  `The credential mode used for the catalog. CREDENTIAL_MODE_END_USER - End user credentials, default. The authenticating user must have access to the catalog resources and the corresponding Google Cloud Storage files. CREDENTIAL_MODE_VENDED_CREDENTIALS - Use credential vending. The authenticating user must have access to the catalog resources and the system will provide the caller with downscoped credentials to access the Google Cloud Storage files. All table operations in this mode would require 'X-Iceberg-Access-Delegation' header with 'vended-credentials' value included. System will generate a service account and the catalog administrator must grant the service account appropriate permissions. Possible values: ["CREDENTIAL_MODE_END_USER", "CREDENTIAL_MODE_VENDED_CREDENTIALS"]`,
			},
			"biglake_service_account": {
				Type:        schema.TypeString,
				Computed:    true,
				Description: `Output only. The service account used for credential vending. It might be empty if credential vending was never enabled for the catalog.`,
			},
			"create_time": {
				Type:        schema.TypeString,
				Computed:    true,
				Description: `Output only. The creation time of the IcebergCatalog.`,
			},
			"default_location": {
				Type:        schema.TypeString,
				Computed:    true,
				Description: `Output only. The default storage location for the catalog, e.g., 'gs://my-bucket'.`,
			},
			"replicas": {
				Type:        schema.TypeList,
				Computed:    true,
				Description: `Output only. The replicas for the catalog metadata.`,
				Elem: &schema.Resource{
					Schema: map[string]*schema.Schema{
						"region": {
							Type:        schema.TypeString,
							Computed:    true,
							Description: `The region of the replica, e.g., 'us-east1'.`,
						},
						"state": {
							Type:        schema.TypeString,
							Computed:    true,
							Description: `If the IcebergCatalog is replicated to multiple regions, this describes the current state of the replica. STATE_UNKNOWN - The replica state is unknown. STATE_PRIMARY - The replica is the writable primary. STATE_PRIMARY_IN_PROGRESS - The replica has been recently assigned as the primary, but not all namespaces are writeable yet. STATE_SECONDARY - The replica is a read-only secondary replica.`,
						},
					},
				},
			},
			"storage_regions": {
				Type:        schema.TypeList,
				Computed:    true,
				Description: `Output only. The GCP region(s) where the physical metadata for the tables is stored, e.g. 'us-central1', 'nam4' or 'us'. This will contain one value for all locations, except for the catalogs that are configured to use custom dual region buckets.`,
				Elem: &schema.Schema{
					Type: schema.TypeString,
				},
			},
			"update_time": {
				Type:        schema.TypeString,
				Computed:    true,
				Description: `Output only. The last modification time of the IcebergCatalog.`,
			},
			"project": {
				Type:     schema.TypeString,
				Optional: true,
				Computed: true,
				ForceNew: true,
			},
		},
		UseJSONNumber: true,
	}
}

func resourceBiglakeIcebergIcebergCatalogCreate(d *schema.ResourceData, meta interface{}) error {
	config := meta.(*transport_tpg.Config)
	userAgent, err := tpgresource.GenerateUserAgentString(d, config.UserAgent)
	if err != nil {
		return err
	}

	obj := make(map[string]interface{})
	credentialModeProp, err := expandBiglakeIcebergIcebergCatalogCredentialMode(d.Get("credential_mode"), d, config)
	if err != nil {
		return err
	} else if v, ok := d.GetOkExists("credential_mode"); !tpgresource.IsEmptyValue(reflect.ValueOf(credentialModeProp)) && (ok || !reflect.DeepEqual(v, credentialModeProp)) {
		obj["credential-mode"] = credentialModeProp
	}
	catalogTypeProp, err := expandBiglakeIcebergIcebergCatalogCatalogType(d.Get("catalog_type"), d, config)
	if err != nil {
		return err
	} else if v, ok := d.GetOkExists("catalog_type"); !tpgresource.IsEmptyValue(reflect.ValueOf(catalogTypeProp)) && (ok || !reflect.DeepEqual(v, catalogTypeProp)) {
		obj["catalog-type"] = catalogTypeProp
	}

	url, err := tpgresource.ReplaceVars(d, config, "{{BiglakeIcebergBasePath}}iceberg/v1/restcatalog/extensions/projects/{{project}}/catalogs?iceberg-catalog-id={{name}}")
	if err != nil {
		return err
	}

	log.Printf("[DEBUG] Creating new IcebergCatalog: %#v", obj)
	billingProject := ""

	project, err := tpgresource.GetProject(d, config)
	if err != nil {
		return fmt.Errorf("Error fetching project for IcebergCatalog: %s", err)
	}
	billingProject = project

	if parts := regexp.MustCompile(`projects\/([^\/]+)\/`).FindStringSubmatch(url); parts != nil {
		billingProject = parts[1]
	}

	// err == nil indicates that the billing_project value was found
	if bp, err := tpgresource.GetBillingProject(d, config); err == nil {
		billingProject = bp
	}

	headers := make(http.Header)
	res, err := transport_tpg.SendRequest(transport_tpg.SendRequestOptions{
		Config:    config,
		Method:    "POST",
		Project:   billingProject,
		RawURL:    url,
		UserAgent: userAgent,
		Body:      obj,
		Timeout:   d.Timeout(schema.TimeoutCreate),
		Headers:   headers,
	})
	if err != nil {
		return fmt.Errorf("Error creating IcebergCatalog: %s", err)
	}

	// Store the ID now
	id, err := tpgresource.ReplaceVars(d, config, "iceberg/v1/restcatalog/extensions/projects/{{project}}/catalogs/{{name}}")
	if err != nil {
		return fmt.Errorf("Error constructing id: %s", err)
	}
	d.SetId(id)

	identity, err := d.Identity()
	if err == nil && identity != nil {
		if nameValue, ok := d.GetOk("name"); ok && nameValue.(string) != "" {
			if err = identity.Set("name", nameValue.(string)); err != nil {
				return fmt.Errorf("Error setting name: %s", err)
			}
		}
		if projectValue, ok := d.GetOk("project"); ok && projectValue.(string) != "" {
			if err = identity.Set("project", projectValue.(string)); err != nil {
				return fmt.Errorf("Error setting project: %s", err)
			}
		}
	} else {
		log.Printf("[DEBUG] (Create) identity not set: %s", err)
	}

	log.Printf("[DEBUG] Finished creating IcebergCatalog %q: %#v", d.Id(), res)

	return resourceBiglakeIcebergIcebergCatalogRead(d, meta)
}

func resourceBiglakeIcebergIcebergCatalogRead(d *schema.ResourceData, meta interface{}) error {
	config := meta.(*transport_tpg.Config)
	userAgent, err := tpgresource.GenerateUserAgentString(d, config.UserAgent)
	if err != nil {
		return err
	}

	url, err := tpgresource.ReplaceVars(d, config, "{{BiglakeIcebergBasePath}}iceberg/v1/restcatalog/extensions/projects/{{project}}/catalogs/{{name}}")
	if err != nil {
		return err
	}

	billingProject := ""

	project, err := tpgresource.GetProject(d, config)
	if err != nil {
		return fmt.Errorf("Error fetching project for IcebergCatalog: %s", err)
	}
	billingProject = project

	if parts := regexp.MustCompile(`projects\/([^\/]+)\/`).FindStringSubmatch(url); parts != nil {
		billingProject = parts[1]
	}

	// err == nil indicates that the billing_project value was found
	if bp, err := tpgresource.GetBillingProject(d, config); err == nil {
		billingProject = bp
	}

	headers := make(http.Header)
	res, err := transport_tpg.SendRequest(transport_tpg.SendRequestOptions{
		Config:    config,
		Method:    "GET",
		Project:   billingProject,
		RawURL:    url,
		UserAgent: userAgent,
		Headers:   headers,
	})
	if err != nil {
		return transport_tpg.HandleNotFoundError(err, d, fmt.Sprintf("BiglakeIcebergIcebergCatalog %q", d.Id()))
	}

	if err := d.Set("project", project); err != nil {
		return fmt.Errorf("Error reading IcebergCatalog: %s", err)
	}

	if err := d.Set("credential_mode", flattenBiglakeIcebergIcebergCatalogCredentialMode(res["credential-mode"], d, config)); err != nil {
		return fmt.Errorf("Error reading IcebergCatalog: %s", err)
	}
	if err := d.Set("biglake_service_account", flattenBiglakeIcebergIcebergCatalogBiglakeServiceAccount(res["biglake-service-account"], d, config)); err != nil {
		return fmt.Errorf("Error reading IcebergCatalog: %s", err)
	}
	if err := d.Set("catalog_type", flattenBiglakeIcebergIcebergCatalogCatalogType(res["catalog-type"], d, config)); err != nil {
		return fmt.Errorf("Error reading IcebergCatalog: %s", err)
	}
	if err := d.Set("default_location", flattenBiglakeIcebergIcebergCatalogDefaultLocation(res["default-location"], d, config)); err != nil {
		return fmt.Errorf("Error reading IcebergCatalog: %s", err)
	}
	if err := d.Set("storage_regions", flattenBiglakeIcebergIcebergCatalogStorageRegions(res["storage-regions"], d, config)); err != nil {
		return fmt.Errorf("Error reading IcebergCatalog: %s", err)
	}
	if err := d.Set("create_time", flattenBiglakeIcebergIcebergCatalogCreateTime(res["create-time"], d, config)); err != nil {
		return fmt.Errorf("Error reading IcebergCatalog: %s", err)
	}
	if err := d.Set("update_time", flattenBiglakeIcebergIcebergCatalogUpdateTime(res["update-time"], d, config)); err != nil {
		return fmt.Errorf("Error reading IcebergCatalog: %s", err)
	}
	if err := d.Set("replicas", flattenBiglakeIcebergIcebergCatalogReplicas(res["replicas"], d, config)); err != nil {
		return fmt.Errorf("Error reading IcebergCatalog: %s", err)
	}

	identity, err := d.Identity()
	if err == nil && identity != nil {
		if v, ok := identity.GetOk("name"); !ok && v == "" {
			err = identity.Set("name", d.Get("name").(string))
			if err != nil {
				return fmt.Errorf("Error setting name: %s", err)
			}
		}
		if v, ok := identity.GetOk("project"); !ok && v == "" {
			err = identity.Set("project", d.Get("project").(string))
			if err != nil {
				return fmt.Errorf("Error setting project: %s", err)
			}
		}
	} else {
		log.Printf("[DEBUG] (Read) identity not set: %s", err)
	}

	return nil
}

func resourceBiglakeIcebergIcebergCatalogUpdate(d *schema.ResourceData, meta interface{}) error {
	config := meta.(*transport_tpg.Config)
	userAgent, err := tpgresource.GenerateUserAgentString(d, config.UserAgent)
	if err != nil {
		return err
	}

	billingProject := ""

	project, err := tpgresource.GetProject(d, config)
	if err != nil {
		return fmt.Errorf("Error fetching project for IcebergCatalog: %s", err)
	}
	billingProject = project

	obj := make(map[string]interface{})
	credentialModeProp, err := expandBiglakeIcebergIcebergCatalogCredentialMode(d.Get("credential_mode"), d, config)
	if err != nil {
		return err
	} else if v, ok := d.GetOkExists("credential_mode"); !tpgresource.IsEmptyValue(reflect.ValueOf(v)) && (ok || !reflect.DeepEqual(v, credentialModeProp)) {
		obj["credential-mode"] = credentialModeProp
	}

	url, err := tpgresource.ReplaceVars(d, config, "{{BiglakeIcebergBasePath}}iceberg/v1/restcatalog/extensions/projects/{{project}}/catalogs/{{name}}")
	if err != nil {
		return err
	}

	log.Printf("[DEBUG] Updating IcebergCatalog %q: %#v", d.Id(), obj)
	headers := make(http.Header)
	updateMask := []string{}

	// The custom logic is that server only respects property name not the json name for updateMask.
	// This will apply to all future updateable fields if they have a kebab-case json name override.
	// This does not apply to any field with a camelCase or snake_case name.
	if d.HasChange("credential_mode") {
		updateMask = append(updateMask, "credential_mode")
	}
	// updateMask is a URL parameter but not present in the schema, so ReplaceVars
	// won't set it
	url, err = transport_tpg.AddQueryParams(url, map[string]string{"updateMask": strings.Join(updateMask, ",")})
	if err != nil {
		return err
	}

	// err == nil indicates that the billing_project value was found
	if bp, err := tpgresource.GetBillingProject(d, config); err == nil {
		billingProject = bp
	}

	// if updateMask is empty we are not updating anything so skip the post
	if len(updateMask) > 0 {
		res, err := transport_tpg.SendRequest(transport_tpg.SendRequestOptions{
			Config:    config,
			Method:    "PATCH",
			Project:   billingProject,
			RawURL:    url,
			UserAgent: userAgent,
			Body:      obj,
			Timeout:   d.Timeout(schema.TimeoutUpdate),
			Headers:   headers,
		})

		if err != nil {
			return fmt.Errorf("Error updating IcebergCatalog %q: %s", d.Id(), err)
		} else {
			log.Printf("[DEBUG] Finished updating IcebergCatalog %q: %#v", d.Id(), res)
		}

	}

	return resourceBiglakeIcebergIcebergCatalogRead(d, meta)
}

func resourceBiglakeIcebergIcebergCatalogDelete(d *schema.ResourceData, meta interface{}) error {
	config := meta.(*transport_tpg.Config)
	userAgent, err := tpgresource.GenerateUserAgentString(d, config.UserAgent)
	if err != nil {
		return err
	}

	billingProject := ""

	project, err := tpgresource.GetProject(d, config)
	if err != nil {
		return fmt.Errorf("Error fetching project for IcebergCatalog: %s", err)
	}
	billingProject = project

	url, err := tpgresource.ReplaceVars(d, config, "{{BiglakeIcebergBasePath}}iceberg/v1/restcatalog/extensions/projects/{{project}}/catalogs/{{name}}")
	if err != nil {
		return err
	}

	var obj map[string]interface{}
	if parts := regexp.MustCompile(`projects\/([^\/]+)\/`).FindStringSubmatch(url); parts != nil {
		billingProject = parts[1]
	}

	// err == nil indicates that the billing_project value was found
	if bp, err := tpgresource.GetBillingProject(d, config); err == nil {
		billingProject = bp
	}

	headers := make(http.Header)

	log.Printf("[DEBUG] Deleting IcebergCatalog %q", d.Id())
	res, err := transport_tpg.SendRequest(transport_tpg.SendRequestOptions{
		Config:    config,
		Method:    "DELETE",
		Project:   billingProject,
		RawURL:    url,
		UserAgent: userAgent,
		Body:      obj,
		Timeout:   d.Timeout(schema.TimeoutDelete),
		Headers:   headers,
	})
	if err != nil {
		return transport_tpg.HandleNotFoundError(err, d, "IcebergCatalog")
	}

	log.Printf("[DEBUG] Finished deleting IcebergCatalog %q: %#v", d.Id(), res)
	return nil
}

func resourceBiglakeIcebergIcebergCatalogImport(d *schema.ResourceData, meta interface{}) ([]*schema.ResourceData, error) {
	config := meta.(*transport_tpg.Config)
	if err := tpgresource.ParseImportId([]string{
		"^iceberg/v1/restcatalog/extensions/projects/(?P<project>[^/]+)/catalogs/(?P<name>[^/]+)$",
		"^(?P<project>[^/]+)/(?P<name>[^/]+)$",
		"^(?P<name>[^/]+)$",
	}, d, config); err != nil {
		return nil, err
	}

	// Replace import id for the resource id
	id, err := tpgresource.ReplaceVars(d, config, "iceberg/v1/restcatalog/extensions/projects/{{project}}/catalogs/{{name}}")
	if err != nil {
		return nil, fmt.Errorf("Error constructing id: %s", err)
	}
	d.SetId(id)

	return []*schema.ResourceData{d}, nil
}

func flattenBiglakeIcebergIcebergCatalogCredentialMode(v interface{}, d *schema.ResourceData, config *transport_tpg.Config) interface{} {
	return v
}

func flattenBiglakeIcebergIcebergCatalogBiglakeServiceAccount(v interface{}, d *schema.ResourceData, config *transport_tpg.Config) interface{} {
	return v
}

func flattenBiglakeIcebergIcebergCatalogCatalogType(v interface{}, d *schema.ResourceData, config *transport_tpg.Config) interface{} {
	return v
}

func flattenBiglakeIcebergIcebergCatalogDefaultLocation(v interface{}, d *schema.ResourceData, config *transport_tpg.Config) interface{} {
	return v
}

func flattenBiglakeIcebergIcebergCatalogStorageRegions(v interface{}, d *schema.ResourceData, config *transport_tpg.Config) interface{} {
	return v
}

func flattenBiglakeIcebergIcebergCatalogCreateTime(v interface{}, d *schema.ResourceData, config *transport_tpg.Config) interface{} {
	return v
}

func flattenBiglakeIcebergIcebergCatalogUpdateTime(v interface{}, d *schema.ResourceData, config *transport_tpg.Config) interface{} {
	return v
}

func flattenBiglakeIcebergIcebergCatalogReplicas(v interface{}, d *schema.ResourceData, config *transport_tpg.Config) interface{} {
	if v == nil {
		return v
	}
	l := v.([]interface{})
	transformed := make([]interface{}, 0, len(l))
	for _, raw := range l {
		original := raw.(map[string]interface{})
		if len(original) < 1 {
			// Do not include empty json objects coming back from the api
			continue
		}
		transformed = append(transformed, map[string]interface{}{
			"region": flattenBiglakeIcebergIcebergCatalogReplicasRegion(original["region"], d, config),
			"state":  flattenBiglakeIcebergIcebergCatalogReplicasState(original["state"], d, config),
		})
	}
	return transformed
}
func flattenBiglakeIcebergIcebergCatalogReplicasRegion(v interface{}, d *schema.ResourceData, config *transport_tpg.Config) interface{} {
	return v
}

func flattenBiglakeIcebergIcebergCatalogReplicasState(v interface{}, d *schema.ResourceData, config *transport_tpg.Config) interface{} {
	return v
}

func expandBiglakeIcebergIcebergCatalogCredentialMode(v interface{}, d tpgresource.TerraformResourceData, config *transport_tpg.Config) (interface{}, error) {
	return v, nil
}

func expandBiglakeIcebergIcebergCatalogCatalogType(v interface{}, d tpgresource.TerraformResourceData, config *transport_tpg.Config) (interface{}, error) {
	return v, nil
}
