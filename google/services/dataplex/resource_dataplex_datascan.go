// Copyright (c) HashiCorp, Inc.
// SPDX-License-Identifier: MPL-2.0

// ----------------------------------------------------------------------------
//
//     ***     AUTO GENERATED CODE    ***    Type: MMv1     ***
//
// ----------------------------------------------------------------------------
//
//     This code is generated by Magic Modules using the following:
//
//     Configuration: https://github.com/GoogleCloudPlatform/magic-modules/tree/main/mmv1/products/dataplex/Datascan.yaml
//     Template:      https://github.com/GoogleCloudPlatform/magic-modules/tree/main/mmv1/templates/terraform/resource.go.tmpl
//
//     DO NOT EDIT this file directly. Any changes made to this file will be
//     overwritten during the next generation cycle.
//
// ----------------------------------------------------------------------------

package dataplex

import (
	"fmt"
	"log"
	"net/http"
	"reflect"
	"strings"
	"time"

	"github.com/hashicorp/terraform-plugin-sdk/v2/helper/customdiff"
	"github.com/hashicorp/terraform-plugin-sdk/v2/helper/schema"

	"github.com/hashicorp/terraform-provider-google/google/tpgresource"
	transport_tpg "github.com/hashicorp/terraform-provider-google/google/transport"
	"github.com/hashicorp/terraform-provider-google/google/verify"
)

func ResourceDataplexDatascan() *schema.Resource {
	return &schema.Resource{
		Create: resourceDataplexDatascanCreate,
		Read:   resourceDataplexDatascanRead,
		Update: resourceDataplexDatascanUpdate,
		Delete: resourceDataplexDatascanDelete,

		Importer: &schema.ResourceImporter{
			State: resourceDataplexDatascanImport,
		},

		Timeouts: &schema.ResourceTimeout{
			Create: schema.DefaultTimeout(5 * time.Minute),
			Update: schema.DefaultTimeout(5 * time.Minute),
			Delete: schema.DefaultTimeout(5 * time.Minute),
		},

		CustomizeDiff: customdiff.All(
			tpgresource.SetLabelsDiffWithoutAttributionLabel,
			tpgresource.DefaultProviderProject,
		),

		Schema: map[string]*schema.Schema{
			"data": {
				Type:        schema.TypeList,
				Required:    true,
				ForceNew:    true,
				Description: `The data source for DataScan.`,
				MaxItems:    1,
				Elem: &schema.Resource{
					Schema: map[string]*schema.Schema{
						"entity": {
							Type:         schema.TypeString,
							Optional:     true,
							ForceNew:     true,
							Description:  `The Dataplex entity that represents the data source(e.g. BigQuery table) for Datascan.`,
							ExactlyOneOf: []string{"data.0.entity", "data.0.resource"},
						},
						"resource": {
							Type:     schema.TypeString,
							Optional: true,
							ForceNew: true,
							Description: `The service-qualified full resource name of the cloud resource for a DataScan job to scan against. The field could be:
(Cloud Storage bucket for DataDiscoveryScan)BigQuery table of type "TABLE" for DataProfileScan/DataQualityScan.`,
							ExactlyOneOf: []string{"data.0.entity", "data.0.resource"},
						},
					},
				},
			},
			"data_scan_id": {
				Type:        schema.TypeString,
				Required:    true,
				ForceNew:    true,
				Description: `DataScan identifier. Must contain only lowercase letters, numbers and hyphens. Must start with a letter. Must end with a number or a letter.`,
			},
			"execution_spec": {
				Type:        schema.TypeList,
				Required:    true,
				Description: `DataScan execution settings.`,
				MaxItems:    1,
				Elem: &schema.Resource{
					Schema: map[string]*schema.Schema{
						"trigger": {
							Type:        schema.TypeList,
							Required:    true,
							Description: `Spec related to how often and when a scan should be triggered.`,
							MaxItems:    1,
							Elem: &schema.Resource{
								Schema: map[string]*schema.Schema{
									"on_demand": {
										Type:        schema.TypeList,
										Optional:    true,
										Description: `The scan runs once via dataScans.run API.`,
										MaxItems:    1,
										Elem: &schema.Resource{
											Schema: map[string]*schema.Schema{},
										},
										ExactlyOneOf: []string{"execution_spec.0.trigger.0.on_demand", "execution_spec.0.trigger.0.schedule"},
									},
									"schedule": {
										Type:        schema.TypeList,
										Optional:    true,
										Description: `The scan is scheduled to run periodically.`,
										MaxItems:    1,
										Elem: &schema.Resource{
											Schema: map[string]*schema.Schema{
												"cron": {
													Type:        schema.TypeString,
													Required:    true,
													Description: `Cron schedule for running scans periodically. This field is required for Schedule scans.`,
												},
											},
										},
										ExactlyOneOf: []string{"execution_spec.0.trigger.0.on_demand", "execution_spec.0.trigger.0.schedule"},
									},
								},
							},
						},
						"field": {
							Type:        schema.TypeString,
							Optional:    true,
							ForceNew:    true,
							Description: `The unnested field (of type Date or Timestamp) that contains values which monotonically increase over time. If not specified, a data scan will run for all data in the table.`,
						},
					},
				},
			},
			"location": {
				Type:        schema.TypeString,
				Required:    true,
				ForceNew:    true,
				Description: `The location where the data scan should reside.`,
			},
			"data_profile_spec": {
				Type:        schema.TypeList,
				Optional:    true,
				Description: `DataProfileScan related setting.`,
				MaxItems:    1,
				Elem: &schema.Resource{
					Schema: map[string]*schema.Schema{
						"exclude_fields": {
							Type:     schema.TypeList,
							Optional: true,
							Description: `The fields to exclude from data profile.
If specified, the fields will be excluded from data profile, regardless of 'include_fields' value.`,
							MaxItems: 1,
							Elem: &schema.Resource{
								Schema: map[string]*schema.Schema{
									"field_names": {
										Type:     schema.TypeList,
										Optional: true,
										Description: `Expected input is a list of fully qualified names of fields as in the schema.
Only top-level field names for nested fields are supported.
For instance, if 'x' is of nested field type, listing 'x' is supported but 'x.y.z' is not supported. Here 'y' and 'y.z' are nested fields of 'x'.`,
										Elem: &schema.Schema{
											Type: schema.TypeString,
										},
									},
								},
							},
						},
						"include_fields": {
							Type:     schema.TypeList,
							Optional: true,
							Description: `The fields to include in data profile.
If not specified, all fields at the time of profile scan job execution are included, except for ones listed in 'exclude_fields'.`,
							MaxItems: 1,
							Elem: &schema.Resource{
								Schema: map[string]*schema.Schema{
									"field_names": {
										Type:     schema.TypeList,
										Optional: true,
										Description: `Expected input is a list of fully qualified names of fields as in the schema.
Only top-level field names for nested fields are supported.
For instance, if 'x' is of nested field type, listing 'x' is supported but 'x.y.z' is not supported. Here 'y' and 'y.z' are nested fields of 'x'.`,
										Elem: &schema.Schema{
											Type: schema.TypeString,
										},
									},
								},
							},
						},
						"post_scan_actions": {
							Type:        schema.TypeList,
							Optional:    true,
							Description: `Actions to take upon job completion.`,
							MaxItems:    1,
							Elem: &schema.Resource{
								Schema: map[string]*schema.Schema{
									"bigquery_export": {
										Type:        schema.TypeList,
										Optional:    true,
										Description: `If set, results will be exported to the provided BigQuery table.`,
										MaxItems:    1,
										Elem: &schema.Resource{
											Schema: map[string]*schema.Schema{
												"results_table": {
													Type:     schema.TypeString,
													Optional: true,
													Description: `The BigQuery table to export DataProfileScan results to.
Format://bigquery.googleapis.com/projects/PROJECT_ID/datasets/DATASET_ID/tables/TABLE_ID`,
												},
											},
										},
									},
								},
							},
						},
						"row_filter": {
							Type:        schema.TypeString,
							Optional:    true,
							Description: `A filter applied to all rows in a single DataScan job. The filter needs to be a valid SQL expression for a WHERE clause in BigQuery standard SQL syntax. Example: col1 >= 0 AND col2 < 10`,
						},
						"sampling_percent": {
							Type:     schema.TypeFloat,
							Optional: true,
							Description: `The percentage of the records to be selected from the dataset for DataScan.
Value can range between 0.0 and 100.0 with up to 3 significant decimal digits.
Sampling is not applied if 'sampling_percent' is not specified, 0 or 100.`,
						},
					},
				},
				ExactlyOneOf: []string{"data_quality_spec", "data_profile_spec"},
			},
			"data_quality_spec": {
				Type:        schema.TypeList,
				Optional:    true,
				Description: `DataQualityScan related setting.`,
				MaxItems:    1,
				Elem: &schema.Resource{
					Schema: map[string]*schema.Schema{
						"post_scan_actions": {
							Type:        schema.TypeList,
							Optional:    true,
							Description: `Actions to take upon job completion.`,
							MaxItems:    1,
							Elem: &schema.Resource{
								Schema: map[string]*schema.Schema{
									"bigquery_export": {
										Type:        schema.TypeList,
										Optional:    true,
										Description: `If set, results will be exported to the provided BigQuery table.`,
										MaxItems:    1,
										Elem: &schema.Resource{
											Schema: map[string]*schema.Schema{
												"results_table": {
													Type:     schema.TypeString,
													Optional: true,
													Description: `The BigQuery table to export DataQualityScan results to.
Format://bigquery.googleapis.com/projects/PROJECT_ID/datasets/DATASET_ID/tables/TABLE_ID`,
												},
											},
										},
									},
									"notification_report": {
										Type:        schema.TypeList,
										Optional:    true,
										Description: `The configuration of notification report post scan action.`,
										MaxItems:    1,
										Elem: &schema.Resource{
											Schema: map[string]*schema.Schema{
												"recipients": {
													Type:        schema.TypeList,
													Required:    true,
													Description: `The individuals or groups who are designated to receive notifications upon triggers.`,
													MaxItems:    1,
													Elem: &schema.Resource{
														Schema: map[string]*schema.Schema{
															"emails": {
																Type:        schema.TypeList,
																Optional:    true,
																Description: `The email recipients who will receive the DataQualityScan results report.`,
																Elem: &schema.Schema{
																	Type: schema.TypeString,
																},
															},
														},
													},
												},
												"job_end_trigger": {
													Type:        schema.TypeList,
													Optional:    true,
													Description: `This trigger is triggered whenever a scan job run ends, regardless of the result.`,
													MaxItems:    1,
													Elem: &schema.Resource{
														Schema: map[string]*schema.Schema{},
													},
												},
												"job_failure_trigger": {
													Type:        schema.TypeList,
													Optional:    true,
													Description: `This trigger is triggered when the scan job itself fails, regardless of the result.`,
													MaxItems:    1,
													Elem: &schema.Resource{
														Schema: map[string]*schema.Schema{},
													},
												},
												"score_threshold_trigger": {
													Type:        schema.TypeList,
													Optional:    true,
													Description: `This trigger is triggered when the DQ score in the job result is less than a specified input score.`,
													MaxItems:    1,
													Elem: &schema.Resource{
														Schema: map[string]*schema.Schema{
															"score_threshold": {
																Type:        schema.TypeFloat,
																Optional:    true,
																Description: `The score range is in [0,100].`,
															},
														},
													},
												},
											},
										},
									},
								},
							},
						},
						"row_filter": {
							Type:        schema.TypeString,
							Optional:    true,
							Description: `A filter applied to all rows in a single DataScan job. The filter needs to be a valid SQL expression for a WHERE clause in BigQuery standard SQL syntax. Example: col1 >= 0 AND col2 < 10`,
						},
						"rules": {
							Type:        schema.TypeList,
							Optional:    true,
							Description: `The list of rules to evaluate against a data source. At least one rule is required.`,
							MinItems:    1,
							Elem: &schema.Resource{
								Schema: map[string]*schema.Schema{
									"dimension": {
										Type:        schema.TypeString,
										Required:    true,
										Description: `The dimension a rule belongs to. Results are also aggregated at the dimension level. Supported dimensions are ["COMPLETENESS", "ACCURACY", "CONSISTENCY", "VALIDITY", "UNIQUENESS", "INTEGRITY"]`,
									},
									"column": {
										Type:        schema.TypeString,
										Optional:    true,
										Description: `The unnested column which this rule is evaluated against.`,
									},
									"description": {
										Type:     schema.TypeString,
										Optional: true,
										Description: `Description of the rule.
The maximum length is 1,024 characters.`,
									},
									"ignore_null": {
										Type:        schema.TypeBool,
										Optional:    true,
										Description: `Rows with null values will automatically fail a rule, unless ignoreNull is true. In that case, such null rows are trivially considered passing. Only applicable to ColumnMap rules.`,
									},
									"name": {
										Type:     schema.TypeString,
										Optional: true,
										Description: `A mutable name for the rule.
The name must contain only letters (a-z, A-Z), numbers (0-9), or hyphens (-).
The maximum length is 63 characters.
Must start with a letter.
Must end with a number or a letter.`,
									},
									"non_null_expectation": {
										Type:        schema.TypeList,
										Optional:    true,
										Description: `ColumnMap rule which evaluates whether each column value is null.`,
										MaxItems:    1,
										Elem: &schema.Resource{
											Schema: map[string]*schema.Schema{},
										},
									},
									"range_expectation": {
										Type:        schema.TypeList,
										Optional:    true,
										Description: `ColumnMap rule which evaluates whether each column value lies between a specified range.`,
										MaxItems:    1,
										Elem: &schema.Resource{
											Schema: map[string]*schema.Schema{
												"max_value": {
													Type:        schema.TypeString,
													Optional:    true,
													Description: `The maximum column value allowed for a row to pass this validation. At least one of minValue and maxValue need to be provided.`,
												},
												"min_value": {
													Type:        schema.TypeString,
													Optional:    true,
													Description: `The minimum column value allowed for a row to pass this validation. At least one of minValue and maxValue need to be provided.`,
												},
												"strict_max_enabled": {
													Type:     schema.TypeBool,
													Optional: true,
													Description: `Whether each value needs to be strictly lesser than ('<') the maximum, or if equality is allowed.
Only relevant if a maxValue has been defined. Default = false.`,
													Default: false,
												},
												"strict_min_enabled": {
													Type:     schema.TypeBool,
													Optional: true,
													Description: `Whether each value needs to be strictly greater than ('>') the minimum, or if equality is allowed.
Only relevant if a minValue has been defined. Default = false.`,
													Default: false,
												},
											},
										},
									},
									"regex_expectation": {
										Type:        schema.TypeList,
										Optional:    true,
										Description: `ColumnMap rule which evaluates whether each column value matches a specified regex.`,
										MaxItems:    1,
										Elem: &schema.Resource{
											Schema: map[string]*schema.Schema{
												"regex": {
													Type:        schema.TypeString,
													Required:    true,
													Description: `A regular expression the column value is expected to match.`,
												},
											},
										},
									},
									"row_condition_expectation": {
										Type:        schema.TypeList,
										Optional:    true,
										Description: `Table rule which evaluates whether each row passes the specified condition.`,
										MaxItems:    1,
										Elem: &schema.Resource{
											Schema: map[string]*schema.Schema{
												"sql_expression": {
													Type:        schema.TypeString,
													Required:    true,
													Description: `The SQL expression.`,
												},
											},
										},
									},
									"set_expectation": {
										Type:        schema.TypeList,
										Optional:    true,
										Description: `ColumnMap rule which evaluates whether each column value is contained by a specified set.`,
										MaxItems:    1,
										Elem: &schema.Resource{
											Schema: map[string]*schema.Schema{
												"values": {
													Type:        schema.TypeList,
													Required:    true,
													Description: `Expected values for the column value.`,
													Elem: &schema.Schema{
														Type: schema.TypeString,
													},
												},
											},
										},
									},
									"sql_assertion": {
										Type:        schema.TypeList,
										Optional:    true,
										Description: `Table rule which evaluates whether any row matches invalid state.`,
										MaxItems:    1,
										Elem: &schema.Resource{
											Schema: map[string]*schema.Schema{
												"sql_statement": {
													Type:        schema.TypeString,
													Required:    true,
													Description: `The SQL statement.`,
												},
											},
										},
									},
									"statistic_range_expectation": {
										Type:        schema.TypeList,
										Optional:    true,
										Description: `ColumnAggregate rule which evaluates whether the column aggregate statistic lies between a specified range.`,
										MaxItems:    1,
										Elem: &schema.Resource{
											Schema: map[string]*schema.Schema{
												"statistic": {
													Type:         schema.TypeString,
													Required:     true,
													ValidateFunc: verify.ValidateEnum([]string{"STATISTIC_UNDEFINED", "MEAN", "MIN", "MAX"}),
													Description:  `column statistics. Possible values: ["STATISTIC_UNDEFINED", "MEAN", "MIN", "MAX"]`,
												},
												"max_value": {
													Type:     schema.TypeString,
													Optional: true,
													Description: `The maximum column statistic value allowed for a row to pass this validation.
At least one of minValue and maxValue need to be provided.`,
												},
												"min_value": {
													Type:     schema.TypeString,
													Optional: true,
													Description: `The minimum column statistic value allowed for a row to pass this validation.
At least one of minValue and maxValue need to be provided.`,
												},
												"strict_max_enabled": {
													Type:     schema.TypeBool,
													Optional: true,
													Description: `Whether column statistic needs to be strictly lesser than ('<') the maximum, or if equality is allowed.
Only relevant if a maxValue has been defined. Default = false.`,
													Default: false,
												},
												"strict_min_enabled": {
													Type:     schema.TypeBool,
													Optional: true,
													Description: `Whether column statistic needs to be strictly greater than ('>') the minimum, or if equality is allowed.
Only relevant if a minValue has been defined. Default = false.`,
													Default: false,
												},
											},
										},
									},
									"table_condition_expectation": {
										Type:        schema.TypeList,
										Optional:    true,
										Description: `Table rule which evaluates whether the provided expression is true.`,
										MaxItems:    1,
										Elem: &schema.Resource{
											Schema: map[string]*schema.Schema{
												"sql_expression": {
													Type:        schema.TypeString,
													Required:    true,
													Description: `The SQL expression.`,
												},
											},
										},
									},
									"threshold": {
										Type:        schema.TypeFloat,
										Optional:    true,
										Description: `The minimum ratio of passing_rows / total_rows required to pass this rule, with a range of [0.0, 1.0]. 0 indicates default value (i.e. 1.0).`,
									},
									"uniqueness_expectation": {
										Type:        schema.TypeList,
										Optional:    true,
										Description: `Row-level rule which evaluates whether each column value is unique.`,
										MaxItems:    1,
										Elem: &schema.Resource{
											Schema: map[string]*schema.Schema{},
										},
									},
								},
							},
						},
						"sampling_percent": {
							Type:     schema.TypeFloat,
							Optional: true,
							Description: `The percentage of the records to be selected from the dataset for DataScan.
Value can range between 0.0 and 100.0 with up to 3 significant decimal digits.
Sampling is not applied if 'sampling_percent' is not specified, 0 or 100.`,
						},
					},
				},
				ExactlyOneOf: []string{"data_quality_spec", "data_profile_spec"},
			},
			"description": {
				Type:        schema.TypeString,
				Optional:    true,
				Description: `Description of the scan.`,
			},
			"display_name": {
				Type:        schema.TypeString,
				Optional:    true,
				Description: `User friendly display name.`,
			},
			"labels": {
				Type:     schema.TypeMap,
				Optional: true,
				Description: `User-defined labels for the scan. A list of key->value pairs.


**Note**: This field is non-authoritative, and will only manage the labels present in your configuration.
Please refer to the field 'effective_labels' for all of the labels present on the resource.`,
				Elem: &schema.Schema{Type: schema.TypeString},
			},
			"create_time": {
				Type:        schema.TypeString,
				Computed:    true,
				Description: `The time when the scan was created.`,
			},
			"effective_labels": {
				Type:        schema.TypeMap,
				Computed:    true,
				Description: `All of labels (key/value pairs) present on the resource in GCP, including the labels configured through Terraform, other clients and services.`,
				Elem:        &schema.Schema{Type: schema.TypeString},
			},
			"execution_status": {
				Type:        schema.TypeList,
				Computed:    true,
				Description: `Status of the data scan execution.`,
				Elem: &schema.Resource{
					Schema: map[string]*schema.Schema{
						"latest_job_end_time": {
							Type:        schema.TypeString,
							Computed:    true,
							Description: `The time when the latest DataScanJob started.`,
						},
						"latest_job_start_time": {
							Type:        schema.TypeString,
							Computed:    true,
							Description: `The time when the latest DataScanJob ended.`,
						},
					},
				},
			},
			"name": {
				Type:        schema.TypeString,
				Computed:    true,
				Description: `The relative resource name of the scan, of the form: projects/{project}/locations/{locationId}/dataScans/{datascan_id}, where project refers to a project_id or project_number and locationId refers to a GCP region.`,
			},
			"state": {
				Type:        schema.TypeString,
				Computed:    true,
				Description: `Current state of the DataScan.`,
			},
			"terraform_labels": {
				Type:     schema.TypeMap,
				Computed: true,
				Description: `The combination of labels configured directly on the resource
 and default labels configured on the provider.`,
				Elem: &schema.Schema{Type: schema.TypeString},
			},
			"type": {
				Type:        schema.TypeString,
				Computed:    true,
				Description: `The type of DataScan.`,
			},
			"uid": {
				Type:        schema.TypeString,
				Computed:    true,
				Description: `System generated globally unique ID for the scan. This ID will be different if the scan is deleted and re-created with the same name.`,
			},
			"update_time": {
				Type:        schema.TypeString,
				Computed:    true,
				Description: `The time when the scan was last updated.`,
			},
			"project": {
				Type:     schema.TypeString,
				Optional: true,
				Computed: true,
				ForceNew: true,
			},
		},
		UseJSONNumber: true,
	}
}

func resourceDataplexDatascanCreate(d *schema.ResourceData, meta interface{}) error {
	config := meta.(*transport_tpg.Config)
	userAgent, err := tpgresource.GenerateUserAgentString(d, config.UserAgent)
	if err != nil {
		return err
	}

	obj := make(map[string]interface{})
	descriptionProp, err := expandDataplexDatascanDescription(d.Get("description"), d, config)
	if err != nil {
		return err
	} else if v, ok := d.GetOkExists("description"); !tpgresource.IsEmptyValue(reflect.ValueOf(descriptionProp)) && (ok || !reflect.DeepEqual(v, descriptionProp)) {
		obj["description"] = descriptionProp
	}
	displayNameProp, err := expandDataplexDatascanDisplayName(d.Get("display_name"), d, config)
	if err != nil {
		return err
	} else if v, ok := d.GetOkExists("display_name"); !tpgresource.IsEmptyValue(reflect.ValueOf(displayNameProp)) && (ok || !reflect.DeepEqual(v, displayNameProp)) {
		obj["displayName"] = displayNameProp
	}
	dataProp, err := expandDataplexDatascanData(d.Get("data"), d, config)
	if err != nil {
		return err
	} else if v, ok := d.GetOkExists("data"); !tpgresource.IsEmptyValue(reflect.ValueOf(dataProp)) && (ok || !reflect.DeepEqual(v, dataProp)) {
		obj["data"] = dataProp
	}
	executionSpecProp, err := expandDataplexDatascanExecutionSpec(d.Get("execution_spec"), d, config)
	if err != nil {
		return err
	} else if v, ok := d.GetOkExists("execution_spec"); !tpgresource.IsEmptyValue(reflect.ValueOf(executionSpecProp)) && (ok || !reflect.DeepEqual(v, executionSpecProp)) {
		obj["executionSpec"] = executionSpecProp
	}
	dataQualitySpecProp, err := expandDataplexDatascanDataQualitySpec(d.Get("data_quality_spec"), d, config)
	if err != nil {
		return err
	} else if v, ok := d.GetOkExists("data_quality_spec"); !tpgresource.IsEmptyValue(reflect.ValueOf(dataQualitySpecProp)) && (ok || !reflect.DeepEqual(v, dataQualitySpecProp)) {
		obj["dataQualitySpec"] = dataQualitySpecProp
	}
	dataProfileSpecProp, err := expandDataplexDatascanDataProfileSpec(d.Get("data_profile_spec"), d, config)
	if err != nil {
		return err
	} else if v, ok := d.GetOkExists("data_profile_spec"); ok || !reflect.DeepEqual(v, dataProfileSpecProp) {
		obj["dataProfileSpec"] = dataProfileSpecProp
	}
	labelsProp, err := expandDataplexDatascanEffectiveLabels(d.Get("effective_labels"), d, config)
	if err != nil {
		return err
	} else if v, ok := d.GetOkExists("effective_labels"); !tpgresource.IsEmptyValue(reflect.ValueOf(labelsProp)) && (ok || !reflect.DeepEqual(v, labelsProp)) {
		obj["labels"] = labelsProp
	}

	url, err := tpgresource.ReplaceVars(d, config, "{{DataplexBasePath}}projects/{{project}}/locations/{{location}}/dataScans?dataScanId={{data_scan_id}}")
	if err != nil {
		return err
	}

	log.Printf("[DEBUG] Creating new Datascan: %#v", obj)
	billingProject := ""

	project, err := tpgresource.GetProject(d, config)
	if err != nil {
		return fmt.Errorf("Error fetching project for Datascan: %s", err)
	}
	billingProject = project

	// err == nil indicates that the billing_project value was found
	if bp, err := tpgresource.GetBillingProject(d, config); err == nil {
		billingProject = bp
	}

	headers := make(http.Header)
	res, err := transport_tpg.SendRequest(transport_tpg.SendRequestOptions{
		Config:    config,
		Method:    "POST",
		Project:   billingProject,
		RawURL:    url,
		UserAgent: userAgent,
		Body:      obj,
		Timeout:   d.Timeout(schema.TimeoutCreate),
		Headers:   headers,
	})
	if err != nil {
		return fmt.Errorf("Error creating Datascan: %s", err)
	}

	// Store the ID now
	id, err := tpgresource.ReplaceVars(d, config, "projects/{{project}}/locations/{{location}}/dataScans/{{data_scan_id}}")
	if err != nil {
		return fmt.Errorf("Error constructing id: %s", err)
	}
	d.SetId(id)

	err = DataplexOperationWaitTime(
		config, res, project, "Creating Datascan", userAgent,
		d.Timeout(schema.TimeoutCreate))

	if err != nil {
		// The resource didn't actually create
		d.SetId("")
		return fmt.Errorf("Error waiting to create Datascan: %s", err)
	}

	log.Printf("[DEBUG] Finished creating Datascan %q: %#v", d.Id(), res)

	return resourceDataplexDatascanRead(d, meta)
}

func resourceDataplexDatascanRead(d *schema.ResourceData, meta interface{}) error {
	config := meta.(*transport_tpg.Config)
	userAgent, err := tpgresource.GenerateUserAgentString(d, config.UserAgent)
	if err != nil {
		return err
	}

	url, err := tpgresource.ReplaceVars(d, config, "{{DataplexBasePath}}projects/{{project}}/locations/{{location}}/dataScans/{{data_scan_id}}?view=FULL")
	if err != nil {
		return err
	}

	billingProject := ""

	project, err := tpgresource.GetProject(d, config)
	if err != nil {
		return fmt.Errorf("Error fetching project for Datascan: %s", err)
	}
	billingProject = project

	// err == nil indicates that the billing_project value was found
	if bp, err := tpgresource.GetBillingProject(d, config); err == nil {
		billingProject = bp
	}

	headers := make(http.Header)
	res, err := transport_tpg.SendRequest(transport_tpg.SendRequestOptions{
		Config:    config,
		Method:    "GET",
		Project:   billingProject,
		RawURL:    url,
		UserAgent: userAgent,
		Headers:   headers,
	})
	if err != nil {
		return transport_tpg.HandleNotFoundError(err, d, fmt.Sprintf("DataplexDatascan %q", d.Id()))
	}

	if err := d.Set("project", project); err != nil {
		return fmt.Errorf("Error reading Datascan: %s", err)
	}

	if err := d.Set("name", flattenDataplexDatascanName(res["name"], d, config)); err != nil {
		return fmt.Errorf("Error reading Datascan: %s", err)
	}
	if err := d.Set("uid", flattenDataplexDatascanUid(res["uid"], d, config)); err != nil {
		return fmt.Errorf("Error reading Datascan: %s", err)
	}
	if err := d.Set("description", flattenDataplexDatascanDescription(res["description"], d, config)); err != nil {
		return fmt.Errorf("Error reading Datascan: %s", err)
	}
	if err := d.Set("display_name", flattenDataplexDatascanDisplayName(res["displayName"], d, config)); err != nil {
		return fmt.Errorf("Error reading Datascan: %s", err)
	}
	if err := d.Set("labels", flattenDataplexDatascanLabels(res["labels"], d, config)); err != nil {
		return fmt.Errorf("Error reading Datascan: %s", err)
	}
	if err := d.Set("state", flattenDataplexDatascanState(res["state"], d, config)); err != nil {
		return fmt.Errorf("Error reading Datascan: %s", err)
	}
	if err := d.Set("create_time", flattenDataplexDatascanCreateTime(res["createTime"], d, config)); err != nil {
		return fmt.Errorf("Error reading Datascan: %s", err)
	}
	if err := d.Set("update_time", flattenDataplexDatascanUpdateTime(res["updateTime"], d, config)); err != nil {
		return fmt.Errorf("Error reading Datascan: %s", err)
	}
	if err := d.Set("data", flattenDataplexDatascanData(res["data"], d, config)); err != nil {
		return fmt.Errorf("Error reading Datascan: %s", err)
	}
	if err := d.Set("execution_spec", flattenDataplexDatascanExecutionSpec(res["executionSpec"], d, config)); err != nil {
		return fmt.Errorf("Error reading Datascan: %s", err)
	}
	if err := d.Set("execution_status", flattenDataplexDatascanExecutionStatus(res["executionStatus"], d, config)); err != nil {
		return fmt.Errorf("Error reading Datascan: %s", err)
	}
	if err := d.Set("type", flattenDataplexDatascanType(res["type"], d, config)); err != nil {
		return fmt.Errorf("Error reading Datascan: %s", err)
	}
	if err := d.Set("data_quality_spec", flattenDataplexDatascanDataQualitySpec(res["dataQualitySpec"], d, config)); err != nil {
		return fmt.Errorf("Error reading Datascan: %s", err)
	}
	if err := d.Set("data_profile_spec", flattenDataplexDatascanDataProfileSpec(res["dataProfileSpec"], d, config)); err != nil {
		return fmt.Errorf("Error reading Datascan: %s", err)
	}
	if err := d.Set("terraform_labels", flattenDataplexDatascanTerraformLabels(res["labels"], d, config)); err != nil {
		return fmt.Errorf("Error reading Datascan: %s", err)
	}
	if err := d.Set("effective_labels", flattenDataplexDatascanEffectiveLabels(res["labels"], d, config)); err != nil {
		return fmt.Errorf("Error reading Datascan: %s", err)
	}

	return nil
}

func resourceDataplexDatascanUpdate(d *schema.ResourceData, meta interface{}) error {
	config := meta.(*transport_tpg.Config)
	userAgent, err := tpgresource.GenerateUserAgentString(d, config.UserAgent)
	if err != nil {
		return err
	}

	billingProject := ""

	project, err := tpgresource.GetProject(d, config)
	if err != nil {
		return fmt.Errorf("Error fetching project for Datascan: %s", err)
	}
	billingProject = project

	obj := make(map[string]interface{})
	descriptionProp, err := expandDataplexDatascanDescription(d.Get("description"), d, config)
	if err != nil {
		return err
	} else if v, ok := d.GetOkExists("description"); !tpgresource.IsEmptyValue(reflect.ValueOf(v)) && (ok || !reflect.DeepEqual(v, descriptionProp)) {
		obj["description"] = descriptionProp
	}
	displayNameProp, err := expandDataplexDatascanDisplayName(d.Get("display_name"), d, config)
	if err != nil {
		return err
	} else if v, ok := d.GetOkExists("display_name"); !tpgresource.IsEmptyValue(reflect.ValueOf(v)) && (ok || !reflect.DeepEqual(v, displayNameProp)) {
		obj["displayName"] = displayNameProp
	}
	executionSpecProp, err := expandDataplexDatascanExecutionSpec(d.Get("execution_spec"), d, config)
	if err != nil {
		return err
	} else if v, ok := d.GetOkExists("execution_spec"); !tpgresource.IsEmptyValue(reflect.ValueOf(v)) && (ok || !reflect.DeepEqual(v, executionSpecProp)) {
		obj["executionSpec"] = executionSpecProp
	}
	dataQualitySpecProp, err := expandDataplexDatascanDataQualitySpec(d.Get("data_quality_spec"), d, config)
	if err != nil {
		return err
	} else if v, ok := d.GetOkExists("data_quality_spec"); !tpgresource.IsEmptyValue(reflect.ValueOf(v)) && (ok || !reflect.DeepEqual(v, dataQualitySpecProp)) {
		obj["dataQualitySpec"] = dataQualitySpecProp
	}
	dataProfileSpecProp, err := expandDataplexDatascanDataProfileSpec(d.Get("data_profile_spec"), d, config)
	if err != nil {
		return err
	} else if v, ok := d.GetOkExists("data_profile_spec"); ok || !reflect.DeepEqual(v, dataProfileSpecProp) {
		obj["dataProfileSpec"] = dataProfileSpecProp
	}
	labelsProp, err := expandDataplexDatascanEffectiveLabels(d.Get("effective_labels"), d, config)
	if err != nil {
		return err
	} else if v, ok := d.GetOkExists("effective_labels"); !tpgresource.IsEmptyValue(reflect.ValueOf(v)) && (ok || !reflect.DeepEqual(v, labelsProp)) {
		obj["labels"] = labelsProp
	}

	url, err := tpgresource.ReplaceVars(d, config, "{{DataplexBasePath}}projects/{{project}}/locations/{{location}}/dataScans/{{data_scan_id}}")
	if err != nil {
		return err
	}

	log.Printf("[DEBUG] Updating Datascan %q: %#v", d.Id(), obj)
	headers := make(http.Header)
	updateMask := []string{}

	if d.HasChange("description") {
		updateMask = append(updateMask, "description")
	}

	if d.HasChange("display_name") {
		updateMask = append(updateMask, "displayName")
	}

	if d.HasChange("execution_spec") {
		updateMask = append(updateMask, "executionSpec")
	}

	if d.HasChange("data_quality_spec") {
		updateMask = append(updateMask, "dataQualitySpec")
	}

	if d.HasChange("data_profile_spec") {
		updateMask = append(updateMask, "dataProfileSpec")
	}

	if d.HasChange("effective_labels") {
		updateMask = append(updateMask, "labels")
	}
	// updateMask is a URL parameter but not present in the schema, so ReplaceVars
	// won't set it
	url, err = transport_tpg.AddQueryParams(url, map[string]string{"updateMask": strings.Join(updateMask, ",")})
	if err != nil {
		return err
	}

	// err == nil indicates that the billing_project value was found
	if bp, err := tpgresource.GetBillingProject(d, config); err == nil {
		billingProject = bp
	}

	// if updateMask is empty we are not updating anything so skip the post
	if len(updateMask) > 0 {
		res, err := transport_tpg.SendRequest(transport_tpg.SendRequestOptions{
			Config:    config,
			Method:    "PATCH",
			Project:   billingProject,
			RawURL:    url,
			UserAgent: userAgent,
			Body:      obj,
			Timeout:   d.Timeout(schema.TimeoutUpdate),
			Headers:   headers,
		})

		if err != nil {
			return fmt.Errorf("Error updating Datascan %q: %s", d.Id(), err)
		} else {
			log.Printf("[DEBUG] Finished updating Datascan %q: %#v", d.Id(), res)
		}

		err = DataplexOperationWaitTime(
			config, res, project, "Updating Datascan", userAgent,
			d.Timeout(schema.TimeoutUpdate))

		if err != nil {
			return err
		}
	}

	return resourceDataplexDatascanRead(d, meta)
}

func resourceDataplexDatascanDelete(d *schema.ResourceData, meta interface{}) error {
	config := meta.(*transport_tpg.Config)
	userAgent, err := tpgresource.GenerateUserAgentString(d, config.UserAgent)
	if err != nil {
		return err
	}

	billingProject := ""

	project, err := tpgresource.GetProject(d, config)
	if err != nil {
		return fmt.Errorf("Error fetching project for Datascan: %s", err)
	}
	billingProject = project

	url, err := tpgresource.ReplaceVars(d, config, "{{DataplexBasePath}}projects/{{project}}/locations/{{location}}/dataScans/{{data_scan_id}}")
	if err != nil {
		return err
	}

	var obj map[string]interface{}

	// err == nil indicates that the billing_project value was found
	if bp, err := tpgresource.GetBillingProject(d, config); err == nil {
		billingProject = bp
	}

	headers := make(http.Header)

	log.Printf("[DEBUG] Deleting Datascan %q", d.Id())
	res, err := transport_tpg.SendRequest(transport_tpg.SendRequestOptions{
		Config:    config,
		Method:    "DELETE",
		Project:   billingProject,
		RawURL:    url,
		UserAgent: userAgent,
		Body:      obj,
		Timeout:   d.Timeout(schema.TimeoutDelete),
		Headers:   headers,
	})
	if err != nil {
		return transport_tpg.HandleNotFoundError(err, d, "Datascan")
	}

	err = DataplexOperationWaitTime(
		config, res, project, "Deleting Datascan", userAgent,
		d.Timeout(schema.TimeoutDelete))

	if err != nil {
		return err
	}

	log.Printf("[DEBUG] Finished deleting Datascan %q: %#v", d.Id(), res)
	return nil
}

func resourceDataplexDatascanImport(d *schema.ResourceData, meta interface{}) ([]*schema.ResourceData, error) {
	config := meta.(*transport_tpg.Config)
	if err := tpgresource.ParseImportId([]string{
		"^projects/(?P<project>[^/]+)/locations/(?P<location>[^/]+)/dataScans/(?P<data_scan_id>[^/]+)$",
		"^(?P<project>[^/]+)/(?P<location>[^/]+)/(?P<data_scan_id>[^/]+)$",
		"^(?P<location>[^/]+)/(?P<data_scan_id>[^/]+)$",
		"^(?P<data_scan_id>[^/]+)$",
	}, d, config); err != nil {
		return nil, err
	}

	// Replace import id for the resource id
	id, err := tpgresource.ReplaceVars(d, config, "projects/{{project}}/locations/{{location}}/dataScans/{{data_scan_id}}")
	if err != nil {
		return nil, fmt.Errorf("Error constructing id: %s", err)
	}
	d.SetId(id)

	return []*schema.ResourceData{d}, nil
}

func flattenDataplexDatascanName(v interface{}, d *schema.ResourceData, config *transport_tpg.Config) interface{} {
	return v
}

func flattenDataplexDatascanUid(v interface{}, d *schema.ResourceData, config *transport_tpg.Config) interface{} {
	return v
}

func flattenDataplexDatascanDescription(v interface{}, d *schema.ResourceData, config *transport_tpg.Config) interface{} {
	return v
}

func flattenDataplexDatascanDisplayName(v interface{}, d *schema.ResourceData, config *transport_tpg.Config) interface{} {
	return v
}

func flattenDataplexDatascanLabels(v interface{}, d *schema.ResourceData, config *transport_tpg.Config) interface{} {
	if v == nil {
		return v
	}

	transformed := make(map[string]interface{})
	if l, ok := d.GetOkExists("labels"); ok {
		for k := range l.(map[string]interface{}) {
			transformed[k] = v.(map[string]interface{})[k]
		}
	}

	return transformed
}

func flattenDataplexDatascanState(v interface{}, d *schema.ResourceData, config *transport_tpg.Config) interface{} {
	return v
}

func flattenDataplexDatascanCreateTime(v interface{}, d *schema.ResourceData, config *transport_tpg.Config) interface{} {
	return v
}

func flattenDataplexDatascanUpdateTime(v interface{}, d *schema.ResourceData, config *transport_tpg.Config) interface{} {
	return v
}

func flattenDataplexDatascanData(v interface{}, d *schema.ResourceData, config *transport_tpg.Config) interface{} {
	if v == nil {
		return nil
	}
	original := v.(map[string]interface{})
	if len(original) == 0 {
		return nil
	}
	transformed := make(map[string]interface{})
	transformed["entity"] =
		flattenDataplexDatascanDataEntity(original["entity"], d, config)
	transformed["resource"] =
		flattenDataplexDatascanDataResource(original["resource"], d, config)
	return []interface{}{transformed}
}
func flattenDataplexDatascanDataEntity(v interface{}, d *schema.ResourceData, config *transport_tpg.Config) interface{} {
	return v
}

func flattenDataplexDatascanDataResource(v interface{}, d *schema.ResourceData, config *transport_tpg.Config) interface{} {
	return v
}

func flattenDataplexDatascanExecutionSpec(v interface{}, d *schema.ResourceData, config *transport_tpg.Config) interface{} {
	if v == nil {
		return nil
	}
	original := v.(map[string]interface{})
	if len(original) == 0 {
		return nil
	}
	transformed := make(map[string]interface{})
	transformed["trigger"] =
		flattenDataplexDatascanExecutionSpecTrigger(original["trigger"], d, config)
	transformed["field"] =
		flattenDataplexDatascanExecutionSpecField(original["field"], d, config)
	return []interface{}{transformed}
}
func flattenDataplexDatascanExecutionSpecTrigger(v interface{}, d *schema.ResourceData, config *transport_tpg.Config) interface{} {
	if v == nil {
		return nil
	}
	original := v.(map[string]interface{})
	if len(original) == 0 {
		return nil
	}
	transformed := make(map[string]interface{})
	transformed["on_demand"] =
		flattenDataplexDatascanExecutionSpecTriggerOnDemand(original["onDemand"], d, config)
	transformed["schedule"] =
		flattenDataplexDatascanExecutionSpecTriggerSchedule(original["schedule"], d, config)
	return []interface{}{transformed}
}
func flattenDataplexDatascanExecutionSpecTriggerOnDemand(v interface{}, d *schema.ResourceData, config *transport_tpg.Config) interface{} {
	if v == nil {
		return nil
	}
	transformed := make(map[string]interface{})
	return []interface{}{transformed}
}

func flattenDataplexDatascanExecutionSpecTriggerSchedule(v interface{}, d *schema.ResourceData, config *transport_tpg.Config) interface{} {
	if v == nil {
		return nil
	}
	original := v.(map[string]interface{})
	if len(original) == 0 {
		return nil
	}
	transformed := make(map[string]interface{})
	transformed["cron"] =
		flattenDataplexDatascanExecutionSpecTriggerScheduleCron(original["cron"], d, config)
	return []interface{}{transformed}
}
func flattenDataplexDatascanExecutionSpecTriggerScheduleCron(v interface{}, d *schema.ResourceData, config *transport_tpg.Config) interface{} {
	return v
}

func flattenDataplexDatascanExecutionSpecField(v interface{}, d *schema.ResourceData, config *transport_tpg.Config) interface{} {
	return v
}

func flattenDataplexDatascanExecutionStatus(v interface{}, d *schema.ResourceData, config *transport_tpg.Config) interface{} {
	if v == nil {
		return nil
	}
	original := v.(map[string]interface{})
	if len(original) == 0 {
		return nil
	}
	transformed := make(map[string]interface{})
	transformed["latest_job_end_time"] =
		flattenDataplexDatascanExecutionStatusLatestJobEndTime(original["latestJobEndTime"], d, config)
	transformed["latest_job_start_time"] =
		flattenDataplexDatascanExecutionStatusLatestJobStartTime(original["latestJobStartTime"], d, config)
	return []interface{}{transformed}
}
func flattenDataplexDatascanExecutionStatusLatestJobEndTime(v interface{}, d *schema.ResourceData, config *transport_tpg.Config) interface{} {
	return v
}

func flattenDataplexDatascanExecutionStatusLatestJobStartTime(v interface{}, d *schema.ResourceData, config *transport_tpg.Config) interface{} {
	return v
}

func flattenDataplexDatascanType(v interface{}, d *schema.ResourceData, config *transport_tpg.Config) interface{} {
	return v
}

func flattenDataplexDatascanDataQualitySpec(v interface{}, d *schema.ResourceData, config *transport_tpg.Config) interface{} {
	if v == nil {
		return nil
	}
	original := v.(map[string]interface{})
	if len(original) == 0 {
		return nil
	}
	transformed := make(map[string]interface{})
	transformed["sampling_percent"] =
		flattenDataplexDatascanDataQualitySpecSamplingPercent(original["samplingPercent"], d, config)
	transformed["row_filter"] =
		flattenDataplexDatascanDataQualitySpecRowFilter(original["rowFilter"], d, config)
	transformed["post_scan_actions"] =
		flattenDataplexDatascanDataQualitySpecPostScanActions(original["postScanActions"], d, config)
	transformed["rules"] =
		flattenDataplexDatascanDataQualitySpecRules(original["rules"], d, config)
	return []interface{}{transformed}
}
func flattenDataplexDatascanDataQualitySpecSamplingPercent(v interface{}, d *schema.ResourceData, config *transport_tpg.Config) interface{} {
	return v
}

func flattenDataplexDatascanDataQualitySpecRowFilter(v interface{}, d *schema.ResourceData, config *transport_tpg.Config) interface{} {
	return v
}

func flattenDataplexDatascanDataQualitySpecPostScanActions(v interface{}, d *schema.ResourceData, config *transport_tpg.Config) interface{} {
	if v == nil {
		return nil
	}
	original := v.(map[string]interface{})
	if len(original) == 0 {
		return nil
	}
	transformed := make(map[string]interface{})
	transformed["bigquery_export"] =
		flattenDataplexDatascanDataQualitySpecPostScanActionsBigqueryExport(original["bigqueryExport"], d, config)
	transformed["notification_report"] =
		flattenDataplexDatascanDataQualitySpecPostScanActionsNotificationReport(original["notificationReport"], d, config)
	return []interface{}{transformed}
}
func flattenDataplexDatascanDataQualitySpecPostScanActionsBigqueryExport(v interface{}, d *schema.ResourceData, config *transport_tpg.Config) interface{} {
	if v == nil {
		return nil
	}
	original := v.(map[string]interface{})
	if len(original) == 0 {
		return nil
	}
	transformed := make(map[string]interface{})
	transformed["results_table"] =
		flattenDataplexDatascanDataQualitySpecPostScanActionsBigqueryExportResultsTable(original["resultsTable"], d, config)
	return []interface{}{transformed}
}
func flattenDataplexDatascanDataQualitySpecPostScanActionsBigqueryExportResultsTable(v interface{}, d *schema.ResourceData, config *transport_tpg.Config) interface{} {
	return v
}

func flattenDataplexDatascanDataQualitySpecPostScanActionsNotificationReport(v interface{}, d *schema.ResourceData, config *transport_tpg.Config) interface{} {
	if v == nil {
		return nil
	}
	original := v.(map[string]interface{})
	if len(original) == 0 {
		return nil
	}
	transformed := make(map[string]interface{})
	transformed["recipients"] =
		flattenDataplexDatascanDataQualitySpecPostScanActionsNotificationReportRecipients(original["recipients"], d, config)
	transformed["score_threshold_trigger"] =
		flattenDataplexDatascanDataQualitySpecPostScanActionsNotificationReportScoreThresholdTrigger(original["scoreThresholdTrigger"], d, config)
	transformed["job_failure_trigger"] =
		flattenDataplexDatascanDataQualitySpecPostScanActionsNotificationReportJobFailureTrigger(original["jobFailureTrigger"], d, config)
	transformed["job_end_trigger"] =
		flattenDataplexDatascanDataQualitySpecPostScanActionsNotificationReportJobEndTrigger(original["jobEndTrigger"], d, config)
	return []interface{}{transformed}
}
func flattenDataplexDatascanDataQualitySpecPostScanActionsNotificationReportRecipients(v interface{}, d *schema.ResourceData, config *transport_tpg.Config) interface{} {
	if v == nil {
		return nil
	}
	original := v.(map[string]interface{})
	if len(original) == 0 {
		return nil
	}
	transformed := make(map[string]interface{})
	transformed["emails"] =
		flattenDataplexDatascanDataQualitySpecPostScanActionsNotificationReportRecipientsEmails(original["emails"], d, config)
	return []interface{}{transformed}
}
func flattenDataplexDatascanDataQualitySpecPostScanActionsNotificationReportRecipientsEmails(v interface{}, d *schema.ResourceData, config *transport_tpg.Config) interface{} {
	return v
}

func flattenDataplexDatascanDataQualitySpecPostScanActionsNotificationReportScoreThresholdTrigger(v interface{}, d *schema.ResourceData, config *transport_tpg.Config) interface{} {
	if v == nil {
		return nil
	}
	original := v.(map[string]interface{})
	if len(original) == 0 {
		return nil
	}
	transformed := make(map[string]interface{})
	transformed["score_threshold"] =
		flattenDataplexDatascanDataQualitySpecPostScanActionsNotificationReportScoreThresholdTriggerScoreThreshold(original["scoreThreshold"], d, config)
	return []interface{}{transformed}
}
func flattenDataplexDatascanDataQualitySpecPostScanActionsNotificationReportScoreThresholdTriggerScoreThreshold(v interface{}, d *schema.ResourceData, config *transport_tpg.Config) interface{} {
	return v
}

func flattenDataplexDatascanDataQualitySpecPostScanActionsNotificationReportJobFailureTrigger(v interface{}, d *schema.ResourceData, config *transport_tpg.Config) interface{} {
	if v == nil {
		return nil
	}
	transformed := make(map[string]interface{})
	return []interface{}{transformed}
}

func flattenDataplexDatascanDataQualitySpecPostScanActionsNotificationReportJobEndTrigger(v interface{}, d *schema.ResourceData, config *transport_tpg.Config) interface{} {
	if v == nil {
		return nil
	}
	transformed := make(map[string]interface{})
	return []interface{}{transformed}
}

func flattenDataplexDatascanDataQualitySpecRules(v interface{}, d *schema.ResourceData, config *transport_tpg.Config) interface{} {
	if v == nil {
		return v
	}
	l := v.([]interface{})
	transformed := make([]interface{}, 0, len(l))
	for _, raw := range l {
		original := raw.(map[string]interface{})
		if len(original) < 1 {
			// Do not include empty json objects coming back from the api
			continue
		}
		transformed = append(transformed, map[string]interface{}{
			"column":                      flattenDataplexDatascanDataQualitySpecRulesColumn(original["column"], d, config),
			"ignore_null":                 flattenDataplexDatascanDataQualitySpecRulesIgnoreNull(original["ignoreNull"], d, config),
			"dimension":                   flattenDataplexDatascanDataQualitySpecRulesDimension(original["dimension"], d, config),
			"threshold":                   flattenDataplexDatascanDataQualitySpecRulesThreshold(original["threshold"], d, config),
			"name":                        flattenDataplexDatascanDataQualitySpecRulesName(original["name"], d, config),
			"description":                 flattenDataplexDatascanDataQualitySpecRulesDescription(original["description"], d, config),
			"range_expectation":           flattenDataplexDatascanDataQualitySpecRulesRangeExpectation(original["rangeExpectation"], d, config),
			"non_null_expectation":        flattenDataplexDatascanDataQualitySpecRulesNonNullExpectation(original["nonNullExpectation"], d, config),
			"set_expectation":             flattenDataplexDatascanDataQualitySpecRulesSetExpectation(original["setExpectation"], d, config),
			"regex_expectation":           flattenDataplexDatascanDataQualitySpecRulesRegexExpectation(original["regexExpectation"], d, config),
			"uniqueness_expectation":      flattenDataplexDatascanDataQualitySpecRulesUniquenessExpectation(original["uniquenessExpectation"], d, config),
			"statistic_range_expectation": flattenDataplexDatascanDataQualitySpecRulesStatisticRangeExpectation(original["statisticRangeExpectation"], d, config),
			"row_condition_expectation":   flattenDataplexDatascanDataQualitySpecRulesRowConditionExpectation(original["rowConditionExpectation"], d, config),
			"table_condition_expectation": flattenDataplexDatascanDataQualitySpecRulesTableConditionExpectation(original["tableConditionExpectation"], d, config),
			"sql_assertion":               flattenDataplexDatascanDataQualitySpecRulesSqlAssertion(original["sqlAssertion"], d, config),
		})
	}
	return transformed
}
func flattenDataplexDatascanDataQualitySpecRulesColumn(v interface{}, d *schema.ResourceData, config *transport_tpg.Config) interface{} {
	return v
}

func flattenDataplexDatascanDataQualitySpecRulesIgnoreNull(v interface{}, d *schema.ResourceData, config *transport_tpg.Config) interface{} {
	return v
}

func flattenDataplexDatascanDataQualitySpecRulesDimension(v interface{}, d *schema.ResourceData, config *transport_tpg.Config) interface{} {
	return v
}

func flattenDataplexDatascanDataQualitySpecRulesThreshold(v interface{}, d *schema.ResourceData, config *transport_tpg.Config) interface{} {
	return v
}

func flattenDataplexDatascanDataQualitySpecRulesName(v interface{}, d *schema.ResourceData, config *transport_tpg.Config) interface{} {
	return v
}

func flattenDataplexDatascanDataQualitySpecRulesDescription(v interface{}, d *schema.ResourceData, config *transport_tpg.Config) interface{} {
	return v
}

func flattenDataplexDatascanDataQualitySpecRulesRangeExpectation(v interface{}, d *schema.ResourceData, config *transport_tpg.Config) interface{} {
	if v == nil {
		return nil
	}
	original := v.(map[string]interface{})
	if len(original) == 0 {
		return nil
	}
	transformed := make(map[string]interface{})
	transformed["min_value"] =
		flattenDataplexDatascanDataQualitySpecRulesRangeExpectationMinValue(original["minValue"], d, config)
	transformed["max_value"] =
		flattenDataplexDatascanDataQualitySpecRulesRangeExpectationMaxValue(original["maxValue"], d, config)
	transformed["strict_min_enabled"] =
		flattenDataplexDatascanDataQualitySpecRulesRangeExpectationStrictMinEnabled(original["strictMinEnabled"], d, config)
	transformed["strict_max_enabled"] =
		flattenDataplexDatascanDataQualitySpecRulesRangeExpectationStrictMaxEnabled(original["strictMaxEnabled"], d, config)
	return []interface{}{transformed}
}
func flattenDataplexDatascanDataQualitySpecRulesRangeExpectationMinValue(v interface{}, d *schema.ResourceData, config *transport_tpg.Config) interface{} {
	return v
}

func flattenDataplexDatascanDataQualitySpecRulesRangeExpectationMaxValue(v interface{}, d *schema.ResourceData, config *transport_tpg.Config) interface{} {
	return v
}

func flattenDataplexDatascanDataQualitySpecRulesRangeExpectationStrictMinEnabled(v interface{}, d *schema.ResourceData, config *transport_tpg.Config) interface{} {
	return v
}

func flattenDataplexDatascanDataQualitySpecRulesRangeExpectationStrictMaxEnabled(v interface{}, d *schema.ResourceData, config *transport_tpg.Config) interface{} {
	return v
}

func flattenDataplexDatascanDataQualitySpecRulesNonNullExpectation(v interface{}, d *schema.ResourceData, config *transport_tpg.Config) interface{} {
	if v == nil {
		return nil
	}
	transformed := make(map[string]interface{})
	return []interface{}{transformed}
}

func flattenDataplexDatascanDataQualitySpecRulesSetExpectation(v interface{}, d *schema.ResourceData, config *transport_tpg.Config) interface{} {
	if v == nil {
		return nil
	}
	original := v.(map[string]interface{})
	if len(original) == 0 {
		return nil
	}
	transformed := make(map[string]interface{})
	transformed["values"] =
		flattenDataplexDatascanDataQualitySpecRulesSetExpectationValues(original["values"], d, config)
	return []interface{}{transformed}
}
func flattenDataplexDatascanDataQualitySpecRulesSetExpectationValues(v interface{}, d *schema.ResourceData, config *transport_tpg.Config) interface{} {
	return v
}

func flattenDataplexDatascanDataQualitySpecRulesRegexExpectation(v interface{}, d *schema.ResourceData, config *transport_tpg.Config) interface{} {
	if v == nil {
		return nil
	}
	original := v.(map[string]interface{})
	if len(original) == 0 {
		return nil
	}
	transformed := make(map[string]interface{})
	transformed["regex"] =
		flattenDataplexDatascanDataQualitySpecRulesRegexExpectationRegex(original["regex"], d, config)
	return []interface{}{transformed}
}
func flattenDataplexDatascanDataQualitySpecRulesRegexExpectationRegex(v interface{}, d *schema.ResourceData, config *transport_tpg.Config) interface{} {
	return v
}

func flattenDataplexDatascanDataQualitySpecRulesUniquenessExpectation(v interface{}, d *schema.ResourceData, config *transport_tpg.Config) interface{} {
	if v == nil {
		return nil
	}
	transformed := make(map[string]interface{})
	return []interface{}{transformed}
}

func flattenDataplexDatascanDataQualitySpecRulesStatisticRangeExpectation(v interface{}, d *schema.ResourceData, config *transport_tpg.Config) interface{} {
	if v == nil {
		return nil
	}
	original := v.(map[string]interface{})
	if len(original) == 0 {
		return nil
	}
	transformed := make(map[string]interface{})
	transformed["statistic"] =
		flattenDataplexDatascanDataQualitySpecRulesStatisticRangeExpectationStatistic(original["statistic"], d, config)
	transformed["min_value"] =
		flattenDataplexDatascanDataQualitySpecRulesStatisticRangeExpectationMinValue(original["minValue"], d, config)
	transformed["max_value"] =
		flattenDataplexDatascanDataQualitySpecRulesStatisticRangeExpectationMaxValue(original["maxValue"], d, config)
	transformed["strict_min_enabled"] =
		flattenDataplexDatascanDataQualitySpecRulesStatisticRangeExpectationStrictMinEnabled(original["strictMinEnabled"], d, config)
	transformed["strict_max_enabled"] =
		flattenDataplexDatascanDataQualitySpecRulesStatisticRangeExpectationStrictMaxEnabled(original["strictMaxEnabled"], d, config)
	return []interface{}{transformed}
}
func flattenDataplexDatascanDataQualitySpecRulesStatisticRangeExpectationStatistic(v interface{}, d *schema.ResourceData, config *transport_tpg.Config) interface{} {
	return v
}

func flattenDataplexDatascanDataQualitySpecRulesStatisticRangeExpectationMinValue(v interface{}, d *schema.ResourceData, config *transport_tpg.Config) interface{} {
	return v
}

func flattenDataplexDatascanDataQualitySpecRulesStatisticRangeExpectationMaxValue(v interface{}, d *schema.ResourceData, config *transport_tpg.Config) interface{} {
	return v
}

func flattenDataplexDatascanDataQualitySpecRulesStatisticRangeExpectationStrictMinEnabled(v interface{}, d *schema.ResourceData, config *transport_tpg.Config) interface{} {
	return v
}

func flattenDataplexDatascanDataQualitySpecRulesStatisticRangeExpectationStrictMaxEnabled(v interface{}, d *schema.ResourceData, config *transport_tpg.Config) interface{} {
	return v
}

func flattenDataplexDatascanDataQualitySpecRulesRowConditionExpectation(v interface{}, d *schema.ResourceData, config *transport_tpg.Config) interface{} {
	if v == nil {
		return nil
	}
	original := v.(map[string]interface{})
	if len(original) == 0 {
		return nil
	}
	transformed := make(map[string]interface{})
	transformed["sql_expression"] =
		flattenDataplexDatascanDataQualitySpecRulesRowConditionExpectationSqlExpression(original["sqlExpression"], d, config)
	return []interface{}{transformed}
}
func flattenDataplexDatascanDataQualitySpecRulesRowConditionExpectationSqlExpression(v interface{}, d *schema.ResourceData, config *transport_tpg.Config) interface{} {
	return v
}

func flattenDataplexDatascanDataQualitySpecRulesTableConditionExpectation(v interface{}, d *schema.ResourceData, config *transport_tpg.Config) interface{} {
	if v == nil {
		return nil
	}
	original := v.(map[string]interface{})
	if len(original) == 0 {
		return nil
	}
	transformed := make(map[string]interface{})
	transformed["sql_expression"] =
		flattenDataplexDatascanDataQualitySpecRulesTableConditionExpectationSqlExpression(original["sqlExpression"], d, config)
	return []interface{}{transformed}
}
func flattenDataplexDatascanDataQualitySpecRulesTableConditionExpectationSqlExpression(v interface{}, d *schema.ResourceData, config *transport_tpg.Config) interface{} {
	return v
}

func flattenDataplexDatascanDataQualitySpecRulesSqlAssertion(v interface{}, d *schema.ResourceData, config *transport_tpg.Config) interface{} {
	if v == nil {
		return nil
	}
	original := v.(map[string]interface{})
	if len(original) == 0 {
		return nil
	}
	transformed := make(map[string]interface{})
	transformed["sql_statement"] =
		flattenDataplexDatascanDataQualitySpecRulesSqlAssertionSqlStatement(original["sqlStatement"], d, config)
	return []interface{}{transformed}
}
func flattenDataplexDatascanDataQualitySpecRulesSqlAssertionSqlStatement(v interface{}, d *schema.ResourceData, config *transport_tpg.Config) interface{} {
	return v
}

func flattenDataplexDatascanDataProfileSpec(v interface{}, d *schema.ResourceData, config *transport_tpg.Config) interface{} {
	if v == nil {
		return nil
	}
	original := v.(map[string]interface{})
	transformed := make(map[string]interface{})
	transformed["sampling_percent"] =
		flattenDataplexDatascanDataProfileSpecSamplingPercent(original["samplingPercent"], d, config)
	transformed["row_filter"] =
		flattenDataplexDatascanDataProfileSpecRowFilter(original["rowFilter"], d, config)
	transformed["post_scan_actions"] =
		flattenDataplexDatascanDataProfileSpecPostScanActions(original["postScanActions"], d, config)
	transformed["include_fields"] =
		flattenDataplexDatascanDataProfileSpecIncludeFields(original["includeFields"], d, config)
	transformed["exclude_fields"] =
		flattenDataplexDatascanDataProfileSpecExcludeFields(original["excludeFields"], d, config)
	return []interface{}{transformed}
}
func flattenDataplexDatascanDataProfileSpecSamplingPercent(v interface{}, d *schema.ResourceData, config *transport_tpg.Config) interface{} {
	return v
}

func flattenDataplexDatascanDataProfileSpecRowFilter(v interface{}, d *schema.ResourceData, config *transport_tpg.Config) interface{} {
	return v
}

func flattenDataplexDatascanDataProfileSpecPostScanActions(v interface{}, d *schema.ResourceData, config *transport_tpg.Config) interface{} {
	if v == nil {
		return nil
	}
	original := v.(map[string]interface{})
	if len(original) == 0 {
		return nil
	}
	transformed := make(map[string]interface{})
	transformed["bigquery_export"] =
		flattenDataplexDatascanDataProfileSpecPostScanActionsBigqueryExport(original["bigqueryExport"], d, config)
	return []interface{}{transformed}
}
func flattenDataplexDatascanDataProfileSpecPostScanActionsBigqueryExport(v interface{}, d *schema.ResourceData, config *transport_tpg.Config) interface{} {
	if v == nil {
		return nil
	}
	original := v.(map[string]interface{})
	if len(original) == 0 {
		return nil
	}
	transformed := make(map[string]interface{})
	transformed["results_table"] =
		flattenDataplexDatascanDataProfileSpecPostScanActionsBigqueryExportResultsTable(original["resultsTable"], d, config)
	return []interface{}{transformed}
}
func flattenDataplexDatascanDataProfileSpecPostScanActionsBigqueryExportResultsTable(v interface{}, d *schema.ResourceData, config *transport_tpg.Config) interface{} {
	return v
}

func flattenDataplexDatascanDataProfileSpecIncludeFields(v interface{}, d *schema.ResourceData, config *transport_tpg.Config) interface{} {
	if v == nil {
		return nil
	}
	original := v.(map[string]interface{})
	if len(original) == 0 {
		return nil
	}
	transformed := make(map[string]interface{})
	transformed["field_names"] =
		flattenDataplexDatascanDataProfileSpecIncludeFieldsFieldNames(original["fieldNames"], d, config)
	return []interface{}{transformed}
}
func flattenDataplexDatascanDataProfileSpecIncludeFieldsFieldNames(v interface{}, d *schema.ResourceData, config *transport_tpg.Config) interface{} {
	return v
}

func flattenDataplexDatascanDataProfileSpecExcludeFields(v interface{}, d *schema.ResourceData, config *transport_tpg.Config) interface{} {
	if v == nil {
		return nil
	}
	original := v.(map[string]interface{})
	if len(original) == 0 {
		return nil
	}
	transformed := make(map[string]interface{})
	transformed["field_names"] =
		flattenDataplexDatascanDataProfileSpecExcludeFieldsFieldNames(original["fieldNames"], d, config)
	return []interface{}{transformed}
}
func flattenDataplexDatascanDataProfileSpecExcludeFieldsFieldNames(v interface{}, d *schema.ResourceData, config *transport_tpg.Config) interface{} {
	return v
}

func flattenDataplexDatascanTerraformLabels(v interface{}, d *schema.ResourceData, config *transport_tpg.Config) interface{} {
	if v == nil {
		return v
	}

	transformed := make(map[string]interface{})
	if l, ok := d.GetOkExists("terraform_labels"); ok {
		for k := range l.(map[string]interface{}) {
			transformed[k] = v.(map[string]interface{})[k]
		}
	}

	return transformed
}

func flattenDataplexDatascanEffectiveLabels(v interface{}, d *schema.ResourceData, config *transport_tpg.Config) interface{} {
	return v
}

func expandDataplexDatascanDescription(v interface{}, d tpgresource.TerraformResourceData, config *transport_tpg.Config) (interface{}, error) {
	return v, nil
}

func expandDataplexDatascanDisplayName(v interface{}, d tpgresource.TerraformResourceData, config *transport_tpg.Config) (interface{}, error) {
	return v, nil
}

func expandDataplexDatascanData(v interface{}, d tpgresource.TerraformResourceData, config *transport_tpg.Config) (interface{}, error) {
	l := v.([]interface{})
	if len(l) == 0 || l[0] == nil {
		return nil, nil
	}
	raw := l[0]
	original := raw.(map[string]interface{})
	transformed := make(map[string]interface{})

	transformedEntity, err := expandDataplexDatascanDataEntity(original["entity"], d, config)
	if err != nil {
		return nil, err
	} else if val := reflect.ValueOf(transformedEntity); val.IsValid() && !tpgresource.IsEmptyValue(val) {
		transformed["entity"] = transformedEntity
	}

	transformedResource, err := expandDataplexDatascanDataResource(original["resource"], d, config)
	if err != nil {
		return nil, err
	} else if val := reflect.ValueOf(transformedResource); val.IsValid() && !tpgresource.IsEmptyValue(val) {
		transformed["resource"] = transformedResource
	}

	return transformed, nil
}

func expandDataplexDatascanDataEntity(v interface{}, d tpgresource.TerraformResourceData, config *transport_tpg.Config) (interface{}, error) {
	return v, nil
}

func expandDataplexDatascanDataResource(v interface{}, d tpgresource.TerraformResourceData, config *transport_tpg.Config) (interface{}, error) {
	return v, nil
}

func expandDataplexDatascanExecutionSpec(v interface{}, d tpgresource.TerraformResourceData, config *transport_tpg.Config) (interface{}, error) {
	l := v.([]interface{})
	if len(l) == 0 || l[0] == nil {
		return nil, nil
	}
	raw := l[0]
	original := raw.(map[string]interface{})
	transformed := make(map[string]interface{})

	transformedTrigger, err := expandDataplexDatascanExecutionSpecTrigger(original["trigger"], d, config)
	if err != nil {
		return nil, err
	} else if val := reflect.ValueOf(transformedTrigger); val.IsValid() && !tpgresource.IsEmptyValue(val) {
		transformed["trigger"] = transformedTrigger
	}

	transformedField, err := expandDataplexDatascanExecutionSpecField(original["field"], d, config)
	if err != nil {
		return nil, err
	} else if val := reflect.ValueOf(transformedField); val.IsValid() && !tpgresource.IsEmptyValue(val) {
		transformed["field"] = transformedField
	}

	return transformed, nil
}

func expandDataplexDatascanExecutionSpecTrigger(v interface{}, d tpgresource.TerraformResourceData, config *transport_tpg.Config) (interface{}, error) {
	l := v.([]interface{})
	if len(l) == 0 || l[0] == nil {
		return nil, nil
	}
	raw := l[0]
	original := raw.(map[string]interface{})
	transformed := make(map[string]interface{})

	transformedOnDemand, err := expandDataplexDatascanExecutionSpecTriggerOnDemand(original["on_demand"], d, config)
	if err != nil {
		return nil, err
	} else {
		transformed["onDemand"] = transformedOnDemand
	}

	transformedSchedule, err := expandDataplexDatascanExecutionSpecTriggerSchedule(original["schedule"], d, config)
	if err != nil {
		return nil, err
	} else if val := reflect.ValueOf(transformedSchedule); val.IsValid() && !tpgresource.IsEmptyValue(val) {
		transformed["schedule"] = transformedSchedule
	}

	return transformed, nil
}

func expandDataplexDatascanExecutionSpecTriggerOnDemand(v interface{}, d tpgresource.TerraformResourceData, config *transport_tpg.Config) (interface{}, error) {
	l := v.([]interface{})
	if len(l) == 0 {
		return nil, nil
	}

	if l[0] == nil {
		transformed := make(map[string]interface{})
		return transformed, nil
	}
	transformed := make(map[string]interface{})

	return transformed, nil
}

func expandDataplexDatascanExecutionSpecTriggerSchedule(v interface{}, d tpgresource.TerraformResourceData, config *transport_tpg.Config) (interface{}, error) {
	l := v.([]interface{})
	if len(l) == 0 || l[0] == nil {
		return nil, nil
	}
	raw := l[0]
	original := raw.(map[string]interface{})
	transformed := make(map[string]interface{})

	transformedCron, err := expandDataplexDatascanExecutionSpecTriggerScheduleCron(original["cron"], d, config)
	if err != nil {
		return nil, err
	} else if val := reflect.ValueOf(transformedCron); val.IsValid() && !tpgresource.IsEmptyValue(val) {
		transformed["cron"] = transformedCron
	}

	return transformed, nil
}

func expandDataplexDatascanExecutionSpecTriggerScheduleCron(v interface{}, d tpgresource.TerraformResourceData, config *transport_tpg.Config) (interface{}, error) {
	return v, nil
}

func expandDataplexDatascanExecutionSpecField(v interface{}, d tpgresource.TerraformResourceData, config *transport_tpg.Config) (interface{}, error) {
	return v, nil
}

func expandDataplexDatascanDataQualitySpec(v interface{}, d tpgresource.TerraformResourceData, config *transport_tpg.Config) (interface{}, error) {
	l := v.([]interface{})
	if len(l) == 0 || l[0] == nil {
		return nil, nil
	}
	raw := l[0]
	original := raw.(map[string]interface{})
	transformed := make(map[string]interface{})

	transformedSamplingPercent, err := expandDataplexDatascanDataQualitySpecSamplingPercent(original["sampling_percent"], d, config)
	if err != nil {
		return nil, err
	} else if val := reflect.ValueOf(transformedSamplingPercent); val.IsValid() && !tpgresource.IsEmptyValue(val) {
		transformed["samplingPercent"] = transformedSamplingPercent
	}

	transformedRowFilter, err := expandDataplexDatascanDataQualitySpecRowFilter(original["row_filter"], d, config)
	if err != nil {
		return nil, err
	} else if val := reflect.ValueOf(transformedRowFilter); val.IsValid() && !tpgresource.IsEmptyValue(val) {
		transformed["rowFilter"] = transformedRowFilter
	}

	transformedPostScanActions, err := expandDataplexDatascanDataQualitySpecPostScanActions(original["post_scan_actions"], d, config)
	if err != nil {
		return nil, err
	} else if val := reflect.ValueOf(transformedPostScanActions); val.IsValid() && !tpgresource.IsEmptyValue(val) {
		transformed["postScanActions"] = transformedPostScanActions
	}

	transformedRules, err := expandDataplexDatascanDataQualitySpecRules(original["rules"], d, config)
	if err != nil {
		return nil, err
	} else if val := reflect.ValueOf(transformedRules); val.IsValid() && !tpgresource.IsEmptyValue(val) {
		transformed["rules"] = transformedRules
	}

	return transformed, nil
}

func expandDataplexDatascanDataQualitySpecSamplingPercent(v interface{}, d tpgresource.TerraformResourceData, config *transport_tpg.Config) (interface{}, error) {
	return v, nil
}

func expandDataplexDatascanDataQualitySpecRowFilter(v interface{}, d tpgresource.TerraformResourceData, config *transport_tpg.Config) (interface{}, error) {
	return v, nil
}

func expandDataplexDatascanDataQualitySpecPostScanActions(v interface{}, d tpgresource.TerraformResourceData, config *transport_tpg.Config) (interface{}, error) {
	l := v.([]interface{})
	if len(l) == 0 || l[0] == nil {
		return nil, nil
	}
	raw := l[0]
	original := raw.(map[string]interface{})
	transformed := make(map[string]interface{})

	transformedBigqueryExport, err := expandDataplexDatascanDataQualitySpecPostScanActionsBigqueryExport(original["bigquery_export"], d, config)
	if err != nil {
		return nil, err
	} else if val := reflect.ValueOf(transformedBigqueryExport); val.IsValid() && !tpgresource.IsEmptyValue(val) {
		transformed["bigqueryExport"] = transformedBigqueryExport
	}

	transformedNotificationReport, err := expandDataplexDatascanDataQualitySpecPostScanActionsNotificationReport(original["notification_report"], d, config)
	if err != nil {
		return nil, err
	} else if val := reflect.ValueOf(transformedNotificationReport); val.IsValid() && !tpgresource.IsEmptyValue(val) {
		transformed["notificationReport"] = transformedNotificationReport
	}

	return transformed, nil
}

func expandDataplexDatascanDataQualitySpecPostScanActionsBigqueryExport(v interface{}, d tpgresource.TerraformResourceData, config *transport_tpg.Config) (interface{}, error) {
	l := v.([]interface{})
	if len(l) == 0 || l[0] == nil {
		return nil, nil
	}
	raw := l[0]
	original := raw.(map[string]interface{})
	transformed := make(map[string]interface{})

	transformedResultsTable, err := expandDataplexDatascanDataQualitySpecPostScanActionsBigqueryExportResultsTable(original["results_table"], d, config)
	if err != nil {
		return nil, err
	} else if val := reflect.ValueOf(transformedResultsTable); val.IsValid() && !tpgresource.IsEmptyValue(val) {
		transformed["resultsTable"] = transformedResultsTable
	}

	return transformed, nil
}

func expandDataplexDatascanDataQualitySpecPostScanActionsBigqueryExportResultsTable(v interface{}, d tpgresource.TerraformResourceData, config *transport_tpg.Config) (interface{}, error) {
	return v, nil
}

func expandDataplexDatascanDataQualitySpecPostScanActionsNotificationReport(v interface{}, d tpgresource.TerraformResourceData, config *transport_tpg.Config) (interface{}, error) {
	l := v.([]interface{})
	if len(l) == 0 || l[0] == nil {
		return nil, nil
	}
	raw := l[0]
	original := raw.(map[string]interface{})
	transformed := make(map[string]interface{})

	transformedRecipients, err := expandDataplexDatascanDataQualitySpecPostScanActionsNotificationReportRecipients(original["recipients"], d, config)
	if err != nil {
		return nil, err
	} else if val := reflect.ValueOf(transformedRecipients); val.IsValid() && !tpgresource.IsEmptyValue(val) {
		transformed["recipients"] = transformedRecipients
	}

	transformedScoreThresholdTrigger, err := expandDataplexDatascanDataQualitySpecPostScanActionsNotificationReportScoreThresholdTrigger(original["score_threshold_trigger"], d, config)
	if err != nil {
		return nil, err
	} else if val := reflect.ValueOf(transformedScoreThresholdTrigger); val.IsValid() && !tpgresource.IsEmptyValue(val) {
		transformed["scoreThresholdTrigger"] = transformedScoreThresholdTrigger
	}

	transformedJobFailureTrigger, err := expandDataplexDatascanDataQualitySpecPostScanActionsNotificationReportJobFailureTrigger(original["job_failure_trigger"], d, config)
	if err != nil {
		return nil, err
	} else {
		transformed["jobFailureTrigger"] = transformedJobFailureTrigger
	}

	transformedJobEndTrigger, err := expandDataplexDatascanDataQualitySpecPostScanActionsNotificationReportJobEndTrigger(original["job_end_trigger"], d, config)
	if err != nil {
		return nil, err
	} else {
		transformed["jobEndTrigger"] = transformedJobEndTrigger
	}

	return transformed, nil
}

func expandDataplexDatascanDataQualitySpecPostScanActionsNotificationReportRecipients(v interface{}, d tpgresource.TerraformResourceData, config *transport_tpg.Config) (interface{}, error) {
	l := v.([]interface{})
	if len(l) == 0 || l[0] == nil {
		return nil, nil
	}
	raw := l[0]
	original := raw.(map[string]interface{})
	transformed := make(map[string]interface{})

	transformedEmails, err := expandDataplexDatascanDataQualitySpecPostScanActionsNotificationReportRecipientsEmails(original["emails"], d, config)
	if err != nil {
		return nil, err
	} else if val := reflect.ValueOf(transformedEmails); val.IsValid() && !tpgresource.IsEmptyValue(val) {
		transformed["emails"] = transformedEmails
	}

	return transformed, nil
}

func expandDataplexDatascanDataQualitySpecPostScanActionsNotificationReportRecipientsEmails(v interface{}, d tpgresource.TerraformResourceData, config *transport_tpg.Config) (interface{}, error) {
	return v, nil
}

func expandDataplexDatascanDataQualitySpecPostScanActionsNotificationReportScoreThresholdTrigger(v interface{}, d tpgresource.TerraformResourceData, config *transport_tpg.Config) (interface{}, error) {
	l := v.([]interface{})
	if len(l) == 0 || l[0] == nil {
		return nil, nil
	}
	raw := l[0]
	original := raw.(map[string]interface{})
	transformed := make(map[string]interface{})

	transformedScoreThreshold, err := expandDataplexDatascanDataQualitySpecPostScanActionsNotificationReportScoreThresholdTriggerScoreThreshold(original["score_threshold"], d, config)
	if err != nil {
		return nil, err
	} else if val := reflect.ValueOf(transformedScoreThreshold); val.IsValid() && !tpgresource.IsEmptyValue(val) {
		transformed["scoreThreshold"] = transformedScoreThreshold
	}

	return transformed, nil
}

func expandDataplexDatascanDataQualitySpecPostScanActionsNotificationReportScoreThresholdTriggerScoreThreshold(v interface{}, d tpgresource.TerraformResourceData, config *transport_tpg.Config) (interface{}, error) {
	return v, nil
}

func expandDataplexDatascanDataQualitySpecPostScanActionsNotificationReportJobFailureTrigger(v interface{}, d tpgresource.TerraformResourceData, config *transport_tpg.Config) (interface{}, error) {
	l := v.([]interface{})
	if len(l) == 0 {
		return nil, nil
	}

	if l[0] == nil {
		transformed := make(map[string]interface{})
		return transformed, nil
	}
	transformed := make(map[string]interface{})

	return transformed, nil
}

func expandDataplexDatascanDataQualitySpecPostScanActionsNotificationReportJobEndTrigger(v interface{}, d tpgresource.TerraformResourceData, config *transport_tpg.Config) (interface{}, error) {
	l := v.([]interface{})
	if len(l) == 0 {
		return nil, nil
	}

	if l[0] == nil {
		transformed := make(map[string]interface{})
		return transformed, nil
	}
	transformed := make(map[string]interface{})

	return transformed, nil
}

func expandDataplexDatascanDataQualitySpecRules(v interface{}, d tpgresource.TerraformResourceData, config *transport_tpg.Config) (interface{}, error) {
	l := v.([]interface{})
	req := make([]interface{}, 0, len(l))
	for _, raw := range l {
		if raw == nil {
			continue
		}
		original := raw.(map[string]interface{})
		transformed := make(map[string]interface{})

		transformedColumn, err := expandDataplexDatascanDataQualitySpecRulesColumn(original["column"], d, config)
		if err != nil {
			return nil, err
		} else if val := reflect.ValueOf(transformedColumn); val.IsValid() && !tpgresource.IsEmptyValue(val) {
			transformed["column"] = transformedColumn
		}

		transformedIgnoreNull, err := expandDataplexDatascanDataQualitySpecRulesIgnoreNull(original["ignore_null"], d, config)
		if err != nil {
			return nil, err
		} else if val := reflect.ValueOf(transformedIgnoreNull); val.IsValid() && !tpgresource.IsEmptyValue(val) {
			transformed["ignoreNull"] = transformedIgnoreNull
		}

		transformedDimension, err := expandDataplexDatascanDataQualitySpecRulesDimension(original["dimension"], d, config)
		if err != nil {
			return nil, err
		} else if val := reflect.ValueOf(transformedDimension); val.IsValid() && !tpgresource.IsEmptyValue(val) {
			transformed["dimension"] = transformedDimension
		}

		transformedThreshold, err := expandDataplexDatascanDataQualitySpecRulesThreshold(original["threshold"], d, config)
		if err != nil {
			return nil, err
		} else if val := reflect.ValueOf(transformedThreshold); val.IsValid() && !tpgresource.IsEmptyValue(val) {
			transformed["threshold"] = transformedThreshold
		}

		transformedName, err := expandDataplexDatascanDataQualitySpecRulesName(original["name"], d, config)
		if err != nil {
			return nil, err
		} else if val := reflect.ValueOf(transformedName); val.IsValid() && !tpgresource.IsEmptyValue(val) {
			transformed["name"] = transformedName
		}

		transformedDescription, err := expandDataplexDatascanDataQualitySpecRulesDescription(original["description"], d, config)
		if err != nil {
			return nil, err
		} else if val := reflect.ValueOf(transformedDescription); val.IsValid() && !tpgresource.IsEmptyValue(val) {
			transformed["description"] = transformedDescription
		}

		transformedRangeExpectation, err := expandDataplexDatascanDataQualitySpecRulesRangeExpectation(original["range_expectation"], d, config)
		if err != nil {
			return nil, err
		} else if val := reflect.ValueOf(transformedRangeExpectation); val.IsValid() && !tpgresource.IsEmptyValue(val) {
			transformed["rangeExpectation"] = transformedRangeExpectation
		}

		transformedNonNullExpectation, err := expandDataplexDatascanDataQualitySpecRulesNonNullExpectation(original["non_null_expectation"], d, config)
		if err != nil {
			return nil, err
		} else {
			transformed["nonNullExpectation"] = transformedNonNullExpectation
		}

		transformedSetExpectation, err := expandDataplexDatascanDataQualitySpecRulesSetExpectation(original["set_expectation"], d, config)
		if err != nil {
			return nil, err
		} else if val := reflect.ValueOf(transformedSetExpectation); val.IsValid() && !tpgresource.IsEmptyValue(val) {
			transformed["setExpectation"] = transformedSetExpectation
		}

		transformedRegexExpectation, err := expandDataplexDatascanDataQualitySpecRulesRegexExpectation(original["regex_expectation"], d, config)
		if err != nil {
			return nil, err
		} else if val := reflect.ValueOf(transformedRegexExpectation); val.IsValid() && !tpgresource.IsEmptyValue(val) {
			transformed["regexExpectation"] = transformedRegexExpectation
		}

		transformedUniquenessExpectation, err := expandDataplexDatascanDataQualitySpecRulesUniquenessExpectation(original["uniqueness_expectation"], d, config)
		if err != nil {
			return nil, err
		} else {
			transformed["uniquenessExpectation"] = transformedUniquenessExpectation
		}

		transformedStatisticRangeExpectation, err := expandDataplexDatascanDataQualitySpecRulesStatisticRangeExpectation(original["statistic_range_expectation"], d, config)
		if err != nil {
			return nil, err
		} else if val := reflect.ValueOf(transformedStatisticRangeExpectation); val.IsValid() && !tpgresource.IsEmptyValue(val) {
			transformed["statisticRangeExpectation"] = transformedStatisticRangeExpectation
		}

		transformedRowConditionExpectation, err := expandDataplexDatascanDataQualitySpecRulesRowConditionExpectation(original["row_condition_expectation"], d, config)
		if err != nil {
			return nil, err
		} else if val := reflect.ValueOf(transformedRowConditionExpectation); val.IsValid() && !tpgresource.IsEmptyValue(val) {
			transformed["rowConditionExpectation"] = transformedRowConditionExpectation
		}

		transformedTableConditionExpectation, err := expandDataplexDatascanDataQualitySpecRulesTableConditionExpectation(original["table_condition_expectation"], d, config)
		if err != nil {
			return nil, err
		} else if val := reflect.ValueOf(transformedTableConditionExpectation); val.IsValid() && !tpgresource.IsEmptyValue(val) {
			transformed["tableConditionExpectation"] = transformedTableConditionExpectation
		}

		transformedSqlAssertion, err := expandDataplexDatascanDataQualitySpecRulesSqlAssertion(original["sql_assertion"], d, config)
		if err != nil {
			return nil, err
		} else if val := reflect.ValueOf(transformedSqlAssertion); val.IsValid() && !tpgresource.IsEmptyValue(val) {
			transformed["sqlAssertion"] = transformedSqlAssertion
		}

		req = append(req, transformed)
	}
	return req, nil
}

func expandDataplexDatascanDataQualitySpecRulesColumn(v interface{}, d tpgresource.TerraformResourceData, config *transport_tpg.Config) (interface{}, error) {
	return v, nil
}

func expandDataplexDatascanDataQualitySpecRulesIgnoreNull(v interface{}, d tpgresource.TerraformResourceData, config *transport_tpg.Config) (interface{}, error) {
	return v, nil
}

func expandDataplexDatascanDataQualitySpecRulesDimension(v interface{}, d tpgresource.TerraformResourceData, config *transport_tpg.Config) (interface{}, error) {
	return v, nil
}

func expandDataplexDatascanDataQualitySpecRulesThreshold(v interface{}, d tpgresource.TerraformResourceData, config *transport_tpg.Config) (interface{}, error) {
	return v, nil
}

func expandDataplexDatascanDataQualitySpecRulesName(v interface{}, d tpgresource.TerraformResourceData, config *transport_tpg.Config) (interface{}, error) {
	return v, nil
}

func expandDataplexDatascanDataQualitySpecRulesDescription(v interface{}, d tpgresource.TerraformResourceData, config *transport_tpg.Config) (interface{}, error) {
	return v, nil
}

func expandDataplexDatascanDataQualitySpecRulesRangeExpectation(v interface{}, d tpgresource.TerraformResourceData, config *transport_tpg.Config) (interface{}, error) {
	l := v.([]interface{})
	if len(l) == 0 || l[0] == nil {
		return nil, nil
	}
	raw := l[0]
	original := raw.(map[string]interface{})
	transformed := make(map[string]interface{})

	transformedMinValue, err := expandDataplexDatascanDataQualitySpecRulesRangeExpectationMinValue(original["min_value"], d, config)
	if err != nil {
		return nil, err
	} else if val := reflect.ValueOf(transformedMinValue); val.IsValid() && !tpgresource.IsEmptyValue(val) {
		transformed["minValue"] = transformedMinValue
	}

	transformedMaxValue, err := expandDataplexDatascanDataQualitySpecRulesRangeExpectationMaxValue(original["max_value"], d, config)
	if err != nil {
		return nil, err
	} else if val := reflect.ValueOf(transformedMaxValue); val.IsValid() && !tpgresource.IsEmptyValue(val) {
		transformed["maxValue"] = transformedMaxValue
	}

	transformedStrictMinEnabled, err := expandDataplexDatascanDataQualitySpecRulesRangeExpectationStrictMinEnabled(original["strict_min_enabled"], d, config)
	if err != nil {
		return nil, err
	} else if val := reflect.ValueOf(transformedStrictMinEnabled); val.IsValid() && !tpgresource.IsEmptyValue(val) {
		transformed["strictMinEnabled"] = transformedStrictMinEnabled
	}

	transformedStrictMaxEnabled, err := expandDataplexDatascanDataQualitySpecRulesRangeExpectationStrictMaxEnabled(original["strict_max_enabled"], d, config)
	if err != nil {
		return nil, err
	} else if val := reflect.ValueOf(transformedStrictMaxEnabled); val.IsValid() && !tpgresource.IsEmptyValue(val) {
		transformed["strictMaxEnabled"] = transformedStrictMaxEnabled
	}

	return transformed, nil
}

func expandDataplexDatascanDataQualitySpecRulesRangeExpectationMinValue(v interface{}, d tpgresource.TerraformResourceData, config *transport_tpg.Config) (interface{}, error) {
	return v, nil
}

func expandDataplexDatascanDataQualitySpecRulesRangeExpectationMaxValue(v interface{}, d tpgresource.TerraformResourceData, config *transport_tpg.Config) (interface{}, error) {
	return v, nil
}

func expandDataplexDatascanDataQualitySpecRulesRangeExpectationStrictMinEnabled(v interface{}, d tpgresource.TerraformResourceData, config *transport_tpg.Config) (interface{}, error) {
	return v, nil
}

func expandDataplexDatascanDataQualitySpecRulesRangeExpectationStrictMaxEnabled(v interface{}, d tpgresource.TerraformResourceData, config *transport_tpg.Config) (interface{}, error) {
	return v, nil
}

func expandDataplexDatascanDataQualitySpecRulesNonNullExpectation(v interface{}, d tpgresource.TerraformResourceData, config *transport_tpg.Config) (interface{}, error) {
	l := v.([]interface{})
	if len(l) == 0 {
		return nil, nil
	}

	if l[0] == nil {
		transformed := make(map[string]interface{})
		return transformed, nil
	}
	transformed := make(map[string]interface{})

	return transformed, nil
}

func expandDataplexDatascanDataQualitySpecRulesSetExpectation(v interface{}, d tpgresource.TerraformResourceData, config *transport_tpg.Config) (interface{}, error) {
	l := v.([]interface{})
	if len(l) == 0 || l[0] == nil {
		return nil, nil
	}
	raw := l[0]
	original := raw.(map[string]interface{})
	transformed := make(map[string]interface{})

	transformedValues, err := expandDataplexDatascanDataQualitySpecRulesSetExpectationValues(original["values"], d, config)
	if err != nil {
		return nil, err
	} else if val := reflect.ValueOf(transformedValues); val.IsValid() && !tpgresource.IsEmptyValue(val) {
		transformed["values"] = transformedValues
	}

	return transformed, nil
}

func expandDataplexDatascanDataQualitySpecRulesSetExpectationValues(v interface{}, d tpgresource.TerraformResourceData, config *transport_tpg.Config) (interface{}, error) {
	return v, nil
}

func expandDataplexDatascanDataQualitySpecRulesRegexExpectation(v interface{}, d tpgresource.TerraformResourceData, config *transport_tpg.Config) (interface{}, error) {
	l := v.([]interface{})
	if len(l) == 0 || l[0] == nil {
		return nil, nil
	}
	raw := l[0]
	original := raw.(map[string]interface{})
	transformed := make(map[string]interface{})

	transformedRegex, err := expandDataplexDatascanDataQualitySpecRulesRegexExpectationRegex(original["regex"], d, config)
	if err != nil {
		return nil, err
	} else if val := reflect.ValueOf(transformedRegex); val.IsValid() && !tpgresource.IsEmptyValue(val) {
		transformed["regex"] = transformedRegex
	}

	return transformed, nil
}

func expandDataplexDatascanDataQualitySpecRulesRegexExpectationRegex(v interface{}, d tpgresource.TerraformResourceData, config *transport_tpg.Config) (interface{}, error) {
	return v, nil
}

func expandDataplexDatascanDataQualitySpecRulesUniquenessExpectation(v interface{}, d tpgresource.TerraformResourceData, config *transport_tpg.Config) (interface{}, error) {
	l := v.([]interface{})
	if len(l) == 0 {
		return nil, nil
	}

	if l[0] == nil {
		transformed := make(map[string]interface{})
		return transformed, nil
	}
	transformed := make(map[string]interface{})

	return transformed, nil
}

func expandDataplexDatascanDataQualitySpecRulesStatisticRangeExpectation(v interface{}, d tpgresource.TerraformResourceData, config *transport_tpg.Config) (interface{}, error) {
	l := v.([]interface{})
	if len(l) == 0 || l[0] == nil {
		return nil, nil
	}
	raw := l[0]
	original := raw.(map[string]interface{})
	transformed := make(map[string]interface{})

	transformedStatistic, err := expandDataplexDatascanDataQualitySpecRulesStatisticRangeExpectationStatistic(original["statistic"], d, config)
	if err != nil {
		return nil, err
	} else if val := reflect.ValueOf(transformedStatistic); val.IsValid() && !tpgresource.IsEmptyValue(val) {
		transformed["statistic"] = transformedStatistic
	}

	transformedMinValue, err := expandDataplexDatascanDataQualitySpecRulesStatisticRangeExpectationMinValue(original["min_value"], d, config)
	if err != nil {
		return nil, err
	} else if val := reflect.ValueOf(transformedMinValue); val.IsValid() && !tpgresource.IsEmptyValue(val) {
		transformed["minValue"] = transformedMinValue
	}

	transformedMaxValue, err := expandDataplexDatascanDataQualitySpecRulesStatisticRangeExpectationMaxValue(original["max_value"], d, config)
	if err != nil {
		return nil, err
	} else if val := reflect.ValueOf(transformedMaxValue); val.IsValid() && !tpgresource.IsEmptyValue(val) {
		transformed["maxValue"] = transformedMaxValue
	}

	transformedStrictMinEnabled, err := expandDataplexDatascanDataQualitySpecRulesStatisticRangeExpectationStrictMinEnabled(original["strict_min_enabled"], d, config)
	if err != nil {
		return nil, err
	} else if val := reflect.ValueOf(transformedStrictMinEnabled); val.IsValid() && !tpgresource.IsEmptyValue(val) {
		transformed["strictMinEnabled"] = transformedStrictMinEnabled
	}

	transformedStrictMaxEnabled, err := expandDataplexDatascanDataQualitySpecRulesStatisticRangeExpectationStrictMaxEnabled(original["strict_max_enabled"], d, config)
	if err != nil {
		return nil, err
	} else if val := reflect.ValueOf(transformedStrictMaxEnabled); val.IsValid() && !tpgresource.IsEmptyValue(val) {
		transformed["strictMaxEnabled"] = transformedStrictMaxEnabled
	}

	return transformed, nil
}

func expandDataplexDatascanDataQualitySpecRulesStatisticRangeExpectationStatistic(v interface{}, d tpgresource.TerraformResourceData, config *transport_tpg.Config) (interface{}, error) {
	return v, nil
}

func expandDataplexDatascanDataQualitySpecRulesStatisticRangeExpectationMinValue(v interface{}, d tpgresource.TerraformResourceData, config *transport_tpg.Config) (interface{}, error) {
	return v, nil
}

func expandDataplexDatascanDataQualitySpecRulesStatisticRangeExpectationMaxValue(v interface{}, d tpgresource.TerraformResourceData, config *transport_tpg.Config) (interface{}, error) {
	return v, nil
}

func expandDataplexDatascanDataQualitySpecRulesStatisticRangeExpectationStrictMinEnabled(v interface{}, d tpgresource.TerraformResourceData, config *transport_tpg.Config) (interface{}, error) {
	return v, nil
}

func expandDataplexDatascanDataQualitySpecRulesStatisticRangeExpectationStrictMaxEnabled(v interface{}, d tpgresource.TerraformResourceData, config *transport_tpg.Config) (interface{}, error) {
	return v, nil
}

func expandDataplexDatascanDataQualitySpecRulesRowConditionExpectation(v interface{}, d tpgresource.TerraformResourceData, config *transport_tpg.Config) (interface{}, error) {
	l := v.([]interface{})
	if len(l) == 0 || l[0] == nil {
		return nil, nil
	}
	raw := l[0]
	original := raw.(map[string]interface{})
	transformed := make(map[string]interface{})

	transformedSqlExpression, err := expandDataplexDatascanDataQualitySpecRulesRowConditionExpectationSqlExpression(original["sql_expression"], d, config)
	if err != nil {
		return nil, err
	} else if val := reflect.ValueOf(transformedSqlExpression); val.IsValid() && !tpgresource.IsEmptyValue(val) {
		transformed["sqlExpression"] = transformedSqlExpression
	}

	return transformed, nil
}

func expandDataplexDatascanDataQualitySpecRulesRowConditionExpectationSqlExpression(v interface{}, d tpgresource.TerraformResourceData, config *transport_tpg.Config) (interface{}, error) {
	return v, nil
}

func expandDataplexDatascanDataQualitySpecRulesTableConditionExpectation(v interface{}, d tpgresource.TerraformResourceData, config *transport_tpg.Config) (interface{}, error) {
	l := v.([]interface{})
	if len(l) == 0 || l[0] == nil {
		return nil, nil
	}
	raw := l[0]
	original := raw.(map[string]interface{})
	transformed := make(map[string]interface{})

	transformedSqlExpression, err := expandDataplexDatascanDataQualitySpecRulesTableConditionExpectationSqlExpression(original["sql_expression"], d, config)
	if err != nil {
		return nil, err
	} else if val := reflect.ValueOf(transformedSqlExpression); val.IsValid() && !tpgresource.IsEmptyValue(val) {
		transformed["sqlExpression"] = transformedSqlExpression
	}

	return transformed, nil
}

func expandDataplexDatascanDataQualitySpecRulesTableConditionExpectationSqlExpression(v interface{}, d tpgresource.TerraformResourceData, config *transport_tpg.Config) (interface{}, error) {
	return v, nil
}

func expandDataplexDatascanDataQualitySpecRulesSqlAssertion(v interface{}, d tpgresource.TerraformResourceData, config *transport_tpg.Config) (interface{}, error) {
	l := v.([]interface{})
	if len(l) == 0 || l[0] == nil {
		return nil, nil
	}
	raw := l[0]
	original := raw.(map[string]interface{})
	transformed := make(map[string]interface{})

	transformedSqlStatement, err := expandDataplexDatascanDataQualitySpecRulesSqlAssertionSqlStatement(original["sql_statement"], d, config)
	if err != nil {
		return nil, err
	} else if val := reflect.ValueOf(transformedSqlStatement); val.IsValid() && !tpgresource.IsEmptyValue(val) {
		transformed["sqlStatement"] = transformedSqlStatement
	}

	return transformed, nil
}

func expandDataplexDatascanDataQualitySpecRulesSqlAssertionSqlStatement(v interface{}, d tpgresource.TerraformResourceData, config *transport_tpg.Config) (interface{}, error) {
	return v, nil
}

func expandDataplexDatascanDataProfileSpec(v interface{}, d tpgresource.TerraformResourceData, config *transport_tpg.Config) (interface{}, error) {
	l := v.([]interface{})
	if len(l) == 0 {
		return nil, nil
	}

	if l[0] == nil {
		transformed := make(map[string]interface{})
		return transformed, nil
	}
	raw := l[0]
	original := raw.(map[string]interface{})
	transformed := make(map[string]interface{})

	transformedSamplingPercent, err := expandDataplexDatascanDataProfileSpecSamplingPercent(original["sampling_percent"], d, config)
	if err != nil {
		return nil, err
	} else if val := reflect.ValueOf(transformedSamplingPercent); val.IsValid() && !tpgresource.IsEmptyValue(val) {
		transformed["samplingPercent"] = transformedSamplingPercent
	}

	transformedRowFilter, err := expandDataplexDatascanDataProfileSpecRowFilter(original["row_filter"], d, config)
	if err != nil {
		return nil, err
	} else if val := reflect.ValueOf(transformedRowFilter); val.IsValid() && !tpgresource.IsEmptyValue(val) {
		transformed["rowFilter"] = transformedRowFilter
	}

	transformedPostScanActions, err := expandDataplexDatascanDataProfileSpecPostScanActions(original["post_scan_actions"], d, config)
	if err != nil {
		return nil, err
	} else if val := reflect.ValueOf(transformedPostScanActions); val.IsValid() && !tpgresource.IsEmptyValue(val) {
		transformed["postScanActions"] = transformedPostScanActions
	}

	transformedIncludeFields, err := expandDataplexDatascanDataProfileSpecIncludeFields(original["include_fields"], d, config)
	if err != nil {
		return nil, err
	} else if val := reflect.ValueOf(transformedIncludeFields); val.IsValid() && !tpgresource.IsEmptyValue(val) {
		transformed["includeFields"] = transformedIncludeFields
	}

	transformedExcludeFields, err := expandDataplexDatascanDataProfileSpecExcludeFields(original["exclude_fields"], d, config)
	if err != nil {
		return nil, err
	} else if val := reflect.ValueOf(transformedExcludeFields); val.IsValid() && !tpgresource.IsEmptyValue(val) {
		transformed["excludeFields"] = transformedExcludeFields
	}

	return transformed, nil
}

func expandDataplexDatascanDataProfileSpecSamplingPercent(v interface{}, d tpgresource.TerraformResourceData, config *transport_tpg.Config) (interface{}, error) {
	return v, nil
}

func expandDataplexDatascanDataProfileSpecRowFilter(v interface{}, d tpgresource.TerraformResourceData, config *transport_tpg.Config) (interface{}, error) {
	return v, nil
}

func expandDataplexDatascanDataProfileSpecPostScanActions(v interface{}, d tpgresource.TerraformResourceData, config *transport_tpg.Config) (interface{}, error) {
	l := v.([]interface{})
	if len(l) == 0 || l[0] == nil {
		return nil, nil
	}
	raw := l[0]
	original := raw.(map[string]interface{})
	transformed := make(map[string]interface{})

	transformedBigqueryExport, err := expandDataplexDatascanDataProfileSpecPostScanActionsBigqueryExport(original["bigquery_export"], d, config)
	if err != nil {
		return nil, err
	} else if val := reflect.ValueOf(transformedBigqueryExport); val.IsValid() && !tpgresource.IsEmptyValue(val) {
		transformed["bigqueryExport"] = transformedBigqueryExport
	}

	return transformed, nil
}

func expandDataplexDatascanDataProfileSpecPostScanActionsBigqueryExport(v interface{}, d tpgresource.TerraformResourceData, config *transport_tpg.Config) (interface{}, error) {
	l := v.([]interface{})
	if len(l) == 0 || l[0] == nil {
		return nil, nil
	}
	raw := l[0]
	original := raw.(map[string]interface{})
	transformed := make(map[string]interface{})

	transformedResultsTable, err := expandDataplexDatascanDataProfileSpecPostScanActionsBigqueryExportResultsTable(original["results_table"], d, config)
	if err != nil {
		return nil, err
	} else if val := reflect.ValueOf(transformedResultsTable); val.IsValid() && !tpgresource.IsEmptyValue(val) {
		transformed["resultsTable"] = transformedResultsTable
	}

	return transformed, nil
}

func expandDataplexDatascanDataProfileSpecPostScanActionsBigqueryExportResultsTable(v interface{}, d tpgresource.TerraformResourceData, config *transport_tpg.Config) (interface{}, error) {
	return v, nil
}

func expandDataplexDatascanDataProfileSpecIncludeFields(v interface{}, d tpgresource.TerraformResourceData, config *transport_tpg.Config) (interface{}, error) {
	l := v.([]interface{})
	if len(l) == 0 || l[0] == nil {
		return nil, nil
	}
	raw := l[0]
	original := raw.(map[string]interface{})
	transformed := make(map[string]interface{})

	transformedFieldNames, err := expandDataplexDatascanDataProfileSpecIncludeFieldsFieldNames(original["field_names"], d, config)
	if err != nil {
		return nil, err
	} else if val := reflect.ValueOf(transformedFieldNames); val.IsValid() && !tpgresource.IsEmptyValue(val) {
		transformed["fieldNames"] = transformedFieldNames
	}

	return transformed, nil
}

func expandDataplexDatascanDataProfileSpecIncludeFieldsFieldNames(v interface{}, d tpgresource.TerraformResourceData, config *transport_tpg.Config) (interface{}, error) {
	return v, nil
}

func expandDataplexDatascanDataProfileSpecExcludeFields(v interface{}, d tpgresource.TerraformResourceData, config *transport_tpg.Config) (interface{}, error) {
	l := v.([]interface{})
	if len(l) == 0 || l[0] == nil {
		return nil, nil
	}
	raw := l[0]
	original := raw.(map[string]interface{})
	transformed := make(map[string]interface{})

	transformedFieldNames, err := expandDataplexDatascanDataProfileSpecExcludeFieldsFieldNames(original["field_names"], d, config)
	if err != nil {
		return nil, err
	} else if val := reflect.ValueOf(transformedFieldNames); val.IsValid() && !tpgresource.IsEmptyValue(val) {
		transformed["fieldNames"] = transformedFieldNames
	}

	return transformed, nil
}

func expandDataplexDatascanDataProfileSpecExcludeFieldsFieldNames(v interface{}, d tpgresource.TerraformResourceData, config *transport_tpg.Config) (interface{}, error) {
	return v, nil
}

func expandDataplexDatascanEffectiveLabels(v interface{}, d tpgresource.TerraformResourceData, config *transport_tpg.Config) (map[string]string, error) {
	if v == nil {
		return map[string]string{}, nil
	}
	m := make(map[string]string)
	for k, val := range v.(map[string]interface{}) {
		m[k] = val.(string)
	}
	return m, nil
}
