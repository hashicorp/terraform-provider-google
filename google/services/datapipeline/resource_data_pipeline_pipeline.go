// Copyright (c) HashiCorp, Inc.
// SPDX-License-Identifier: MPL-2.0

// ----------------------------------------------------------------------------
//
//     ***     AUTO GENERATED CODE    ***    Type: MMv1     ***
//
// ----------------------------------------------------------------------------
//
//     This file is automatically generated by Magic Modules and manual
//     changes will be clobbered when the file is regenerated.
//
//     Please read more about how to change this file in
//     .github/CONTRIBUTING.md.
//
// ----------------------------------------------------------------------------

package datapipeline

import (
	"fmt"
	"log"
	"net/http"
	"reflect"
	"strings"
	"time"

	"github.com/hashicorp/terraform-plugin-sdk/v2/helper/customdiff"
	"github.com/hashicorp/terraform-plugin-sdk/v2/helper/schema"

	"github.com/hashicorp/terraform-provider-google/google/tpgresource"
	transport_tpg "github.com/hashicorp/terraform-provider-google/google/transport"
	"github.com/hashicorp/terraform-provider-google/google/verify"
)

func ResourceDataPipelinePipeline() *schema.Resource {
	return &schema.Resource{
		Create: resourceDataPipelinePipelineCreate,
		Read:   resourceDataPipelinePipelineRead,
		Update: resourceDataPipelinePipelineUpdate,
		Delete: resourceDataPipelinePipelineDelete,

		Importer: &schema.ResourceImporter{
			State: resourceDataPipelinePipelineImport,
		},

		Timeouts: &schema.ResourceTimeout{
			Create: schema.DefaultTimeout(20 * time.Minute),
			Update: schema.DefaultTimeout(20 * time.Minute),
			Delete: schema.DefaultTimeout(20 * time.Minute),
		},

		CustomizeDiff: customdiff.All(
			tpgresource.DefaultProviderProject,
		),

		Schema: map[string]*schema.Schema{
			"name": {
				Type:     schema.TypeString,
				Required: true,
				ForceNew: true,
				Description: `"The pipeline name. For example': 'projects/PROJECT_ID/locations/LOCATION_ID/pipelines/PIPELINE_ID."
"- PROJECT_ID can contain letters ([A-Za-z]), numbers ([0-9]), hyphens (-), colons (:), and periods (.). For more information, see Identifying projects."
"LOCATION_ID is the canonical ID for the pipeline's location. The list of available locations can be obtained by calling google.cloud.location.Locations.ListLocations. Note that the Data Pipelines service is not available in all regions. It depends on Cloud Scheduler, an App Engine application, so it's only available in App Engine regions."
"PIPELINE_ID is the ID of the pipeline. Must be unique for the selected project and location."`,
			},
			"state": {
				Type:         schema.TypeString,
				Required:     true,
				ForceNew:     true,
				ValidateFunc: verify.ValidateEnum([]string{"STATE_UNSPECIFIED", "STATE_RESUMING", "STATE_ACTIVE", "STATE_STOPPING", "STATE_ARCHIVED", "STATE_PAUSED"}),
				Description: `The state of the pipeline. When the pipeline is created, the state is set to 'PIPELINE_STATE_ACTIVE' by default. State changes can be requested by setting the state to stopping, paused, or resuming. State cannot be changed through pipelines.patch requests.
https://cloud.google.com/dataflow/docs/reference/data-pipelines/rest/v1/projects.locations.pipelines#state Possible values: ["STATE_UNSPECIFIED", "STATE_RESUMING", "STATE_ACTIVE", "STATE_STOPPING", "STATE_ARCHIVED", "STATE_PAUSED"]`,
			},
			"type": {
				Type:         schema.TypeString,
				Required:     true,
				ValidateFunc: verify.ValidateEnum([]string{"PIPELINE_TYPE_UNSPECIFIED", "PIPELINE_TYPE_BATCH", "PIPELINE_TYPE_STREAMING"}),
				Description: `The type of the pipeline. This field affects the scheduling of the pipeline and the type of metrics to show for the pipeline.
https://cloud.google.com/dataflow/docs/reference/data-pipelines/rest/v1/projects.locations.pipelines#pipelinetype Possible values: ["PIPELINE_TYPE_UNSPECIFIED", "PIPELINE_TYPE_BATCH", "PIPELINE_TYPE_STREAMING"]`,
			},
			"display_name": {
				Type:        schema.TypeString,
				Optional:    true,
				Description: `The display name of the pipeline. It can contain only letters ([A-Za-z]), numbers ([0-9]), hyphens (-), and underscores (_).`,
			},
			"pipeline_sources": {
				Type:     schema.TypeMap,
				Optional: true,
				ForceNew: true,
				Description: `The sources of the pipeline (for example, Dataplex). The keys and values are set by the corresponding sources during pipeline creation.
An object containing a list of "key": value pairs. Example: { "name": "wrench", "mass": "1.3kg", "count": "3" }.`,
				Elem: &schema.Schema{Type: schema.TypeString},
			},
			"region": {
				Type:        schema.TypeString,
				Optional:    true,
				Description: `A reference to the region`,
			},
			"schedule_info": {
				Type:     schema.TypeList,
				Optional: true,
				Description: `Internal scheduling information for a pipeline. If this information is provided, periodic jobs will be created per the schedule. If not, users are responsible for creating jobs externally.
https://cloud.google.com/dataflow/docs/reference/data-pipelines/rest/v1/projects.locations.pipelines#schedulespec`,
				MaxItems: 1,
				Elem: &schema.Resource{
					Schema: map[string]*schema.Schema{
						"schedule": {
							Type:        schema.TypeString,
							Optional:    true,
							Description: `Unix-cron format of the schedule. This information is retrieved from the linked Cloud Scheduler.`,
						},
						"time_zone": {
							Type:        schema.TypeString,
							Optional:    true,
							Description: `Timezone ID. This matches the timezone IDs used by the Cloud Scheduler API. If empty, UTC time is assumed.`,
							Default:     "UTC",
						},
						"next_job_time": {
							Type:     schema.TypeString,
							Computed: true,
							Description: `When the next Scheduler job is going to run.
A timestamp in RFC3339 UTC "Zulu" format, with nanosecond resolution and up to nine fractional digits. Examples: "2014-10-02T15:01:23Z" and "2014-10-02T15:01:23.045123456Z".`,
						},
					},
				},
			},
			"scheduler_service_account_email": {
				Type:        schema.TypeString,
				Computed:    true,
				Optional:    true,
				ForceNew:    true,
				Description: `Optional. A service account email to be used with the Cloud Scheduler job. If not specified, the default compute engine service account will be used.`,
			},
			"workload": {
				Type:     schema.TypeList,
				Optional: true,
				Description: `Workload information for creating new jobs.
https://cloud.google.com/dataflow/docs/reference/data-pipelines/rest/v1/projects.locations.pipelines#workload`,
				MaxItems: 1,
				Elem: &schema.Resource{
					Schema: map[string]*schema.Schema{
						"dataflow_flex_template_request": {
							Type:     schema.TypeList,
							Optional: true,
							Description: `Template information and additional parameters needed to launch a Dataflow job using the flex launch API.
https://cloud.google.com/dataflow/docs/reference/data-pipelines/rest/v1/projects.locations.pipelines#launchflextemplaterequest`,
							MaxItems: 1,
							Elem: &schema.Resource{
								Schema: map[string]*schema.Schema{
									"launch_parameter": {
										Type:     schema.TypeList,
										Required: true,
										Description: `Parameter to launch a job from a Flex Template.
https://cloud.google.com/dataflow/docs/reference/data-pipelines/rest/v1/projects.locations.pipelines#launchflextemplateparameter`,
										MaxItems: 1,
										Elem: &schema.Resource{
											Schema: map[string]*schema.Schema{
												"job_name": {
													Type:        schema.TypeString,
													Required:    true,
													Description: `The job name to use for the created job. For an update job request, the job name should be the same as the existing running job.`,
												},
												"container_spec_gcs_path": {
													Type:        schema.TypeString,
													Optional:    true,
													Description: `Cloud Storage path to a file with a JSON-serialized ContainerSpec as content.`,
												},
												"environment": {
													Type:     schema.TypeList,
													Optional: true,
													Description: `The runtime environment for the Flex Template job.
https://cloud.google.com/dataflow/docs/reference/data-pipelines/rest/v1/projects.locations.pipelines#FlexTemplateRuntimeEnvironment`,
													MaxItems: 1,
													Elem: &schema.Resource{
														Schema: map[string]*schema.Schema{
															"additional_experiments": {
																Type:        schema.TypeList,
																Optional:    true,
																Description: `Additional experiment flags for the job.`,
																Elem: &schema.Schema{
																	Type: schema.TypeString,
																},
															},
															"additional_user_labels": {
																Type:     schema.TypeMap,
																Optional: true,
																Description: `Additional user labels to be specified for the job. Keys and values should follow the restrictions specified in the labeling restrictions page. An object containing a list of key/value pairs.
'Example: { "name": "wrench", "mass": "1kg", "count": "3" }.'
'An object containing a list of "key": value pairs. Example: { "name": "wrench", "mass": "1.3kg", "count": "3" }.'`,
																Elem: &schema.Schema{Type: schema.TypeString},
															},
															"enable_streaming_engine": {
																Type:        schema.TypeBool,
																Optional:    true,
																Description: `Whether to enable Streaming Engine for the job.`,
															},
															"flexrs_goal": {
																Type:         schema.TypeString,
																Optional:     true,
																ValidateFunc: verify.ValidateEnum([]string{"FLEXRS_UNSPECIFIED", "FLEXRS_SPEED_OPTIMIZED", "FLEXRS_COST_OPTIMIZED", ""}),
																Description: `Set FlexRS goal for the job. https://cloud.google.com/dataflow/docs/guides/flexrs
https://cloud.google.com/dataflow/docs/reference/data-pipelines/rest/v1/projects.locations.pipelines#FlexResourceSchedulingGoal Possible values: ["FLEXRS_UNSPECIFIED", "FLEXRS_SPEED_OPTIMIZED", "FLEXRS_COST_OPTIMIZED"]`,
															},
															"ip_configuration": {
																Type:         schema.TypeString,
																Optional:     true,
																ValidateFunc: verify.ValidateEnum([]string{"WORKER_IP_UNSPECIFIED", "WORKER_IP_PUBLIC", "WORKER_IP_PRIVATE", ""}),
																Description: `Configuration for VM IPs.
https://cloud.google.com/dataflow/docs/reference/data-pipelines/rest/v1/projects.locations.pipelines#WorkerIPAddressConfiguration Possible values: ["WORKER_IP_UNSPECIFIED", "WORKER_IP_PUBLIC", "WORKER_IP_PRIVATE"]`,
															},
															"kms_key_name": {
																Type:        schema.TypeString,
																Optional:    true,
																Description: `'Name for the Cloud KMS key for the job. The key format is: projects//locations//keyRings//cryptoKeys/'`,
															},
															"machine_type": {
																Type:        schema.TypeString,
																Optional:    true,
																Description: `The machine type to use for the job. Defaults to the value from the template if not specified.`,
															},
															"max_workers": {
																Type:        schema.TypeInt,
																Optional:    true,
																Description: `The maximum number of Compute Engine instances to be made available to your pipeline during execution, from 1 to 1000.`,
															},
															"network": {
																Type:        schema.TypeString,
																Optional:    true,
																Description: `Network to which VMs will be assigned. If empty or unspecified, the service will use the network "default".`,
															},
															"num_workers": {
																Type:        schema.TypeInt,
																Optional:    true,
																Description: `The initial number of Compute Engine instances for the job.`,
															},
															"service_account_email": {
																Type:        schema.TypeString,
																Optional:    true,
																Description: `The email address of the service account to run the job as.`,
															},
															"subnetwork": {
																Type:        schema.TypeString,
																Optional:    true,
																Description: `Subnetwork to which VMs will be assigned, if desired. You can specify a subnetwork using either a complete URL or an abbreviated path. Expected to be of the form "https://www.googleapis.com/compute/v1/projects/HOST_PROJECT_ID/regions/REGION/subnetworks/SUBNETWORK" or "regions/REGION/subnetworks/SUBNETWORK". If the subnetwork is located in a Shared VPC network, you must use the complete URL.`,
															},
															"temp_location": {
																Type:        schema.TypeString,
																Optional:    true,
																Description: `The Cloud Storage path to use for temporary files. Must be a valid Cloud Storage URL, beginning with gs://.`,
															},
															"worker_region": {
																Type:        schema.TypeString,
																Optional:    true,
																Description: `The Compute Engine region (https://cloud.google.com/compute/docs/regions-zones/regions-zones) in which worker processing should occur, e.g. "us-west1". Mutually exclusive with workerZone. If neither workerRegion nor workerZone is specified, default to the control plane's region.`,
															},
															"worker_zone": {
																Type:        schema.TypeString,
																Optional:    true,
																Description: `The Compute Engine zone (https://cloud.google.com/compute/docs/regions-zones/regions-zones) in which worker processing should occur, e.g. "us-west1-a". Mutually exclusive with workerRegion. If neither workerRegion nor workerZone is specified, a zone in the control plane's region is chosen based on available capacity. If both workerZone and zone are set, workerZone takes precedence.`,
															},
															"zone": {
																Type:        schema.TypeString,
																Optional:    true,
																Description: `The Compute Engine availability zone for launching worker instances to run your pipeline. In the future, workerZone will take precedence.`,
															},
														},
													},
												},
												"launch_options": {
													Type:     schema.TypeMap,
													Optional: true,
													Description: `Launch options for this Flex Template job. This is a common set of options across languages and templates. This should not be used to pass job parameters.
'An object containing a list of "key": value pairs. Example: { "name": "wrench", "mass": "1.3kg", "count": "3" }.'`,
													Elem: &schema.Schema{Type: schema.TypeString},
												},
												"parameters": {
													Type:     schema.TypeMap,
													Optional: true,
													Description: `'The parameters for the Flex Template. Example: {"numWorkers":"5"}'
'An object containing a list of "key": value pairs. Example: { "name": "wrench", "mass": "1.3kg", "count": "3" }.'`,
													Elem: &schema.Schema{Type: schema.TypeString},
												},
												"transform_name_mappings": {
													Type:     schema.TypeMap,
													Optional: true,
													Description: `'Use this to pass transform name mappings for streaming update jobs. Example: {"oldTransformName":"newTransformName",...}'
'An object containing a list of "key": value pairs. Example: { "name": "wrench", "mass": "1.3kg", "count": "3" }.'`,
													Elem: &schema.Schema{Type: schema.TypeString},
												},
												"update": {
													Type:        schema.TypeBool,
													Optional:    true,
													Description: `Set this to true if you are sending a request to update a running streaming job. When set, the job name should be the same as the running job.`,
												},
											},
										},
									},
									"location": {
										Type:        schema.TypeString,
										Required:    true,
										Description: `The regional endpoint to which to direct the request. For example, us-central1, us-west1.`,
									},
									"project_id": {
										Type:        schema.TypeString,
										Required:    true,
										Description: `The ID of the Cloud Platform project that the job belongs to.`,
									},
									"validate_only": {
										Type:        schema.TypeBool,
										Optional:    true,
										Description: `If true, the request is validated but not actually executed. Defaults to false.`,
									},
								},
							},
						},
						"dataflow_launch_template_request": {
							Type:     schema.TypeList,
							Optional: true,
							Description: `Template information and additional parameters needed to launch a Dataflow job using the standard launch API.
https://cloud.google.com/dataflow/docs/reference/data-pipelines/rest/v1/projects.locations.pipelines#launchtemplaterequest`,
							MaxItems: 1,
							Elem: &schema.Resource{
								Schema: map[string]*schema.Schema{
									"project_id": {
										Type:        schema.TypeString,
										Required:    true,
										Description: `The ID of the Cloud Platform project that the job belongs to.`,
									},
									"gcs_path": {
										Type:        schema.TypeString,
										Optional:    true,
										Description: `A Cloud Storage path to the template from which to create the job. Must be a valid Cloud Storage URL, beginning with 'gs://'.`,
									},
									"launch_parameters": {
										Type:     schema.TypeList,
										Optional: true,
										Description: `The parameters of the template to launch. This should be part of the body of the POST request.
https://cloud.google.com/dataflow/docs/reference/data-pipelines/rest/v1/projects.locations.pipelines#launchtemplateparameters`,
										MaxItems: 1,
										Elem: &schema.Resource{
											Schema: map[string]*schema.Schema{
												"job_name": {
													Type:        schema.TypeString,
													Required:    true,
													Description: `The job name to use for the created job.`,
												},
												"environment": {
													Type:     schema.TypeList,
													Optional: true,
													Description: `The runtime environment for the job.
https://cloud.google.com/dataflow/docs/reference/data-pipelines/rest/v1/projects.locations.pipelines#RuntimeEnvironment`,
													MaxItems: 1,
													Elem: &schema.Resource{
														Schema: map[string]*schema.Schema{
															"additional_experiments": {
																Type:        schema.TypeList,
																Optional:    true,
																Description: `Additional experiment flags for the job.`,
																Elem: &schema.Schema{
																	Type: schema.TypeString,
																},
															},
															"additional_user_labels": {
																Type:     schema.TypeMap,
																Optional: true,
																Description: `Additional user labels to be specified for the job. Keys and values should follow the restrictions specified in the labeling restrictions page. An object containing a list of key/value pairs.
'Example: { "name": "wrench", "mass": "1kg", "count": "3" }.'
'An object containing a list of "key": value pairs. Example: { "name": "wrench", "mass": "1.3kg", "count": "3" }.'`,
																Elem: &schema.Schema{Type: schema.TypeString},
															},
															"bypass_temp_dir_validation": {
																Type:        schema.TypeBool,
																Optional:    true,
																Description: `Whether to bypass the safety checks for the job's temporary directory. Use with caution.`,
															},
															"enable_streaming_engine": {
																Type:        schema.TypeBool,
																Optional:    true,
																Description: `Whether to enable Streaming Engine for the job.`,
															},
															"ip_configuration": {
																Type:         schema.TypeString,
																Optional:     true,
																ValidateFunc: verify.ValidateEnum([]string{"WORKER_IP_UNSPECIFIED", "WORKER_IP_PUBLIC", "WORKER_IP_PRIVATE", ""}),
																Description: `Configuration for VM IPs.
https://cloud.google.com/dataflow/docs/reference/data-pipelines/rest/v1/projects.locations.pipelines#WorkerIPAddressConfiguration Possible values: ["WORKER_IP_UNSPECIFIED", "WORKER_IP_PUBLIC", "WORKER_IP_PRIVATE"]`,
															},
															"kms_key_name": {
																Type:        schema.TypeString,
																Optional:    true,
																Description: `'Name for the Cloud KMS key for the job. The key format is: projects//locations//keyRings//cryptoKeys/'`,
															},
															"machine_type": {
																Type:        schema.TypeString,
																Optional:    true,
																Description: `The machine type to use for the job. Defaults to the value from the template if not specified.`,
															},
															"max_workers": {
																Type:        schema.TypeInt,
																Optional:    true,
																Description: `The maximum number of Compute Engine instances to be made available to your pipeline during execution, from 1 to 1000.`,
															},
															"network": {
																Type:        schema.TypeString,
																Computed:    true,
																Optional:    true,
																Description: `Network to which VMs will be assigned. If empty or unspecified, the service will use the network "default".`,
															},
															"num_workers": {
																Type:        schema.TypeInt,
																Optional:    true,
																Description: `The initial number of Compute Engine instances for the job.`,
															},
															"service_account_email": {
																Type:        schema.TypeString,
																Optional:    true,
																Description: `The email address of the service account to run the job as.`,
															},
															"subnetwork": {
																Type:        schema.TypeString,
																Optional:    true,
																Description: `Subnetwork to which VMs will be assigned, if desired. You can specify a subnetwork using either a complete URL or an abbreviated path. Expected to be of the form "https://www.googleapis.com/compute/v1/projects/HOST_PROJECT_ID/regions/REGION/subnetworks/SUBNETWORK" or "regions/REGION/subnetworks/SUBNETWORK". If the subnetwork is located in a Shared VPC network, you must use the complete URL.`,
															},
															"temp_location": {
																Type:        schema.TypeString,
																Optional:    true,
																Description: `The Cloud Storage path to use for temporary files. Must be a valid Cloud Storage URL, beginning with gs://.`,
															},
															"worker_region": {
																Type:        schema.TypeString,
																Optional:    true,
																Description: `The Compute Engine region (https://cloud.google.com/compute/docs/regions-zones/regions-zones) in which worker processing should occur, e.g. "us-west1". Mutually exclusive with workerZone. If neither workerRegion nor workerZone is specified, default to the control plane's region.`,
															},
															"worker_zone": {
																Type:        schema.TypeString,
																Optional:    true,
																Description: `The Compute Engine zone (https://cloud.google.com/compute/docs/regions-zones/regions-zones) in which worker processing should occur, e.g. "us-west1-a". Mutually exclusive with workerRegion. If neither workerRegion nor workerZone is specified, a zone in the control plane's region is chosen based on available capacity. If both workerZone and zone are set, workerZone takes precedence.`,
															},
															"zone": {
																Type:        schema.TypeString,
																Optional:    true,
																Description: `The Compute Engine availability zone for launching worker instances to run your pipeline. In the future, workerZone will take precedence.`,
															},
														},
													},
												},
												"parameters": {
													Type:     schema.TypeMap,
													Optional: true,
													Description: `The runtime parameters to pass to the job.
'An object containing a list of "key": value pairs. Example: { "name": "wrench", "mass": "1.3kg", "count": "3" }.'`,
													Elem: &schema.Schema{Type: schema.TypeString},
												},
												"transform_name_mapping": {
													Type:     schema.TypeMap,
													Optional: true,
													Description: `Map of transform name prefixes of the job to be replaced to the corresponding name prefixes of the new job. Only applicable when updating a pipeline.
'An object containing a list of "key": value pairs. Example: { "name": "wrench", "mass": "1.3kg", "count": "3" }.'`,
													Elem: &schema.Schema{Type: schema.TypeString},
												},
												"update": {
													Type:        schema.TypeBool,
													Optional:    true,
													Description: `If set, replace the existing pipeline with the name specified by jobName with this pipeline, preserving state.`,
												},
											},
										},
									},
									"location": {
										Type:        schema.TypeString,
										Optional:    true,
										Description: `The regional endpoint to which to direct the request.`,
									},
									"validate_only": {
										Type:        schema.TypeBool,
										Optional:    true,
										Description: ``,
									},
								},
							},
						},
					},
				},
			},
			"create_time": {
				Type:     schema.TypeString,
				Computed: true,
				Description: `The timestamp when the pipeline was initially created. Set by the Data Pipelines service.
A timestamp in RFC3339 UTC "Zulu" format, with nanosecond resolution and up to nine fractional digits. Examples: "2014-10-02T15:01:23Z" and "2014-10-02T15:01:23.045123456Z".`,
			},
			"job_count": {
				Type:        schema.TypeInt,
				Computed:    true,
				Description: `Number of jobs.`,
			},
			"last_update_time": {
				Type:     schema.TypeString,
				Computed: true,
				Description: `The timestamp when the pipeline was last modified. Set by the Data Pipelines service.
A timestamp in RFC3339 UTC "Zulu" format, with nanosecond resolution and up to nine fractional digits. Examples: "2014-10-02T15:01:23Z" and "2014-10-02T15:01:23.045123456Z".`,
			},
			"project": {
				Type:     schema.TypeString,
				Optional: true,
				Computed: true,
				ForceNew: true,
			},
		},
		UseJSONNumber: true,
	}
}

func resourceDataPipelinePipelineCreate(d *schema.ResourceData, meta interface{}) error {
	config := meta.(*transport_tpg.Config)
	userAgent, err := tpgresource.GenerateUserAgentString(d, config.UserAgent)
	if err != nil {
		return err
	}

	obj := make(map[string]interface{})
	nameProp, err := expandDataPipelinePipelineName(d.Get("name"), d, config)
	if err != nil {
		return err
	} else if v, ok := d.GetOkExists("name"); !tpgresource.IsEmptyValue(reflect.ValueOf(nameProp)) && (ok || !reflect.DeepEqual(v, nameProp)) {
		obj["name"] = nameProp
	}
	displayNameProp, err := expandDataPipelinePipelineDisplayName(d.Get("display_name"), d, config)
	if err != nil {
		return err
	} else if v, ok := d.GetOkExists("display_name"); !tpgresource.IsEmptyValue(reflect.ValueOf(displayNameProp)) && (ok || !reflect.DeepEqual(v, displayNameProp)) {
		obj["displayName"] = displayNameProp
	}
	typeProp, err := expandDataPipelinePipelineType(d.Get("type"), d, config)
	if err != nil {
		return err
	} else if v, ok := d.GetOkExists("type"); !tpgresource.IsEmptyValue(reflect.ValueOf(typeProp)) && (ok || !reflect.DeepEqual(v, typeProp)) {
		obj["type"] = typeProp
	}
	stateProp, err := expandDataPipelinePipelineState(d.Get("state"), d, config)
	if err != nil {
		return err
	} else if v, ok := d.GetOkExists("state"); !tpgresource.IsEmptyValue(reflect.ValueOf(stateProp)) && (ok || !reflect.DeepEqual(v, stateProp)) {
		obj["state"] = stateProp
	}
	workloadProp, err := expandDataPipelinePipelineWorkload(d.Get("workload"), d, config)
	if err != nil {
		return err
	} else if v, ok := d.GetOkExists("workload"); !tpgresource.IsEmptyValue(reflect.ValueOf(workloadProp)) && (ok || !reflect.DeepEqual(v, workloadProp)) {
		obj["workload"] = workloadProp
	}
	scheduleInfoProp, err := expandDataPipelinePipelineScheduleInfo(d.Get("schedule_info"), d, config)
	if err != nil {
		return err
	} else if v, ok := d.GetOkExists("schedule_info"); !tpgresource.IsEmptyValue(reflect.ValueOf(scheduleInfoProp)) && (ok || !reflect.DeepEqual(v, scheduleInfoProp)) {
		obj["scheduleInfo"] = scheduleInfoProp
	}
	schedulerServiceAccountEmailProp, err := expandDataPipelinePipelineSchedulerServiceAccountEmail(d.Get("scheduler_service_account_email"), d, config)
	if err != nil {
		return err
	} else if v, ok := d.GetOkExists("scheduler_service_account_email"); !tpgresource.IsEmptyValue(reflect.ValueOf(schedulerServiceAccountEmailProp)) && (ok || !reflect.DeepEqual(v, schedulerServiceAccountEmailProp)) {
		obj["schedulerServiceAccountEmail"] = schedulerServiceAccountEmailProp
	}
	pipelineSourcesProp, err := expandDataPipelinePipelinePipelineSources(d.Get("pipeline_sources"), d, config)
	if err != nil {
		return err
	} else if v, ok := d.GetOkExists("pipeline_sources"); !tpgresource.IsEmptyValue(reflect.ValueOf(pipelineSourcesProp)) && (ok || !reflect.DeepEqual(v, pipelineSourcesProp)) {
		obj["pipelineSources"] = pipelineSourcesProp
	}

	url, err := tpgresource.ReplaceVars(d, config, "{{DataPipelineBasePath}}projects/{{project}}/locations/{{region}}/pipelines")
	if err != nil {
		return err
	}

	log.Printf("[DEBUG] Creating new Pipeline: %#v", obj)
	billingProject := ""

	project, err := tpgresource.GetProject(d, config)
	if err != nil {
		return fmt.Errorf("Error fetching project for Pipeline: %s", err)
	}
	billingProject = project

	// err == nil indicates that the billing_project value was found
	if bp, err := tpgresource.GetBillingProject(d, config); err == nil {
		billingProject = bp
	}

	headers := make(http.Header)
	res, err := transport_tpg.SendRequest(transport_tpg.SendRequestOptions{
		Config:    config,
		Method:    "POST",
		Project:   billingProject,
		RawURL:    url,
		UserAgent: userAgent,
		Body:      obj,
		Timeout:   d.Timeout(schema.TimeoutCreate),
		Headers:   headers,
	})
	if err != nil {
		return fmt.Errorf("Error creating Pipeline: %s", err)
	}

	// Store the ID now
	id, err := tpgresource.ReplaceVars(d, config, "projects/{{project}}/locations/{{region}}/pipelines/{{name}}")
	if err != nil {
		return fmt.Errorf("Error constructing id: %s", err)
	}
	d.SetId(id)

	log.Printf("[DEBUG] Finished creating Pipeline %q: %#v", d.Id(), res)

	return resourceDataPipelinePipelineRead(d, meta)
}

func resourceDataPipelinePipelineRead(d *schema.ResourceData, meta interface{}) error {
	config := meta.(*transport_tpg.Config)
	userAgent, err := tpgresource.GenerateUserAgentString(d, config.UserAgent)
	if err != nil {
		return err
	}

	url, err := tpgresource.ReplaceVars(d, config, "{{DataPipelineBasePath}}projects/{{project}}/locations/{{region}}/pipelines/{{name}}")
	if err != nil {
		return err
	}

	billingProject := ""

	project, err := tpgresource.GetProject(d, config)
	if err != nil {
		return fmt.Errorf("Error fetching project for Pipeline: %s", err)
	}
	billingProject = project

	// err == nil indicates that the billing_project value was found
	if bp, err := tpgresource.GetBillingProject(d, config); err == nil {
		billingProject = bp
	}

	headers := make(http.Header)
	res, err := transport_tpg.SendRequest(transport_tpg.SendRequestOptions{
		Config:    config,
		Method:    "GET",
		Project:   billingProject,
		RawURL:    url,
		UserAgent: userAgent,
		Headers:   headers,
	})
	if err != nil {
		return transport_tpg.HandleNotFoundError(err, d, fmt.Sprintf("DataPipelinePipeline %q", d.Id()))
	}

	if err := d.Set("project", project); err != nil {
		return fmt.Errorf("Error reading Pipeline: %s", err)
	}

	if err := d.Set("name", flattenDataPipelinePipelineName(res["name"], d, config)); err != nil {
		return fmt.Errorf("Error reading Pipeline: %s", err)
	}
	if err := d.Set("display_name", flattenDataPipelinePipelineDisplayName(res["displayName"], d, config)); err != nil {
		return fmt.Errorf("Error reading Pipeline: %s", err)
	}
	if err := d.Set("type", flattenDataPipelinePipelineType(res["type"], d, config)); err != nil {
		return fmt.Errorf("Error reading Pipeline: %s", err)
	}
	if err := d.Set("state", flattenDataPipelinePipelineState(res["state"], d, config)); err != nil {
		return fmt.Errorf("Error reading Pipeline: %s", err)
	}
	if err := d.Set("create_time", flattenDataPipelinePipelineCreateTime(res["createTime"], d, config)); err != nil {
		return fmt.Errorf("Error reading Pipeline: %s", err)
	}
	if err := d.Set("last_update_time", flattenDataPipelinePipelineLastUpdateTime(res["lastUpdateTime"], d, config)); err != nil {
		return fmt.Errorf("Error reading Pipeline: %s", err)
	}
	if err := d.Set("workload", flattenDataPipelinePipelineWorkload(res["workload"], d, config)); err != nil {
		return fmt.Errorf("Error reading Pipeline: %s", err)
	}
	if err := d.Set("schedule_info", flattenDataPipelinePipelineScheduleInfo(res["scheduleInfo"], d, config)); err != nil {
		return fmt.Errorf("Error reading Pipeline: %s", err)
	}
	if err := d.Set("job_count", flattenDataPipelinePipelineJobCount(res["jobCount"], d, config)); err != nil {
		return fmt.Errorf("Error reading Pipeline: %s", err)
	}
	if err := d.Set("scheduler_service_account_email", flattenDataPipelinePipelineSchedulerServiceAccountEmail(res["schedulerServiceAccountEmail"], d, config)); err != nil {
		return fmt.Errorf("Error reading Pipeline: %s", err)
	}
	if err := d.Set("pipeline_sources", flattenDataPipelinePipelinePipelineSources(res["pipelineSources"], d, config)); err != nil {
		return fmt.Errorf("Error reading Pipeline: %s", err)
	}

	return nil
}

func resourceDataPipelinePipelineUpdate(d *schema.ResourceData, meta interface{}) error {
	config := meta.(*transport_tpg.Config)
	userAgent, err := tpgresource.GenerateUserAgentString(d, config.UserAgent)
	if err != nil {
		return err
	}

	billingProject := ""

	project, err := tpgresource.GetProject(d, config)
	if err != nil {
		return fmt.Errorf("Error fetching project for Pipeline: %s", err)
	}
	billingProject = project

	obj := make(map[string]interface{})
	displayNameProp, err := expandDataPipelinePipelineDisplayName(d.Get("display_name"), d, config)
	if err != nil {
		return err
	} else if v, ok := d.GetOkExists("display_name"); !tpgresource.IsEmptyValue(reflect.ValueOf(v)) && (ok || !reflect.DeepEqual(v, displayNameProp)) {
		obj["displayName"] = displayNameProp
	}
	typeProp, err := expandDataPipelinePipelineType(d.Get("type"), d, config)
	if err != nil {
		return err
	} else if v, ok := d.GetOkExists("type"); !tpgresource.IsEmptyValue(reflect.ValueOf(v)) && (ok || !reflect.DeepEqual(v, typeProp)) {
		obj["type"] = typeProp
	}
	workloadProp, err := expandDataPipelinePipelineWorkload(d.Get("workload"), d, config)
	if err != nil {
		return err
	} else if v, ok := d.GetOkExists("workload"); !tpgresource.IsEmptyValue(reflect.ValueOf(v)) && (ok || !reflect.DeepEqual(v, workloadProp)) {
		obj["workload"] = workloadProp
	}
	scheduleInfoProp, err := expandDataPipelinePipelineScheduleInfo(d.Get("schedule_info"), d, config)
	if err != nil {
		return err
	} else if v, ok := d.GetOkExists("schedule_info"); !tpgresource.IsEmptyValue(reflect.ValueOf(v)) && (ok || !reflect.DeepEqual(v, scheduleInfoProp)) {
		obj["scheduleInfo"] = scheduleInfoProp
	}

	url, err := tpgresource.ReplaceVars(d, config, "{{DataPipelineBasePath}}projects/{{project}}/locations/{{region}}/pipelines/{{name}}")
	if err != nil {
		return err
	}

	log.Printf("[DEBUG] Updating Pipeline %q: %#v", d.Id(), obj)
	headers := make(http.Header)
	updateMask := []string{}

	if d.HasChange("display_name") {
		updateMask = append(updateMask, "displayName")
	}

	if d.HasChange("type") {
		updateMask = append(updateMask, "type")
	}

	if d.HasChange("workload") {
		updateMask = append(updateMask, "workload")
	}

	if d.HasChange("schedule_info") {
		updateMask = append(updateMask, "scheduleInfo")
	}
	// updateMask is a URL parameter but not present in the schema, so ReplaceVars
	// won't set it
	url, err = transport_tpg.AddQueryParams(url, map[string]string{"updateMask": strings.Join(updateMask, ",")})
	if err != nil {
		return err
	}

	// err == nil indicates that the billing_project value was found
	if bp, err := tpgresource.GetBillingProject(d, config); err == nil {
		billingProject = bp
	}

	// if updateMask is empty we are not updating anything so skip the post
	if len(updateMask) > 0 {
		res, err := transport_tpg.SendRequest(transport_tpg.SendRequestOptions{
			Config:    config,
			Method:    "PATCH",
			Project:   billingProject,
			RawURL:    url,
			UserAgent: userAgent,
			Body:      obj,
			Timeout:   d.Timeout(schema.TimeoutUpdate),
			Headers:   headers,
		})

		if err != nil {
			return fmt.Errorf("Error updating Pipeline %q: %s", d.Id(), err)
		} else {
			log.Printf("[DEBUG] Finished updating Pipeline %q: %#v", d.Id(), res)
		}

	}

	return resourceDataPipelinePipelineRead(d, meta)
}

func resourceDataPipelinePipelineDelete(d *schema.ResourceData, meta interface{}) error {
	config := meta.(*transport_tpg.Config)
	userAgent, err := tpgresource.GenerateUserAgentString(d, config.UserAgent)
	if err != nil {
		return err
	}

	billingProject := ""

	project, err := tpgresource.GetProject(d, config)
	if err != nil {
		return fmt.Errorf("Error fetching project for Pipeline: %s", err)
	}
	billingProject = project

	url, err := tpgresource.ReplaceVars(d, config, "{{DataPipelineBasePath}}projects/{{project}}/locations/{{region}}/pipelines/{{name}}")
	if err != nil {
		return err
	}

	var obj map[string]interface{}

	// err == nil indicates that the billing_project value was found
	if bp, err := tpgresource.GetBillingProject(d, config); err == nil {
		billingProject = bp
	}

	headers := make(http.Header)

	log.Printf("[DEBUG] Deleting Pipeline %q", d.Id())
	res, err := transport_tpg.SendRequest(transport_tpg.SendRequestOptions{
		Config:    config,
		Method:    "DELETE",
		Project:   billingProject,
		RawURL:    url,
		UserAgent: userAgent,
		Body:      obj,
		Timeout:   d.Timeout(schema.TimeoutDelete),
		Headers:   headers,
	})
	if err != nil {
		return transport_tpg.HandleNotFoundError(err, d, "Pipeline")
	}

	log.Printf("[DEBUG] Finished deleting Pipeline %q: %#v", d.Id(), res)
	return nil
}

func resourceDataPipelinePipelineImport(d *schema.ResourceData, meta interface{}) ([]*schema.ResourceData, error) {
	config := meta.(*transport_tpg.Config)
	if err := tpgresource.ParseImportId([]string{
		"^projects/(?P<project>[^/]+)/locations/(?P<region>[^/]+)/pipelines/(?P<name>[^/]+)$",
		"^(?P<project>[^/]+)/(?P<region>[^/]+)/(?P<name>[^/]+)$",
		"^(?P<region>[^/]+)/(?P<name>[^/]+)$",
		"^(?P<name>[^/]+)$",
	}, d, config); err != nil {
		return nil, err
	}

	// Replace import id for the resource id
	id, err := tpgresource.ReplaceVars(d, config, "projects/{{project}}/locations/{{region}}/pipelines/{{name}}")
	if err != nil {
		return nil, fmt.Errorf("Error constructing id: %s", err)
	}
	d.SetId(id)

	return []*schema.ResourceData{d}, nil
}

func flattenDataPipelinePipelineName(v interface{}, d *schema.ResourceData, config *transport_tpg.Config) interface{} {
	if v == nil {
		return v
	}
	return tpgresource.NameFromSelfLinkStateFunc(v)
}

func flattenDataPipelinePipelineDisplayName(v interface{}, d *schema.ResourceData, config *transport_tpg.Config) interface{} {
	return v
}

func flattenDataPipelinePipelineType(v interface{}, d *schema.ResourceData, config *transport_tpg.Config) interface{} {
	return v
}

func flattenDataPipelinePipelineState(v interface{}, d *schema.ResourceData, config *transport_tpg.Config) interface{} {
	return v
}

func flattenDataPipelinePipelineCreateTime(v interface{}, d *schema.ResourceData, config *transport_tpg.Config) interface{} {
	return v
}

func flattenDataPipelinePipelineLastUpdateTime(v interface{}, d *schema.ResourceData, config *transport_tpg.Config) interface{} {
	return v
}

func flattenDataPipelinePipelineWorkload(v interface{}, d *schema.ResourceData, config *transport_tpg.Config) interface{} {
	if v == nil {
		return nil
	}
	original := v.(map[string]interface{})
	if len(original) == 0 {
		return nil
	}
	transformed := make(map[string]interface{})
	transformed["dataflow_launch_template_request"] =
		flattenDataPipelinePipelineWorkloadDataflowLaunchTemplateRequest(original["dataflowLaunchTemplateRequest"], d, config)
	transformed["dataflow_flex_template_request"] =
		flattenDataPipelinePipelineWorkloadDataflowFlexTemplateRequest(original["dataflowFlexTemplateRequest"], d, config)
	return []interface{}{transformed}
}
func flattenDataPipelinePipelineWorkloadDataflowLaunchTemplateRequest(v interface{}, d *schema.ResourceData, config *transport_tpg.Config) interface{} {
	if v == nil {
		return nil
	}
	original := v.(map[string]interface{})
	if len(original) == 0 {
		return nil
	}
	transformed := make(map[string]interface{})
	transformed["project_id"] =
		flattenDataPipelinePipelineWorkloadDataflowLaunchTemplateRequestProjectId(original["projectId"], d, config)
	transformed["validate_only"] =
		flattenDataPipelinePipelineWorkloadDataflowLaunchTemplateRequestValidateOnly(original["validateOnly"], d, config)
	transformed["launch_parameters"] =
		flattenDataPipelinePipelineWorkloadDataflowLaunchTemplateRequestLaunchParameters(original["launchParameters"], d, config)
	transformed["location"] =
		flattenDataPipelinePipelineWorkloadDataflowLaunchTemplateRequestLocation(original["location"], d, config)
	transformed["gcs_path"] =
		flattenDataPipelinePipelineWorkloadDataflowLaunchTemplateRequestGcsPath(original["gcsPath"], d, config)
	return []interface{}{transformed}
}
func flattenDataPipelinePipelineWorkloadDataflowLaunchTemplateRequestProjectId(v interface{}, d *schema.ResourceData, config *transport_tpg.Config) interface{} {
	return v
}

func flattenDataPipelinePipelineWorkloadDataflowLaunchTemplateRequestValidateOnly(v interface{}, d *schema.ResourceData, config *transport_tpg.Config) interface{} {
	return v
}

func flattenDataPipelinePipelineWorkloadDataflowLaunchTemplateRequestLaunchParameters(v interface{}, d *schema.ResourceData, config *transport_tpg.Config) interface{} {
	if v == nil {
		return nil
	}
	original := v.(map[string]interface{})
	if len(original) == 0 {
		return nil
	}
	transformed := make(map[string]interface{})
	transformed["job_name"] =
		flattenDataPipelinePipelineWorkloadDataflowLaunchTemplateRequestLaunchParametersJobName(original["jobName"], d, config)
	transformed["parameters"] =
		flattenDataPipelinePipelineWorkloadDataflowLaunchTemplateRequestLaunchParametersParameters(original["parameters"], d, config)
	transformed["environment"] =
		flattenDataPipelinePipelineWorkloadDataflowLaunchTemplateRequestLaunchParametersEnvironment(original["environment"], d, config)
	transformed["update"] =
		flattenDataPipelinePipelineWorkloadDataflowLaunchTemplateRequestLaunchParametersUpdate(original["update"], d, config)
	transformed["transform_name_mapping"] =
		flattenDataPipelinePipelineWorkloadDataflowLaunchTemplateRequestLaunchParametersTransformNameMapping(original["transformNameMapping"], d, config)
	return []interface{}{transformed}
}
func flattenDataPipelinePipelineWorkloadDataflowLaunchTemplateRequestLaunchParametersJobName(v interface{}, d *schema.ResourceData, config *transport_tpg.Config) interface{} {
	return v
}

func flattenDataPipelinePipelineWorkloadDataflowLaunchTemplateRequestLaunchParametersParameters(v interface{}, d *schema.ResourceData, config *transport_tpg.Config) interface{} {
	return v
}

func flattenDataPipelinePipelineWorkloadDataflowLaunchTemplateRequestLaunchParametersEnvironment(v interface{}, d *schema.ResourceData, config *transport_tpg.Config) interface{} {
	if v == nil {
		return nil
	}
	original := v.(map[string]interface{})
	if len(original) == 0 {
		return nil
	}
	transformed := make(map[string]interface{})
	transformed["num_workers"] =
		flattenDataPipelinePipelineWorkloadDataflowLaunchTemplateRequestLaunchParametersEnvironmentNumWorkers(original["numWorkers"], d, config)
	transformed["max_workers"] =
		flattenDataPipelinePipelineWorkloadDataflowLaunchTemplateRequestLaunchParametersEnvironmentMaxWorkers(original["maxWorkers"], d, config)
	transformed["zone"] =
		flattenDataPipelinePipelineWorkloadDataflowLaunchTemplateRequestLaunchParametersEnvironmentZone(original["zone"], d, config)
	transformed["service_account_email"] =
		flattenDataPipelinePipelineWorkloadDataflowLaunchTemplateRequestLaunchParametersEnvironmentServiceAccountEmail(original["serviceAccountEmail"], d, config)
	transformed["temp_location"] =
		flattenDataPipelinePipelineWorkloadDataflowLaunchTemplateRequestLaunchParametersEnvironmentTempLocation(original["tempLocation"], d, config)
	transformed["bypass_temp_dir_validation"] =
		flattenDataPipelinePipelineWorkloadDataflowLaunchTemplateRequestLaunchParametersEnvironmentBypassTempDirValidation(original["bypassTempDirValidation"], d, config)
	transformed["machine_type"] =
		flattenDataPipelinePipelineWorkloadDataflowLaunchTemplateRequestLaunchParametersEnvironmentMachineType(original["machineType"], d, config)
	transformed["additional_experiments"] =
		flattenDataPipelinePipelineWorkloadDataflowLaunchTemplateRequestLaunchParametersEnvironmentAdditionalExperiments(original["additionalExperiments"], d, config)
	transformed["network"] =
		flattenDataPipelinePipelineWorkloadDataflowLaunchTemplateRequestLaunchParametersEnvironmentNetwork(original["network"], d, config)
	transformed["subnetwork"] =
		flattenDataPipelinePipelineWorkloadDataflowLaunchTemplateRequestLaunchParametersEnvironmentSubnetwork(original["subnetwork"], d, config)
	transformed["additional_user_labels"] =
		flattenDataPipelinePipelineWorkloadDataflowLaunchTemplateRequestLaunchParametersEnvironmentAdditionalUserLabels(original["additionalUserLabels"], d, config)
	transformed["kms_key_name"] =
		flattenDataPipelinePipelineWorkloadDataflowLaunchTemplateRequestLaunchParametersEnvironmentKmsKeyName(original["kmsKeyName"], d, config)
	transformed["ip_configuration"] =
		flattenDataPipelinePipelineWorkloadDataflowLaunchTemplateRequestLaunchParametersEnvironmentIpConfiguration(original["ipConfiguration"], d, config)
	transformed["worker_region"] =
		flattenDataPipelinePipelineWorkloadDataflowLaunchTemplateRequestLaunchParametersEnvironmentWorkerRegion(original["workerRegion"], d, config)
	transformed["worker_zone"] =
		flattenDataPipelinePipelineWorkloadDataflowLaunchTemplateRequestLaunchParametersEnvironmentWorkerZone(original["workerZone"], d, config)
	transformed["enable_streaming_engine"] =
		flattenDataPipelinePipelineWorkloadDataflowLaunchTemplateRequestLaunchParametersEnvironmentEnableStreamingEngine(original["enableStreamingEngine"], d, config)
	return []interface{}{transformed}
}
func flattenDataPipelinePipelineWorkloadDataflowLaunchTemplateRequestLaunchParametersEnvironmentNumWorkers(v interface{}, d *schema.ResourceData, config *transport_tpg.Config) interface{} {
	// Handles the string fixed64 format
	if strVal, ok := v.(string); ok {
		if intVal, err := tpgresource.StringToFixed64(strVal); err == nil {
			return intVal
		}
	}

	// number values are represented as float64
	if floatVal, ok := v.(float64); ok {
		intVal := int(floatVal)
		return intVal
	}

	return v // let terraform core handle it otherwise
}

func flattenDataPipelinePipelineWorkloadDataflowLaunchTemplateRequestLaunchParametersEnvironmentMaxWorkers(v interface{}, d *schema.ResourceData, config *transport_tpg.Config) interface{} {
	// Handles the string fixed64 format
	if strVal, ok := v.(string); ok {
		if intVal, err := tpgresource.StringToFixed64(strVal); err == nil {
			return intVal
		}
	}

	// number values are represented as float64
	if floatVal, ok := v.(float64); ok {
		intVal := int(floatVal)
		return intVal
	}

	return v // let terraform core handle it otherwise
}

func flattenDataPipelinePipelineWorkloadDataflowLaunchTemplateRequestLaunchParametersEnvironmentZone(v interface{}, d *schema.ResourceData, config *transport_tpg.Config) interface{} {
	return v
}

func flattenDataPipelinePipelineWorkloadDataflowLaunchTemplateRequestLaunchParametersEnvironmentServiceAccountEmail(v interface{}, d *schema.ResourceData, config *transport_tpg.Config) interface{} {
	return v
}

func flattenDataPipelinePipelineWorkloadDataflowLaunchTemplateRequestLaunchParametersEnvironmentTempLocation(v interface{}, d *schema.ResourceData, config *transport_tpg.Config) interface{} {
	return v
}

func flattenDataPipelinePipelineWorkloadDataflowLaunchTemplateRequestLaunchParametersEnvironmentBypassTempDirValidation(v interface{}, d *schema.ResourceData, config *transport_tpg.Config) interface{} {
	return v
}

func flattenDataPipelinePipelineWorkloadDataflowLaunchTemplateRequestLaunchParametersEnvironmentMachineType(v interface{}, d *schema.ResourceData, config *transport_tpg.Config) interface{} {
	return v
}

func flattenDataPipelinePipelineWorkloadDataflowLaunchTemplateRequestLaunchParametersEnvironmentAdditionalExperiments(v interface{}, d *schema.ResourceData, config *transport_tpg.Config) interface{} {
	return v
}

func flattenDataPipelinePipelineWorkloadDataflowLaunchTemplateRequestLaunchParametersEnvironmentNetwork(v interface{}, d *schema.ResourceData, config *transport_tpg.Config) interface{} {
	return v
}

func flattenDataPipelinePipelineWorkloadDataflowLaunchTemplateRequestLaunchParametersEnvironmentSubnetwork(v interface{}, d *schema.ResourceData, config *transport_tpg.Config) interface{} {
	return v
}

func flattenDataPipelinePipelineWorkloadDataflowLaunchTemplateRequestLaunchParametersEnvironmentAdditionalUserLabels(v interface{}, d *schema.ResourceData, config *transport_tpg.Config) interface{} {
	return v
}

func flattenDataPipelinePipelineWorkloadDataflowLaunchTemplateRequestLaunchParametersEnvironmentKmsKeyName(v interface{}, d *schema.ResourceData, config *transport_tpg.Config) interface{} {
	return v
}

func flattenDataPipelinePipelineWorkloadDataflowLaunchTemplateRequestLaunchParametersEnvironmentIpConfiguration(v interface{}, d *schema.ResourceData, config *transport_tpg.Config) interface{} {
	return v
}

func flattenDataPipelinePipelineWorkloadDataflowLaunchTemplateRequestLaunchParametersEnvironmentWorkerRegion(v interface{}, d *schema.ResourceData, config *transport_tpg.Config) interface{} {
	return v
}

func flattenDataPipelinePipelineWorkloadDataflowLaunchTemplateRequestLaunchParametersEnvironmentWorkerZone(v interface{}, d *schema.ResourceData, config *transport_tpg.Config) interface{} {
	return v
}

func flattenDataPipelinePipelineWorkloadDataflowLaunchTemplateRequestLaunchParametersEnvironmentEnableStreamingEngine(v interface{}, d *schema.ResourceData, config *transport_tpg.Config) interface{} {
	return v
}

func flattenDataPipelinePipelineWorkloadDataflowLaunchTemplateRequestLaunchParametersUpdate(v interface{}, d *schema.ResourceData, config *transport_tpg.Config) interface{} {
	return v
}

func flattenDataPipelinePipelineWorkloadDataflowLaunchTemplateRequestLaunchParametersTransformNameMapping(v interface{}, d *schema.ResourceData, config *transport_tpg.Config) interface{} {
	return v
}

func flattenDataPipelinePipelineWorkloadDataflowLaunchTemplateRequestLocation(v interface{}, d *schema.ResourceData, config *transport_tpg.Config) interface{} {
	return v
}

func flattenDataPipelinePipelineWorkloadDataflowLaunchTemplateRequestGcsPath(v interface{}, d *schema.ResourceData, config *transport_tpg.Config) interface{} {
	return v
}

func flattenDataPipelinePipelineWorkloadDataflowFlexTemplateRequest(v interface{}, d *schema.ResourceData, config *transport_tpg.Config) interface{} {
	if v == nil {
		return nil
	}
	original := v.(map[string]interface{})
	if len(original) == 0 {
		return nil
	}
	transformed := make(map[string]interface{})
	transformed["project_id"] =
		flattenDataPipelinePipelineWorkloadDataflowFlexTemplateRequestProjectId(original["projectId"], d, config)
	transformed["launch_parameter"] =
		flattenDataPipelinePipelineWorkloadDataflowFlexTemplateRequestLaunchParameter(original["launchParameter"], d, config)
	transformed["location"] =
		flattenDataPipelinePipelineWorkloadDataflowFlexTemplateRequestLocation(original["location"], d, config)
	transformed["validate_only"] =
		flattenDataPipelinePipelineWorkloadDataflowFlexTemplateRequestValidateOnly(original["validateOnly"], d, config)
	return []interface{}{transformed}
}
func flattenDataPipelinePipelineWorkloadDataflowFlexTemplateRequestProjectId(v interface{}, d *schema.ResourceData, config *transport_tpg.Config) interface{} {
	return v
}

func flattenDataPipelinePipelineWorkloadDataflowFlexTemplateRequestLaunchParameter(v interface{}, d *schema.ResourceData, config *transport_tpg.Config) interface{} {
	if v == nil {
		return nil
	}
	original := v.(map[string]interface{})
	if len(original) == 0 {
		return nil
	}
	transformed := make(map[string]interface{})
	transformed["job_name"] =
		flattenDataPipelinePipelineWorkloadDataflowFlexTemplateRequestLaunchParameterJobName(original["jobName"], d, config)
	transformed["parameters"] =
		flattenDataPipelinePipelineWorkloadDataflowFlexTemplateRequestLaunchParameterParameters(original["parameters"], d, config)
	transformed["launch_options"] =
		flattenDataPipelinePipelineWorkloadDataflowFlexTemplateRequestLaunchParameterLaunchOptions(original["launchOptions"], d, config)
	transformed["environment"] =
		flattenDataPipelinePipelineWorkloadDataflowFlexTemplateRequestLaunchParameterEnvironment(original["environment"], d, config)
	transformed["update"] =
		flattenDataPipelinePipelineWorkloadDataflowFlexTemplateRequestLaunchParameterUpdate(original["update"], d, config)
	transformed["transform_name_mappings"] =
		flattenDataPipelinePipelineWorkloadDataflowFlexTemplateRequestLaunchParameterTransformNameMappings(original["transformNameMappings"], d, config)
	transformed["container_spec_gcs_path"] =
		flattenDataPipelinePipelineWorkloadDataflowFlexTemplateRequestLaunchParameterContainerSpecGcsPath(original["containerSpecGcsPath"], d, config)
	return []interface{}{transformed}
}
func flattenDataPipelinePipelineWorkloadDataflowFlexTemplateRequestLaunchParameterJobName(v interface{}, d *schema.ResourceData, config *transport_tpg.Config) interface{} {
	return v
}

func flattenDataPipelinePipelineWorkloadDataflowFlexTemplateRequestLaunchParameterParameters(v interface{}, d *schema.ResourceData, config *transport_tpg.Config) interface{} {
	return v
}

func flattenDataPipelinePipelineWorkloadDataflowFlexTemplateRequestLaunchParameterLaunchOptions(v interface{}, d *schema.ResourceData, config *transport_tpg.Config) interface{} {
	return v
}

func flattenDataPipelinePipelineWorkloadDataflowFlexTemplateRequestLaunchParameterEnvironment(v interface{}, d *schema.ResourceData, config *transport_tpg.Config) interface{} {
	if v == nil {
		return nil
	}
	original := v.(map[string]interface{})
	if len(original) == 0 {
		return nil
	}
	transformed := make(map[string]interface{})
	transformed["num_workers"] =
		flattenDataPipelinePipelineWorkloadDataflowFlexTemplateRequestLaunchParameterEnvironmentNumWorkers(original["numWorkers"], d, config)
	transformed["max_workers"] =
		flattenDataPipelinePipelineWorkloadDataflowFlexTemplateRequestLaunchParameterEnvironmentMaxWorkers(original["maxWorkers"], d, config)
	transformed["zone"] =
		flattenDataPipelinePipelineWorkloadDataflowFlexTemplateRequestLaunchParameterEnvironmentZone(original["zone"], d, config)
	transformed["service_account_email"] =
		flattenDataPipelinePipelineWorkloadDataflowFlexTemplateRequestLaunchParameterEnvironmentServiceAccountEmail(original["serviceAccountEmail"], d, config)
	transformed["temp_location"] =
		flattenDataPipelinePipelineWorkloadDataflowFlexTemplateRequestLaunchParameterEnvironmentTempLocation(original["tempLocation"], d, config)
	transformed["machine_type"] =
		flattenDataPipelinePipelineWorkloadDataflowFlexTemplateRequestLaunchParameterEnvironmentMachineType(original["machineType"], d, config)
	transformed["additional_experiments"] =
		flattenDataPipelinePipelineWorkloadDataflowFlexTemplateRequestLaunchParameterEnvironmentAdditionalExperiments(original["additionalExperiments"], d, config)
	transformed["network"] =
		flattenDataPipelinePipelineWorkloadDataflowFlexTemplateRequestLaunchParameterEnvironmentNetwork(original["network"], d, config)
	transformed["subnetwork"] =
		flattenDataPipelinePipelineWorkloadDataflowFlexTemplateRequestLaunchParameterEnvironmentSubnetwork(original["subnetwork"], d, config)
	transformed["additional_user_labels"] =
		flattenDataPipelinePipelineWorkloadDataflowFlexTemplateRequestLaunchParameterEnvironmentAdditionalUserLabels(original["additionalUserLabels"], d, config)
	transformed["kms_key_name"] =
		flattenDataPipelinePipelineWorkloadDataflowFlexTemplateRequestLaunchParameterEnvironmentKmsKeyName(original["kmsKeyName"], d, config)
	transformed["ip_configuration"] =
		flattenDataPipelinePipelineWorkloadDataflowFlexTemplateRequestLaunchParameterEnvironmentIpConfiguration(original["ipConfiguration"], d, config)
	transformed["worker_region"] =
		flattenDataPipelinePipelineWorkloadDataflowFlexTemplateRequestLaunchParameterEnvironmentWorkerRegion(original["workerRegion"], d, config)
	transformed["worker_zone"] =
		flattenDataPipelinePipelineWorkloadDataflowFlexTemplateRequestLaunchParameterEnvironmentWorkerZone(original["workerZone"], d, config)
	transformed["enable_streaming_engine"] =
		flattenDataPipelinePipelineWorkloadDataflowFlexTemplateRequestLaunchParameterEnvironmentEnableStreamingEngine(original["enableStreamingEngine"], d, config)
	transformed["flexrs_goal"] =
		flattenDataPipelinePipelineWorkloadDataflowFlexTemplateRequestLaunchParameterEnvironmentFlexrsGoal(original["flexrsGoal"], d, config)
	return []interface{}{transformed}
}
func flattenDataPipelinePipelineWorkloadDataflowFlexTemplateRequestLaunchParameterEnvironmentNumWorkers(v interface{}, d *schema.ResourceData, config *transport_tpg.Config) interface{} {
	// Handles the string fixed64 format
	if strVal, ok := v.(string); ok {
		if intVal, err := tpgresource.StringToFixed64(strVal); err == nil {
			return intVal
		}
	}

	// number values are represented as float64
	if floatVal, ok := v.(float64); ok {
		intVal := int(floatVal)
		return intVal
	}

	return v // let terraform core handle it otherwise
}

func flattenDataPipelinePipelineWorkloadDataflowFlexTemplateRequestLaunchParameterEnvironmentMaxWorkers(v interface{}, d *schema.ResourceData, config *transport_tpg.Config) interface{} {
	// Handles the string fixed64 format
	if strVal, ok := v.(string); ok {
		if intVal, err := tpgresource.StringToFixed64(strVal); err == nil {
			return intVal
		}
	}

	// number values are represented as float64
	if floatVal, ok := v.(float64); ok {
		intVal := int(floatVal)
		return intVal
	}

	return v // let terraform core handle it otherwise
}

func flattenDataPipelinePipelineWorkloadDataflowFlexTemplateRequestLaunchParameterEnvironmentZone(v interface{}, d *schema.ResourceData, config *transport_tpg.Config) interface{} {
	return v
}

func flattenDataPipelinePipelineWorkloadDataflowFlexTemplateRequestLaunchParameterEnvironmentServiceAccountEmail(v interface{}, d *schema.ResourceData, config *transport_tpg.Config) interface{} {
	return v
}

func flattenDataPipelinePipelineWorkloadDataflowFlexTemplateRequestLaunchParameterEnvironmentTempLocation(v interface{}, d *schema.ResourceData, config *transport_tpg.Config) interface{} {
	return v
}

func flattenDataPipelinePipelineWorkloadDataflowFlexTemplateRequestLaunchParameterEnvironmentMachineType(v interface{}, d *schema.ResourceData, config *transport_tpg.Config) interface{} {
	return v
}

func flattenDataPipelinePipelineWorkloadDataflowFlexTemplateRequestLaunchParameterEnvironmentAdditionalExperiments(v interface{}, d *schema.ResourceData, config *transport_tpg.Config) interface{} {
	return v
}

func flattenDataPipelinePipelineWorkloadDataflowFlexTemplateRequestLaunchParameterEnvironmentNetwork(v interface{}, d *schema.ResourceData, config *transport_tpg.Config) interface{} {
	return v
}

func flattenDataPipelinePipelineWorkloadDataflowFlexTemplateRequestLaunchParameterEnvironmentSubnetwork(v interface{}, d *schema.ResourceData, config *transport_tpg.Config) interface{} {
	return v
}

func flattenDataPipelinePipelineWorkloadDataflowFlexTemplateRequestLaunchParameterEnvironmentAdditionalUserLabels(v interface{}, d *schema.ResourceData, config *transport_tpg.Config) interface{} {
	return v
}

func flattenDataPipelinePipelineWorkloadDataflowFlexTemplateRequestLaunchParameterEnvironmentKmsKeyName(v interface{}, d *schema.ResourceData, config *transport_tpg.Config) interface{} {
	return v
}

func flattenDataPipelinePipelineWorkloadDataflowFlexTemplateRequestLaunchParameterEnvironmentIpConfiguration(v interface{}, d *schema.ResourceData, config *transport_tpg.Config) interface{} {
	return v
}

func flattenDataPipelinePipelineWorkloadDataflowFlexTemplateRequestLaunchParameterEnvironmentWorkerRegion(v interface{}, d *schema.ResourceData, config *transport_tpg.Config) interface{} {
	return v
}

func flattenDataPipelinePipelineWorkloadDataflowFlexTemplateRequestLaunchParameterEnvironmentWorkerZone(v interface{}, d *schema.ResourceData, config *transport_tpg.Config) interface{} {
	return v
}

func flattenDataPipelinePipelineWorkloadDataflowFlexTemplateRequestLaunchParameterEnvironmentEnableStreamingEngine(v interface{}, d *schema.ResourceData, config *transport_tpg.Config) interface{} {
	return v
}

func flattenDataPipelinePipelineWorkloadDataflowFlexTemplateRequestLaunchParameterEnvironmentFlexrsGoal(v interface{}, d *schema.ResourceData, config *transport_tpg.Config) interface{} {
	return v
}

func flattenDataPipelinePipelineWorkloadDataflowFlexTemplateRequestLaunchParameterUpdate(v interface{}, d *schema.ResourceData, config *transport_tpg.Config) interface{} {
	return v
}

func flattenDataPipelinePipelineWorkloadDataflowFlexTemplateRequestLaunchParameterTransformNameMappings(v interface{}, d *schema.ResourceData, config *transport_tpg.Config) interface{} {
	return v
}

func flattenDataPipelinePipelineWorkloadDataflowFlexTemplateRequestLaunchParameterContainerSpecGcsPath(v interface{}, d *schema.ResourceData, config *transport_tpg.Config) interface{} {
	return v
}

func flattenDataPipelinePipelineWorkloadDataflowFlexTemplateRequestLocation(v interface{}, d *schema.ResourceData, config *transport_tpg.Config) interface{} {
	return v
}

func flattenDataPipelinePipelineWorkloadDataflowFlexTemplateRequestValidateOnly(v interface{}, d *schema.ResourceData, config *transport_tpg.Config) interface{} {
	return v
}

func flattenDataPipelinePipelineScheduleInfo(v interface{}, d *schema.ResourceData, config *transport_tpg.Config) interface{} {
	if v == nil {
		return nil
	}
	original := v.(map[string]interface{})
	if len(original) == 0 {
		return nil
	}
	transformed := make(map[string]interface{})
	transformed["schedule"] =
		flattenDataPipelinePipelineScheduleInfoSchedule(original["schedule"], d, config)
	transformed["time_zone"] =
		flattenDataPipelinePipelineScheduleInfoTimeZone(original["timeZone"], d, config)
	transformed["next_job_time"] =
		flattenDataPipelinePipelineScheduleInfoNextJobTime(original["nextJobTime"], d, config)
	return []interface{}{transformed}
}
func flattenDataPipelinePipelineScheduleInfoSchedule(v interface{}, d *schema.ResourceData, config *transport_tpg.Config) interface{} {
	return v
}

func flattenDataPipelinePipelineScheduleInfoTimeZone(v interface{}, d *schema.ResourceData, config *transport_tpg.Config) interface{} {
	return v
}

func flattenDataPipelinePipelineScheduleInfoNextJobTime(v interface{}, d *schema.ResourceData, config *transport_tpg.Config) interface{} {
	return v
}

func flattenDataPipelinePipelineJobCount(v interface{}, d *schema.ResourceData, config *transport_tpg.Config) interface{} {
	// Handles the string fixed64 format
	if strVal, ok := v.(string); ok {
		if intVal, err := tpgresource.StringToFixed64(strVal); err == nil {
			return intVal
		}
	}

	// number values are represented as float64
	if floatVal, ok := v.(float64); ok {
		intVal := int(floatVal)
		return intVal
	}

	return v // let terraform core handle it otherwise
}

func flattenDataPipelinePipelineSchedulerServiceAccountEmail(v interface{}, d *schema.ResourceData, config *transport_tpg.Config) interface{} {
	return v
}

func flattenDataPipelinePipelinePipelineSources(v interface{}, d *schema.ResourceData, config *transport_tpg.Config) interface{} {
	return v
}

func expandDataPipelinePipelineName(v interface{}, d tpgresource.TerraformResourceData, config *transport_tpg.Config) (interface{}, error) {
	return tpgresource.ReplaceVars(d, config, "projects/{{project}}/locations/{{region}}/pipelines/{{name}}")
}

func expandDataPipelinePipelineDisplayName(v interface{}, d tpgresource.TerraformResourceData, config *transport_tpg.Config) (interface{}, error) {
	return v, nil
}

func expandDataPipelinePipelineType(v interface{}, d tpgresource.TerraformResourceData, config *transport_tpg.Config) (interface{}, error) {
	return v, nil
}

func expandDataPipelinePipelineState(v interface{}, d tpgresource.TerraformResourceData, config *transport_tpg.Config) (interface{}, error) {
	return v, nil
}

func expandDataPipelinePipelineWorkload(v interface{}, d tpgresource.TerraformResourceData, config *transport_tpg.Config) (interface{}, error) {
	l := v.([]interface{})
	if len(l) == 0 || l[0] == nil {
		return nil, nil
	}
	raw := l[0]
	original := raw.(map[string]interface{})
	transformed := make(map[string]interface{})

	transformedDataflowLaunchTemplateRequest, err := expandDataPipelinePipelineWorkloadDataflowLaunchTemplateRequest(original["dataflow_launch_template_request"], d, config)
	if err != nil {
		return nil, err
	} else if val := reflect.ValueOf(transformedDataflowLaunchTemplateRequest); val.IsValid() && !tpgresource.IsEmptyValue(val) {
		transformed["dataflowLaunchTemplateRequest"] = transformedDataflowLaunchTemplateRequest
	}

	transformedDataflowFlexTemplateRequest, err := expandDataPipelinePipelineWorkloadDataflowFlexTemplateRequest(original["dataflow_flex_template_request"], d, config)
	if err != nil {
		return nil, err
	} else if val := reflect.ValueOf(transformedDataflowFlexTemplateRequest); val.IsValid() && !tpgresource.IsEmptyValue(val) {
		transformed["dataflowFlexTemplateRequest"] = transformedDataflowFlexTemplateRequest
	}

	return transformed, nil
}

func expandDataPipelinePipelineWorkloadDataflowLaunchTemplateRequest(v interface{}, d tpgresource.TerraformResourceData, config *transport_tpg.Config) (interface{}, error) {
	l := v.([]interface{})
	if len(l) == 0 || l[0] == nil {
		return nil, nil
	}
	raw := l[0]
	original := raw.(map[string]interface{})
	transformed := make(map[string]interface{})

	transformedProjectId, err := expandDataPipelinePipelineWorkloadDataflowLaunchTemplateRequestProjectId(original["project_id"], d, config)
	if err != nil {
		return nil, err
	} else if val := reflect.ValueOf(transformedProjectId); val.IsValid() && !tpgresource.IsEmptyValue(val) {
		transformed["projectId"] = transformedProjectId
	}

	transformedValidateOnly, err := expandDataPipelinePipelineWorkloadDataflowLaunchTemplateRequestValidateOnly(original["validate_only"], d, config)
	if err != nil {
		return nil, err
	} else if val := reflect.ValueOf(transformedValidateOnly); val.IsValid() && !tpgresource.IsEmptyValue(val) {
		transformed["validateOnly"] = transformedValidateOnly
	}

	transformedLaunchParameters, err := expandDataPipelinePipelineWorkloadDataflowLaunchTemplateRequestLaunchParameters(original["launch_parameters"], d, config)
	if err != nil {
		return nil, err
	} else if val := reflect.ValueOf(transformedLaunchParameters); val.IsValid() && !tpgresource.IsEmptyValue(val) {
		transformed["launchParameters"] = transformedLaunchParameters
	}

	transformedLocation, err := expandDataPipelinePipelineWorkloadDataflowLaunchTemplateRequestLocation(original["location"], d, config)
	if err != nil {
		return nil, err
	} else if val := reflect.ValueOf(transformedLocation); val.IsValid() && !tpgresource.IsEmptyValue(val) {
		transformed["location"] = transformedLocation
	}

	transformedGcsPath, err := expandDataPipelinePipelineWorkloadDataflowLaunchTemplateRequestGcsPath(original["gcs_path"], d, config)
	if err != nil {
		return nil, err
	} else if val := reflect.ValueOf(transformedGcsPath); val.IsValid() && !tpgresource.IsEmptyValue(val) {
		transformed["gcsPath"] = transformedGcsPath
	}

	return transformed, nil
}

func expandDataPipelinePipelineWorkloadDataflowLaunchTemplateRequestProjectId(v interface{}, d tpgresource.TerraformResourceData, config *transport_tpg.Config) (interface{}, error) {
	return v, nil
}

func expandDataPipelinePipelineWorkloadDataflowLaunchTemplateRequestValidateOnly(v interface{}, d tpgresource.TerraformResourceData, config *transport_tpg.Config) (interface{}, error) {
	return v, nil
}

func expandDataPipelinePipelineWorkloadDataflowLaunchTemplateRequestLaunchParameters(v interface{}, d tpgresource.TerraformResourceData, config *transport_tpg.Config) (interface{}, error) {
	l := v.([]interface{})
	if len(l) == 0 || l[0] == nil {
		return nil, nil
	}
	raw := l[0]
	original := raw.(map[string]interface{})
	transformed := make(map[string]interface{})

	transformedJobName, err := expandDataPipelinePipelineWorkloadDataflowLaunchTemplateRequestLaunchParametersJobName(original["job_name"], d, config)
	if err != nil {
		return nil, err
	} else if val := reflect.ValueOf(transformedJobName); val.IsValid() && !tpgresource.IsEmptyValue(val) {
		transformed["jobName"] = transformedJobName
	}

	transformedParameters, err := expandDataPipelinePipelineWorkloadDataflowLaunchTemplateRequestLaunchParametersParameters(original["parameters"], d, config)
	if err != nil {
		return nil, err
	} else if val := reflect.ValueOf(transformedParameters); val.IsValid() && !tpgresource.IsEmptyValue(val) {
		transformed["parameters"] = transformedParameters
	}

	transformedEnvironment, err := expandDataPipelinePipelineWorkloadDataflowLaunchTemplateRequestLaunchParametersEnvironment(original["environment"], d, config)
	if err != nil {
		return nil, err
	} else if val := reflect.ValueOf(transformedEnvironment); val.IsValid() && !tpgresource.IsEmptyValue(val) {
		transformed["environment"] = transformedEnvironment
	}

	transformedUpdate, err := expandDataPipelinePipelineWorkloadDataflowLaunchTemplateRequestLaunchParametersUpdate(original["update"], d, config)
	if err != nil {
		return nil, err
	} else if val := reflect.ValueOf(transformedUpdate); val.IsValid() && !tpgresource.IsEmptyValue(val) {
		transformed["update"] = transformedUpdate
	}

	transformedTransformNameMapping, err := expandDataPipelinePipelineWorkloadDataflowLaunchTemplateRequestLaunchParametersTransformNameMapping(original["transform_name_mapping"], d, config)
	if err != nil {
		return nil, err
	} else if val := reflect.ValueOf(transformedTransformNameMapping); val.IsValid() && !tpgresource.IsEmptyValue(val) {
		transformed["transformNameMapping"] = transformedTransformNameMapping
	}

	return transformed, nil
}

func expandDataPipelinePipelineWorkloadDataflowLaunchTemplateRequestLaunchParametersJobName(v interface{}, d tpgresource.TerraformResourceData, config *transport_tpg.Config) (interface{}, error) {
	return v, nil
}

func expandDataPipelinePipelineWorkloadDataflowLaunchTemplateRequestLaunchParametersEnvironment(v interface{}, d tpgresource.TerraformResourceData, config *transport_tpg.Config) (interface{}, error) {
	l := v.([]interface{})
	if len(l) == 0 || l[0] == nil {
		return nil, nil
	}
	raw := l[0]
	original := raw.(map[string]interface{})
	transformed := make(map[string]interface{})

	transformedNumWorkers, err := expandDataPipelinePipelineWorkloadDataflowLaunchTemplateRequestLaunchParametersEnvironmentNumWorkers(original["num_workers"], d, config)
	if err != nil {
		return nil, err
	} else if val := reflect.ValueOf(transformedNumWorkers); val.IsValid() && !tpgresource.IsEmptyValue(val) {
		transformed["numWorkers"] = transformedNumWorkers
	}

	transformedMaxWorkers, err := expandDataPipelinePipelineWorkloadDataflowLaunchTemplateRequestLaunchParametersEnvironmentMaxWorkers(original["max_workers"], d, config)
	if err != nil {
		return nil, err
	} else if val := reflect.ValueOf(transformedMaxWorkers); val.IsValid() && !tpgresource.IsEmptyValue(val) {
		transformed["maxWorkers"] = transformedMaxWorkers
	}

	transformedZone, err := expandDataPipelinePipelineWorkloadDataflowLaunchTemplateRequestLaunchParametersEnvironmentZone(original["zone"], d, config)
	if err != nil {
		return nil, err
	} else if val := reflect.ValueOf(transformedZone); val.IsValid() && !tpgresource.IsEmptyValue(val) {
		transformed["zone"] = transformedZone
	}

	transformedServiceAccountEmail, err := expandDataPipelinePipelineWorkloadDataflowLaunchTemplateRequestLaunchParametersEnvironmentServiceAccountEmail(original["service_account_email"], d, config)
	if err != nil {
		return nil, err
	} else if val := reflect.ValueOf(transformedServiceAccountEmail); val.IsValid() && !tpgresource.IsEmptyValue(val) {
		transformed["serviceAccountEmail"] = transformedServiceAccountEmail
	}

	transformedTempLocation, err := expandDataPipelinePipelineWorkloadDataflowLaunchTemplateRequestLaunchParametersEnvironmentTempLocation(original["temp_location"], d, config)
	if err != nil {
		return nil, err
	} else if val := reflect.ValueOf(transformedTempLocation); val.IsValid() && !tpgresource.IsEmptyValue(val) {
		transformed["tempLocation"] = transformedTempLocation
	}

	transformedBypassTempDirValidation, err := expandDataPipelinePipelineWorkloadDataflowLaunchTemplateRequestLaunchParametersEnvironmentBypassTempDirValidation(original["bypass_temp_dir_validation"], d, config)
	if err != nil {
		return nil, err
	} else if val := reflect.ValueOf(transformedBypassTempDirValidation); val.IsValid() && !tpgresource.IsEmptyValue(val) {
		transformed["bypassTempDirValidation"] = transformedBypassTempDirValidation
	}

	transformedMachineType, err := expandDataPipelinePipelineWorkloadDataflowLaunchTemplateRequestLaunchParametersEnvironmentMachineType(original["machine_type"], d, config)
	if err != nil {
		return nil, err
	} else if val := reflect.ValueOf(transformedMachineType); val.IsValid() && !tpgresource.IsEmptyValue(val) {
		transformed["machineType"] = transformedMachineType
	}

	transformedAdditionalExperiments, err := expandDataPipelinePipelineWorkloadDataflowLaunchTemplateRequestLaunchParametersEnvironmentAdditionalExperiments(original["additional_experiments"], d, config)
	if err != nil {
		return nil, err
	} else if val := reflect.ValueOf(transformedAdditionalExperiments); val.IsValid() && !tpgresource.IsEmptyValue(val) {
		transformed["additionalExperiments"] = transformedAdditionalExperiments
	}

	transformedNetwork, err := expandDataPipelinePipelineWorkloadDataflowLaunchTemplateRequestLaunchParametersEnvironmentNetwork(original["network"], d, config)
	if err != nil {
		return nil, err
	} else if val := reflect.ValueOf(transformedNetwork); val.IsValid() && !tpgresource.IsEmptyValue(val) {
		transformed["network"] = transformedNetwork
	}

	transformedSubnetwork, err := expandDataPipelinePipelineWorkloadDataflowLaunchTemplateRequestLaunchParametersEnvironmentSubnetwork(original["subnetwork"], d, config)
	if err != nil {
		return nil, err
	} else if val := reflect.ValueOf(transformedSubnetwork); val.IsValid() && !tpgresource.IsEmptyValue(val) {
		transformed["subnetwork"] = transformedSubnetwork
	}

	transformedAdditionalUserLabels, err := expandDataPipelinePipelineWorkloadDataflowLaunchTemplateRequestLaunchParametersEnvironmentAdditionalUserLabels(original["additional_user_labels"], d, config)
	if err != nil {
		return nil, err
	} else if val := reflect.ValueOf(transformedAdditionalUserLabels); val.IsValid() && !tpgresource.IsEmptyValue(val) {
		transformed["additionalUserLabels"] = transformedAdditionalUserLabels
	}

	transformedKmsKeyName, err := expandDataPipelinePipelineWorkloadDataflowLaunchTemplateRequestLaunchParametersEnvironmentKmsKeyName(original["kms_key_name"], d, config)
	if err != nil {
		return nil, err
	} else if val := reflect.ValueOf(transformedKmsKeyName); val.IsValid() && !tpgresource.IsEmptyValue(val) {
		transformed["kmsKeyName"] = transformedKmsKeyName
	}

	transformedIpConfiguration, err := expandDataPipelinePipelineWorkloadDataflowLaunchTemplateRequestLaunchParametersEnvironmentIpConfiguration(original["ip_configuration"], d, config)
	if err != nil {
		return nil, err
	} else if val := reflect.ValueOf(transformedIpConfiguration); val.IsValid() && !tpgresource.IsEmptyValue(val) {
		transformed["ipConfiguration"] = transformedIpConfiguration
	}

	transformedWorkerRegion, err := expandDataPipelinePipelineWorkloadDataflowLaunchTemplateRequestLaunchParametersEnvironmentWorkerRegion(original["worker_region"], d, config)
	if err != nil {
		return nil, err
	} else if val := reflect.ValueOf(transformedWorkerRegion); val.IsValid() && !tpgresource.IsEmptyValue(val) {
		transformed["workerRegion"] = transformedWorkerRegion
	}

	transformedWorkerZone, err := expandDataPipelinePipelineWorkloadDataflowLaunchTemplateRequestLaunchParametersEnvironmentWorkerZone(original["worker_zone"], d, config)
	if err != nil {
		return nil, err
	} else if val := reflect.ValueOf(transformedWorkerZone); val.IsValid() && !tpgresource.IsEmptyValue(val) {
		transformed["workerZone"] = transformedWorkerZone
	}

	transformedEnableStreamingEngine, err := expandDataPipelinePipelineWorkloadDataflowLaunchTemplateRequestLaunchParametersEnvironmentEnableStreamingEngine(original["enable_streaming_engine"], d, config)
	if err != nil {
		return nil, err
	} else if val := reflect.ValueOf(transformedEnableStreamingEngine); val.IsValid() && !tpgresource.IsEmptyValue(val) {
		transformed["enableStreamingEngine"] = transformedEnableStreamingEngine
	}

	return transformed, nil
}

func expandDataPipelinePipelineWorkloadDataflowLaunchTemplateRequestLaunchParametersEnvironmentNumWorkers(v interface{}, d tpgresource.TerraformResourceData, config *transport_tpg.Config) (interface{}, error) {
	return v, nil
}

func expandDataPipelinePipelineWorkloadDataflowLaunchTemplateRequestLaunchParametersEnvironmentMaxWorkers(v interface{}, d tpgresource.TerraformResourceData, config *transport_tpg.Config) (interface{}, error) {
	return v, nil
}

func expandDataPipelinePipelineWorkloadDataflowLaunchTemplateRequestLaunchParametersEnvironmentZone(v interface{}, d tpgresource.TerraformResourceData, config *transport_tpg.Config) (interface{}, error) {
	return v, nil
}

func expandDataPipelinePipelineWorkloadDataflowLaunchTemplateRequestLaunchParametersEnvironmentServiceAccountEmail(v interface{}, d tpgresource.TerraformResourceData, config *transport_tpg.Config) (interface{}, error) {
	return v, nil
}

func expandDataPipelinePipelineWorkloadDataflowLaunchTemplateRequestLaunchParametersEnvironmentTempLocation(v interface{}, d tpgresource.TerraformResourceData, config *transport_tpg.Config) (interface{}, error) {
	return v, nil
}

func expandDataPipelinePipelineWorkloadDataflowLaunchTemplateRequestLaunchParametersEnvironmentBypassTempDirValidation(v interface{}, d tpgresource.TerraformResourceData, config *transport_tpg.Config) (interface{}, error) {
	return v, nil
}

func expandDataPipelinePipelineWorkloadDataflowLaunchTemplateRequestLaunchParametersEnvironmentMachineType(v interface{}, d tpgresource.TerraformResourceData, config *transport_tpg.Config) (interface{}, error) {
	return v, nil
}

func expandDataPipelinePipelineWorkloadDataflowLaunchTemplateRequestLaunchParametersEnvironmentAdditionalExperiments(v interface{}, d tpgresource.TerraformResourceData, config *transport_tpg.Config) (interface{}, error) {
	return v, nil
}

func expandDataPipelinePipelineWorkloadDataflowLaunchTemplateRequestLaunchParametersEnvironmentNetwork(v interface{}, d tpgresource.TerraformResourceData, config *transport_tpg.Config) (interface{}, error) {
	return v, nil
}

func expandDataPipelinePipelineWorkloadDataflowLaunchTemplateRequestLaunchParametersEnvironmentSubnetwork(v interface{}, d tpgresource.TerraformResourceData, config *transport_tpg.Config) (interface{}, error) {
	return v, nil
}

func expandDataPipelinePipelineWorkloadDataflowLaunchTemplateRequestLaunchParametersEnvironmentKmsKeyName(v interface{}, d tpgresource.TerraformResourceData, config *transport_tpg.Config) (interface{}, error) {
	return v, nil
}

func expandDataPipelinePipelineWorkloadDataflowLaunchTemplateRequestLaunchParametersEnvironmentIpConfiguration(v interface{}, d tpgresource.TerraformResourceData, config *transport_tpg.Config) (interface{}, error) {
	return v, nil
}

func expandDataPipelinePipelineWorkloadDataflowLaunchTemplateRequestLaunchParametersEnvironmentWorkerRegion(v interface{}, d tpgresource.TerraformResourceData, config *transport_tpg.Config) (interface{}, error) {
	return v, nil
}

func expandDataPipelinePipelineWorkloadDataflowLaunchTemplateRequestLaunchParametersEnvironmentWorkerZone(v interface{}, d tpgresource.TerraformResourceData, config *transport_tpg.Config) (interface{}, error) {
	return v, nil
}

func expandDataPipelinePipelineWorkloadDataflowLaunchTemplateRequestLaunchParametersEnvironmentEnableStreamingEngine(v interface{}, d tpgresource.TerraformResourceData, config *transport_tpg.Config) (interface{}, error) {
	return v, nil
}

func expandDataPipelinePipelineWorkloadDataflowLaunchTemplateRequestLaunchParametersUpdate(v interface{}, d tpgresource.TerraformResourceData, config *transport_tpg.Config) (interface{}, error) {
	return v, nil
}

func expandDataPipelinePipelineWorkloadDataflowLaunchTemplateRequestLocation(v interface{}, d tpgresource.TerraformResourceData, config *transport_tpg.Config) (interface{}, error) {
	return v, nil
}

func expandDataPipelinePipelineWorkloadDataflowLaunchTemplateRequestGcsPath(v interface{}, d tpgresource.TerraformResourceData, config *transport_tpg.Config) (interface{}, error) {
	return v, nil
}

func expandDataPipelinePipelineWorkloadDataflowFlexTemplateRequest(v interface{}, d tpgresource.TerraformResourceData, config *transport_tpg.Config) (interface{}, error) {
	l := v.([]interface{})
	if len(l) == 0 || l[0] == nil {
		return nil, nil
	}
	raw := l[0]
	original := raw.(map[string]interface{})
	transformed := make(map[string]interface{})

	transformedProjectId, err := expandDataPipelinePipelineWorkloadDataflowFlexTemplateRequestProjectId(original["project_id"], d, config)
	if err != nil {
		return nil, err
	} else if val := reflect.ValueOf(transformedProjectId); val.IsValid() && !tpgresource.IsEmptyValue(val) {
		transformed["projectId"] = transformedProjectId
	}

	transformedLaunchParameter, err := expandDataPipelinePipelineWorkloadDataflowFlexTemplateRequestLaunchParameter(original["launch_parameter"], d, config)
	if err != nil {
		return nil, err
	} else if val := reflect.ValueOf(transformedLaunchParameter); val.IsValid() && !tpgresource.IsEmptyValue(val) {
		transformed["launchParameter"] = transformedLaunchParameter
	}

	transformedLocation, err := expandDataPipelinePipelineWorkloadDataflowFlexTemplateRequestLocation(original["location"], d, config)
	if err != nil {
		return nil, err
	} else if val := reflect.ValueOf(transformedLocation); val.IsValid() && !tpgresource.IsEmptyValue(val) {
		transformed["location"] = transformedLocation
	}

	transformedValidateOnly, err := expandDataPipelinePipelineWorkloadDataflowFlexTemplateRequestValidateOnly(original["validate_only"], d, config)
	if err != nil {
		return nil, err
	} else if val := reflect.ValueOf(transformedValidateOnly); val.IsValid() && !tpgresource.IsEmptyValue(val) {
		transformed["validateOnly"] = transformedValidateOnly
	}

	return transformed, nil
}

func expandDataPipelinePipelineWorkloadDataflowFlexTemplateRequestProjectId(v interface{}, d tpgresource.TerraformResourceData, config *transport_tpg.Config) (interface{}, error) {
	return v, nil
}

func expandDataPipelinePipelineWorkloadDataflowFlexTemplateRequestLaunchParameter(v interface{}, d tpgresource.TerraformResourceData, config *transport_tpg.Config) (interface{}, error) {
	l := v.([]interface{})
	if len(l) == 0 || l[0] == nil {
		return nil, nil
	}
	raw := l[0]
	original := raw.(map[string]interface{})
	transformed := make(map[string]interface{})

	transformedJobName, err := expandDataPipelinePipelineWorkloadDataflowFlexTemplateRequestLaunchParameterJobName(original["job_name"], d, config)
	if err != nil {
		return nil, err
	} else if val := reflect.ValueOf(transformedJobName); val.IsValid() && !tpgresource.IsEmptyValue(val) {
		transformed["jobName"] = transformedJobName
	}

	transformedParameters, err := expandDataPipelinePipelineWorkloadDataflowFlexTemplateRequestLaunchParameterParameters(original["parameters"], d, config)
	if err != nil {
		return nil, err
	} else if val := reflect.ValueOf(transformedParameters); val.IsValid() && !tpgresource.IsEmptyValue(val) {
		transformed["parameters"] = transformedParameters
	}

	transformedLaunchOptions, err := expandDataPipelinePipelineWorkloadDataflowFlexTemplateRequestLaunchParameterLaunchOptions(original["launch_options"], d, config)
	if err != nil {
		return nil, err
	} else if val := reflect.ValueOf(transformedLaunchOptions); val.IsValid() && !tpgresource.IsEmptyValue(val) {
		transformed["launchOptions"] = transformedLaunchOptions
	}

	transformedEnvironment, err := expandDataPipelinePipelineWorkloadDataflowFlexTemplateRequestLaunchParameterEnvironment(original["environment"], d, config)
	if err != nil {
		return nil, err
	} else if val := reflect.ValueOf(transformedEnvironment); val.IsValid() && !tpgresource.IsEmptyValue(val) {
		transformed["environment"] = transformedEnvironment
	}

	transformedUpdate, err := expandDataPipelinePipelineWorkloadDataflowFlexTemplateRequestLaunchParameterUpdate(original["update"], d, config)
	if err != nil {
		return nil, err
	} else if val := reflect.ValueOf(transformedUpdate); val.IsValid() && !tpgresource.IsEmptyValue(val) {
		transformed["update"] = transformedUpdate
	}

	transformedTransformNameMappings, err := expandDataPipelinePipelineWorkloadDataflowFlexTemplateRequestLaunchParameterTransformNameMappings(original["transform_name_mappings"], d, config)
	if err != nil {
		return nil, err
	} else if val := reflect.ValueOf(transformedTransformNameMappings); val.IsValid() && !tpgresource.IsEmptyValue(val) {
		transformed["transformNameMappings"] = transformedTransformNameMappings
	}

	transformedContainerSpecGcsPath, err := expandDataPipelinePipelineWorkloadDataflowFlexTemplateRequestLaunchParameterContainerSpecGcsPath(original["container_spec_gcs_path"], d, config)
	if err != nil {
		return nil, err
	} else if val := reflect.ValueOf(transformedContainerSpecGcsPath); val.IsValid() && !tpgresource.IsEmptyValue(val) {
		transformed["containerSpecGcsPath"] = transformedContainerSpecGcsPath
	}

	return transformed, nil
}

func expandDataPipelinePipelineWorkloadDataflowFlexTemplateRequestLaunchParameterJobName(v interface{}, d tpgresource.TerraformResourceData, config *transport_tpg.Config) (interface{}, error) {
	return v, nil
}

func expandDataPipelinePipelineWorkloadDataflowFlexTemplateRequestLaunchParameterEnvironment(v interface{}, d tpgresource.TerraformResourceData, config *transport_tpg.Config) (interface{}, error) {
	l := v.([]interface{})
	if len(l) == 0 || l[0] == nil {
		return nil, nil
	}
	raw := l[0]
	original := raw.(map[string]interface{})
	transformed := make(map[string]interface{})

	transformedNumWorkers, err := expandDataPipelinePipelineWorkloadDataflowFlexTemplateRequestLaunchParameterEnvironmentNumWorkers(original["num_workers"], d, config)
	if err != nil {
		return nil, err
	} else if val := reflect.ValueOf(transformedNumWorkers); val.IsValid() && !tpgresource.IsEmptyValue(val) {
		transformed["numWorkers"] = transformedNumWorkers
	}

	transformedMaxWorkers, err := expandDataPipelinePipelineWorkloadDataflowFlexTemplateRequestLaunchParameterEnvironmentMaxWorkers(original["max_workers"], d, config)
	if err != nil {
		return nil, err
	} else if val := reflect.ValueOf(transformedMaxWorkers); val.IsValid() && !tpgresource.IsEmptyValue(val) {
		transformed["maxWorkers"] = transformedMaxWorkers
	}

	transformedZone, err := expandDataPipelinePipelineWorkloadDataflowFlexTemplateRequestLaunchParameterEnvironmentZone(original["zone"], d, config)
	if err != nil {
		return nil, err
	} else if val := reflect.ValueOf(transformedZone); val.IsValid() && !tpgresource.IsEmptyValue(val) {
		transformed["zone"] = transformedZone
	}

	transformedServiceAccountEmail, err := expandDataPipelinePipelineWorkloadDataflowFlexTemplateRequestLaunchParameterEnvironmentServiceAccountEmail(original["service_account_email"], d, config)
	if err != nil {
		return nil, err
	} else if val := reflect.ValueOf(transformedServiceAccountEmail); val.IsValid() && !tpgresource.IsEmptyValue(val) {
		transformed["serviceAccountEmail"] = transformedServiceAccountEmail
	}

	transformedTempLocation, err := expandDataPipelinePipelineWorkloadDataflowFlexTemplateRequestLaunchParameterEnvironmentTempLocation(original["temp_location"], d, config)
	if err != nil {
		return nil, err
	} else if val := reflect.ValueOf(transformedTempLocation); val.IsValid() && !tpgresource.IsEmptyValue(val) {
		transformed["tempLocation"] = transformedTempLocation
	}

	transformedMachineType, err := expandDataPipelinePipelineWorkloadDataflowFlexTemplateRequestLaunchParameterEnvironmentMachineType(original["machine_type"], d, config)
	if err != nil {
		return nil, err
	} else if val := reflect.ValueOf(transformedMachineType); val.IsValid() && !tpgresource.IsEmptyValue(val) {
		transformed["machineType"] = transformedMachineType
	}

	transformedAdditionalExperiments, err := expandDataPipelinePipelineWorkloadDataflowFlexTemplateRequestLaunchParameterEnvironmentAdditionalExperiments(original["additional_experiments"], d, config)
	if err != nil {
		return nil, err
	} else if val := reflect.ValueOf(transformedAdditionalExperiments); val.IsValid() && !tpgresource.IsEmptyValue(val) {
		transformed["additionalExperiments"] = transformedAdditionalExperiments
	}

	transformedNetwork, err := expandDataPipelinePipelineWorkloadDataflowFlexTemplateRequestLaunchParameterEnvironmentNetwork(original["network"], d, config)
	if err != nil {
		return nil, err
	} else if val := reflect.ValueOf(transformedNetwork); val.IsValid() && !tpgresource.IsEmptyValue(val) {
		transformed["network"] = transformedNetwork
	}

	transformedSubnetwork, err := expandDataPipelinePipelineWorkloadDataflowFlexTemplateRequestLaunchParameterEnvironmentSubnetwork(original["subnetwork"], d, config)
	if err != nil {
		return nil, err
	} else if val := reflect.ValueOf(transformedSubnetwork); val.IsValid() && !tpgresource.IsEmptyValue(val) {
		transformed["subnetwork"] = transformedSubnetwork
	}

	transformedAdditionalUserLabels, err := expandDataPipelinePipelineWorkloadDataflowFlexTemplateRequestLaunchParameterEnvironmentAdditionalUserLabels(original["additional_user_labels"], d, config)
	if err != nil {
		return nil, err
	} else if val := reflect.ValueOf(transformedAdditionalUserLabels); val.IsValid() && !tpgresource.IsEmptyValue(val) {
		transformed["additionalUserLabels"] = transformedAdditionalUserLabels
	}

	transformedKmsKeyName, err := expandDataPipelinePipelineWorkloadDataflowFlexTemplateRequestLaunchParameterEnvironmentKmsKeyName(original["kms_key_name"], d, config)
	if err != nil {
		return nil, err
	} else if val := reflect.ValueOf(transformedKmsKeyName); val.IsValid() && !tpgresource.IsEmptyValue(val) {
		transformed["kmsKeyName"] = transformedKmsKeyName
	}

	transformedIpConfiguration, err := expandDataPipelinePipelineWorkloadDataflowFlexTemplateRequestLaunchParameterEnvironmentIpConfiguration(original["ip_configuration"], d, config)
	if err != nil {
		return nil, err
	} else if val := reflect.ValueOf(transformedIpConfiguration); val.IsValid() && !tpgresource.IsEmptyValue(val) {
		transformed["ipConfiguration"] = transformedIpConfiguration
	}

	transformedWorkerRegion, err := expandDataPipelinePipelineWorkloadDataflowFlexTemplateRequestLaunchParameterEnvironmentWorkerRegion(original["worker_region"], d, config)
	if err != nil {
		return nil, err
	} else if val := reflect.ValueOf(transformedWorkerRegion); val.IsValid() && !tpgresource.IsEmptyValue(val) {
		transformed["workerRegion"] = transformedWorkerRegion
	}

	transformedWorkerZone, err := expandDataPipelinePipelineWorkloadDataflowFlexTemplateRequestLaunchParameterEnvironmentWorkerZone(original["worker_zone"], d, config)
	if err != nil {
		return nil, err
	} else if val := reflect.ValueOf(transformedWorkerZone); val.IsValid() && !tpgresource.IsEmptyValue(val) {
		transformed["workerZone"] = transformedWorkerZone
	}

	transformedEnableStreamingEngine, err := expandDataPipelinePipelineWorkloadDataflowFlexTemplateRequestLaunchParameterEnvironmentEnableStreamingEngine(original["enable_streaming_engine"], d, config)
	if err != nil {
		return nil, err
	} else if val := reflect.ValueOf(transformedEnableStreamingEngine); val.IsValid() && !tpgresource.IsEmptyValue(val) {
		transformed["enableStreamingEngine"] = transformedEnableStreamingEngine
	}

	transformedFlexrsGoal, err := expandDataPipelinePipelineWorkloadDataflowFlexTemplateRequestLaunchParameterEnvironmentFlexrsGoal(original["flexrs_goal"], d, config)
	if err != nil {
		return nil, err
	} else if val := reflect.ValueOf(transformedFlexrsGoal); val.IsValid() && !tpgresource.IsEmptyValue(val) {
		transformed["flexrsGoal"] = transformedFlexrsGoal
	}

	return transformed, nil
}

func expandDataPipelinePipelineWorkloadDataflowFlexTemplateRequestLaunchParameterEnvironmentNumWorkers(v interface{}, d tpgresource.TerraformResourceData, config *transport_tpg.Config) (interface{}, error) {
	return v, nil
}

func expandDataPipelinePipelineWorkloadDataflowFlexTemplateRequestLaunchParameterEnvironmentMaxWorkers(v interface{}, d tpgresource.TerraformResourceData, config *transport_tpg.Config) (interface{}, error) {
	return v, nil
}

func expandDataPipelinePipelineWorkloadDataflowFlexTemplateRequestLaunchParameterEnvironmentZone(v interface{}, d tpgresource.TerraformResourceData, config *transport_tpg.Config) (interface{}, error) {
	return v, nil
}

func expandDataPipelinePipelineWorkloadDataflowFlexTemplateRequestLaunchParameterEnvironmentServiceAccountEmail(v interface{}, d tpgresource.TerraformResourceData, config *transport_tpg.Config) (interface{}, error) {
	return v, nil
}

func expandDataPipelinePipelineWorkloadDataflowFlexTemplateRequestLaunchParameterEnvironmentTempLocation(v interface{}, d tpgresource.TerraformResourceData, config *transport_tpg.Config) (interface{}, error) {
	return v, nil
}

func expandDataPipelinePipelineWorkloadDataflowFlexTemplateRequestLaunchParameterEnvironmentMachineType(v interface{}, d tpgresource.TerraformResourceData, config *transport_tpg.Config) (interface{}, error) {
	return v, nil
}

func expandDataPipelinePipelineWorkloadDataflowFlexTemplateRequestLaunchParameterEnvironmentAdditionalExperiments(v interface{}, d tpgresource.TerraformResourceData, config *transport_tpg.Config) (interface{}, error) {
	return v, nil
}

func expandDataPipelinePipelineWorkloadDataflowFlexTemplateRequestLaunchParameterEnvironmentNetwork(v interface{}, d tpgresource.TerraformResourceData, config *transport_tpg.Config) (interface{}, error) {
	return v, nil
}

func expandDataPipelinePipelineWorkloadDataflowFlexTemplateRequestLaunchParameterEnvironmentSubnetwork(v interface{}, d tpgresource.TerraformResourceData, config *transport_tpg.Config) (interface{}, error) {
	return v, nil
}

func expandDataPipelinePipelineWorkloadDataflowFlexTemplateRequestLaunchParameterEnvironmentKmsKeyName(v interface{}, d tpgresource.TerraformResourceData, config *transport_tpg.Config) (interface{}, error) {
	return v, nil
}

func expandDataPipelinePipelineWorkloadDataflowFlexTemplateRequestLaunchParameterEnvironmentIpConfiguration(v interface{}, d tpgresource.TerraformResourceData, config *transport_tpg.Config) (interface{}, error) {
	return v, nil
}

func expandDataPipelinePipelineWorkloadDataflowFlexTemplateRequestLaunchParameterEnvironmentWorkerRegion(v interface{}, d tpgresource.TerraformResourceData, config *transport_tpg.Config) (interface{}, error) {
	return v, nil
}

func expandDataPipelinePipelineWorkloadDataflowFlexTemplateRequestLaunchParameterEnvironmentWorkerZone(v interface{}, d tpgresource.TerraformResourceData, config *transport_tpg.Config) (interface{}, error) {
	return v, nil
}

func expandDataPipelinePipelineWorkloadDataflowFlexTemplateRequestLaunchParameterEnvironmentEnableStreamingEngine(v interface{}, d tpgresource.TerraformResourceData, config *transport_tpg.Config) (interface{}, error) {
	return v, nil
}

func expandDataPipelinePipelineWorkloadDataflowFlexTemplateRequestLaunchParameterEnvironmentFlexrsGoal(v interface{}, d tpgresource.TerraformResourceData, config *transport_tpg.Config) (interface{}, error) {
	return v, nil
}

func expandDataPipelinePipelineWorkloadDataflowFlexTemplateRequestLaunchParameterUpdate(v interface{}, d tpgresource.TerraformResourceData, config *transport_tpg.Config) (interface{}, error) {
	return v, nil
}

func expandDataPipelinePipelineWorkloadDataflowFlexTemplateRequestLaunchParameterContainerSpecGcsPath(v interface{}, d tpgresource.TerraformResourceData, config *transport_tpg.Config) (interface{}, error) {
	return v, nil
}

func expandDataPipelinePipelineWorkloadDataflowFlexTemplateRequestLocation(v interface{}, d tpgresource.TerraformResourceData, config *transport_tpg.Config) (interface{}, error) {
	return v, nil
}

func expandDataPipelinePipelineWorkloadDataflowFlexTemplateRequestValidateOnly(v interface{}, d tpgresource.TerraformResourceData, config *transport_tpg.Config) (interface{}, error) {
	return v, nil
}

func expandDataPipelinePipelineScheduleInfo(v interface{}, d tpgresource.TerraformResourceData, config *transport_tpg.Config) (interface{}, error) {
	l := v.([]interface{})
	if len(l) == 0 || l[0] == nil {
		return nil, nil
	}
	raw := l[0]
	original := raw.(map[string]interface{})
	transformed := make(map[string]interface{})

	transformedSchedule, err := expandDataPipelinePipelineScheduleInfoSchedule(original["schedule"], d, config)
	if err != nil {
		return nil, err
	} else if val := reflect.ValueOf(transformedSchedule); val.IsValid() && !tpgresource.IsEmptyValue(val) {
		transformed["schedule"] = transformedSchedule
	}

	transformedTimeZone, err := expandDataPipelinePipelineScheduleInfoTimeZone(original["time_zone"], d, config)
	if err != nil {
		return nil, err
	} else if val := reflect.ValueOf(transformedTimeZone); val.IsValid() && !tpgresource.IsEmptyValue(val) {
		transformed["timeZone"] = transformedTimeZone
	}

	transformedNextJobTime, err := expandDataPipelinePipelineScheduleInfoNextJobTime(original["next_job_time"], d, config)
	if err != nil {
		return nil, err
	} else if val := reflect.ValueOf(transformedNextJobTime); val.IsValid() && !tpgresource.IsEmptyValue(val) {
		transformed["nextJobTime"] = transformedNextJobTime
	}

	return transformed, nil
}

func expandDataPipelinePipelineScheduleInfoSchedule(v interface{}, d tpgresource.TerraformResourceData, config *transport_tpg.Config) (interface{}, error) {
	return v, nil
}

func expandDataPipelinePipelineScheduleInfoTimeZone(v interface{}, d tpgresource.TerraformResourceData, config *transport_tpg.Config) (interface{}, error) {
	return v, nil
}

func expandDataPipelinePipelineScheduleInfoNextJobTime(v interface{}, d tpgresource.TerraformResourceData, config *transport_tpg.Config) (interface{}, error) {
	return v, nil
}

func expandDataPipelinePipelineSchedulerServiceAccountEmail(v interface{}, d tpgresource.TerraformResourceData, config *transport_tpg.Config) (interface{}, error) {
	return v, nil
}

func expandDataPipelinePipelinePipelineSources(v interface{}, d tpgresource.TerraformResourceData, config *transport_tpg.Config) (map[string]string, error) {
	if v == nil {
		return map[string]string{}, nil
	}
	m := make(map[string]string)
	for k, val := range v.(map[string]interface{}) {
		m[k] = val.(string)
	}
	return m, nil
}
