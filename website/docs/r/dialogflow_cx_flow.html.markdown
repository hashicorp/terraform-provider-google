---
# ----------------------------------------------------------------------------
#
#     ***     AUTO GENERATED CODE    ***    Type: MMv1     ***
#
# ----------------------------------------------------------------------------
#
#     This code is generated by Magic Modules using the following:
#
#     Configuration: https:#github.com/GoogleCloudPlatform/magic-modules/tree/main/mmv1/products/dialogflowcx/Flow.yaml
#     Template:      https:#github.com/GoogleCloudPlatform/magic-modules/tree/main/mmv1/templates/terraform/resource.html.markdown.tmpl
#
#     DO NOT EDIT this file directly. Any changes made to this file will be
#     overwritten during the next generation cycle.
#
# ----------------------------------------------------------------------------
subcategory: "Dialogflow CX"
description: |-
  Flows represents the conversation flows when you build your chatbot agent.
---

# google_dialogflow_cx_flow

Flows represents the conversation flows when you build your chatbot agent.


To get more information about Flow, see:

* [API documentation](https://cloud.google.com/dialogflow/cx/docs/reference/rest/v3/projects.locations.agents.flows)
* How-to Guides
    * [Official Documentation](https://cloud.google.com/dialogflow/cx/docs)

<div class = "oics-button" style="float: right; margin: 0 0 -15px">
  <a href="https://console.cloud.google.com/cloudshell/open?cloudshell_git_repo=https%3A%2F%2Fgithub.com%2Fterraform-google-modules%2Fdocs-examples.git&cloudshell_image=gcr.io%2Fcloudshell-images%2Fcloudshell%3Alatest&cloudshell_print=.%2Fmotd&cloudshell_tutorial=.%2Ftutorial.md&cloudshell_working_dir=dialogflowcx_flow_basic&open_in_editor=main.tf" target="_blank">
    <img alt="Open in Cloud Shell" src="//gstatic.com/cloudssh/images/open-btn.svg" style="max-height: 44px; margin: 32px auto; max-width: 100%;">
  </a>
</div>
## Example Usage - Dialogflowcx Flow Basic


```hcl
resource "google_dialogflow_cx_agent" "agent" {
  display_name               = "dialogflowcx-agent"
  location                   = "global"
  default_language_code      = "en"
  supported_language_codes   = ["fr", "de", "es"]
  time_zone                  = "America/New_York"
  description                = "Example description."
  avatar_uri                 = "https://cloud.google.com/_static/images/cloud/icons/favicons/onecloud/super_cloud.png"
  enable_stackdriver_logging = true
  enable_spell_correction    = true
  speech_to_text_settings {
    enable_speech_adaptation = true
  }
}


resource "google_dialogflow_cx_flow" "basic_flow" {
  parent       = google_dialogflow_cx_agent.agent.id
  display_name = "MyFlow"
  description  = "Test Flow"

  nlu_settings {
    classification_threshold = 0.3
    model_type               = "MODEL_TYPE_STANDARD"
  }

  event_handlers {
    event = "custom-event"
    trigger_fulfillment {
      return_partial_responses = false
      messages {
        text {
          text = ["I didn't get that. Can you say it again?"]
        }
      }
    }
  }

  event_handlers {
    event = "sys.no-match-default"
    trigger_fulfillment {
      return_partial_responses = false
      messages {
        text {
          text = ["Sorry, could you say that again?"]
        }
      }
    }
  }

  event_handlers {
    event = "sys.no-input-default"
    trigger_fulfillment {
      return_partial_responses = false
      messages {
        text {
          text = ["One more time?"]
        }
      }
    }
  }
}
```
<div class = "oics-button" style="float: right; margin: 0 0 -15px">
  <a href="https://console.cloud.google.com/cloudshell/open?cloudshell_git_repo=https%3A%2F%2Fgithub.com%2Fterraform-google-modules%2Fdocs-examples.git&cloudshell_image=gcr.io%2Fcloudshell-images%2Fcloudshell%3Alatest&cloudshell_print=.%2Fmotd&cloudshell_tutorial=.%2Ftutorial.md&cloudshell_working_dir=dialogflowcx_flow_full&open_in_editor=main.tf" target="_blank">
    <img alt="Open in Cloud Shell" src="//gstatic.com/cloudssh/images/open-btn.svg" style="max-height: 44px; margin: 32px auto; max-width: 100%;">
  </a>
</div>
## Example Usage - Dialogflowcx Flow Full


```hcl
resource "google_dialogflow_cx_agent" "agent" {
  display_name               = "dialogflowcx-agent"
  location                   = "global"
  default_language_code      = "en"
  supported_language_codes   = ["fr", "de", "es"]
  time_zone                  = "America/New_York"
  description                = "Example description."
  avatar_uri                 = "https://cloud.google.com/_static/images/cloud/icons/favicons/onecloud/super_cloud.png"
  enable_stackdriver_logging = true
  enable_spell_correction    = true
  speech_to_text_settings {
    enable_speech_adaptation = true
  }
}

resource "google_storage_bucket" "bucket" {
  name                        = "dialogflowcx-bucket"
  location                    = "US"
  uniform_bucket_level_access = true
}


resource "google_dialogflow_cx_flow" "basic_flow" {
  parent       = google_dialogflow_cx_agent.agent.id
  display_name = "MyFlow"
  description  = "Test Flow"

  nlu_settings {
    classification_threshold = 0.3
    model_type               = "MODEL_TYPE_STANDARD"
  }

  event_handlers {
    event = "custom-event"
    trigger_fulfillment {
      return_partial_responses = false
      messages {
        text {
          text = ["I didn't get that. Can you say it again?"]
        }
      }
    }
  }

  event_handlers {
    event = "sys.no-match-default"
    trigger_fulfillment {
      return_partial_responses = false
      messages {
        text {
          text = ["Sorry, could you say that again?"]
        }
      }
    }
  }

  event_handlers {
    event = "sys.no-input-default"
    trigger_fulfillment {
      return_partial_responses = false
      messages {
        text {
          text = ["One more time?"]
        }
      }
    }
  }

  event_handlers {
    event = "another-event"
    trigger_fulfillment {
      return_partial_responses = true
      messages {
        channel = "some-channel"
        text {
          text = ["Some text"]
        }
      }
      messages {
        payload = <<EOF
          {"some-key": "some-value", "other-key": ["other-value"]}
        EOF
      }
      messages {
        conversation_success {
          metadata = <<EOF
            {"some-metadata-key": "some-value", "other-metadata-key": 1234}
          EOF
        }
      }
      messages {
        output_audio_text {
          text = "some output text"
        }
      }
      messages {
        output_audio_text {
          ssml = <<EOF
            <speak>Some example <say-as interpret-as="characters">SSML XML</say-as></speak>
          EOF
        }
      }
      messages {
        live_agent_handoff {
          metadata = <<EOF
            {"some-metadata-key": "some-value", "other-metadata-key": 1234}
          EOF
        }
      }
      messages {
        play_audio {
          audio_uri = "http://example.com/some-audio-file.mp3"
        }
      }
      messages {
        telephony_transfer_call {
          phone_number = "1-234-567-8901"
        }
      }

      set_parameter_actions {
        parameter = "some-param"
        value     = "123.45"
      }
      set_parameter_actions {
        parameter = "another-param"
        value     = jsonencode("abc")
      }
      set_parameter_actions {
        parameter = "other-param"
        value     = jsonencode(["foo"])
      }

      conditional_cases {
        cases = jsonencode([
          {
            condition = "$sys.func.RAND() < 0.5",
            caseContent = [
              {
                message = { text = { text = ["First case"] } }
              },
              {
                additionalCases = {
                  cases = [
                    {
                      condition = "$sys.func.RAND() < 0.2"
                      caseContent = [
                        {
                          message = { text = { text = ["Nested case"] } }
                        }
                      ]
                    }
                  ]
                }
              }
            ]
          },
          {
            caseContent = [
              {
                message = { text = { text = ["Final case"] } }
              }
            ]
          },
        ])
      }

      enable_generative_fallback = true
    }
  }

  transition_routes {
    condition = "true"
    trigger_fulfillment {
      return_partial_responses = true
      messages {
        channel = "some-channel"
        text {
          text = ["Some text"]
        }
      }
      messages {
        payload = <<EOF
          {"some-key": "some-value", "other-key": ["other-value"]}
        EOF
      }
      messages {
        conversation_success {
          metadata = <<EOF
            {"some-metadata-key": "some-value", "other-metadata-key": 1234}
          EOF
        }
      }
      messages {
        output_audio_text {
          text = "some output text"
        }
      }
      messages {
        output_audio_text {
          ssml = <<EOF
            <speak>Some example <say-as interpret-as="characters">SSML XML</say-as></speak>
          EOF
        }
      }
      messages {
        live_agent_handoff {
          metadata = <<EOF
            {"some-metadata-key": "some-value", "other-metadata-key": 1234}
          EOF
        }
      }
      messages {
        play_audio {
          audio_uri = "http://example.com/some-audio-file.mp3"
        }
      }
      messages {
        telephony_transfer_call {
          phone_number = "1-234-567-8901"
        }
      }

      set_parameter_actions {
        parameter = "some-param"
        value     = "123.45"
      }
      set_parameter_actions {
        parameter = "another-param"
        value     = jsonencode("abc")
      }
      set_parameter_actions {
        parameter = "other-param"
        value     = jsonencode(["foo"])
      }

      conditional_cases {
        cases = jsonencode([
          {
            condition = "$sys.func.RAND() < 0.5",
            caseContent = [
              {
                message = { text = { text = ["First case"] } }
              },
              {
                additionalCases = {
                  cases = [
                    {
                      condition = "$sys.func.RAND() < 0.2"
                      caseContent = [
                        {
                          message = { text = { text = ["Nested case"] } }
                        }
                      ]
                    }
                  ]
                }
              }
            ]
          },
          {
            caseContent = [
              {
                message = { text = { text = ["Final case"] } }
              }
            ]
          },
        ])
      }
    }
    target_flow = google_dialogflow_cx_agent.agent.start_flow
  }

  advanced_settings {
    audio_export_gcs_destination {
      uri = "${google_storage_bucket.bucket.url}/prefix-"
    }
    speech_settings {
      endpointer_sensitivity        = 30
      no_speech_timeout             = "3.500s"
      use_timeout_based_endpointing = true
      models = {
        name : "wrench"
        mass : "1.3kg"
        count : "3"
      }
    }
    dtmf_settings {
      enabled      = true
      max_digits   = 1
      finish_digit = "#"
    }
    logging_settings {
      enable_stackdriver_logging     = true
      enable_interaction_logging     = true
      enable_consent_based_redaction = true
    }
  }

  knowledge_connector_settings {
    enabled = true
    trigger_fulfillment {
      messages {
        channel = "some-channel"
        text {
          text = ["information completed, navigating to page 2"]
        }
      }
      messages {
        payload = <<EOF
          {"some-key": "some-value", "other-key": ["other-value"]}
        EOF
      }
      messages {
        conversation_success {
          metadata = <<EOF
            {"some-metadata-key": "some-value", "other-metadata-key": 1234}
          EOF
        }
      }
      messages {
        output_audio_text {
          text = "some output text"
        }
      }
      messages {
        output_audio_text {
          ssml = <<EOF
            <speak>Some example <say-as interpret-as="characters">SSML XML</say-as></speak>
          EOF
        }
      }
      messages {
        live_agent_handoff {
          metadata = <<EOF
            {"some-metadata-key": "some-value", "other-metadata-key": 1234}
          EOF
        }
      }
      messages {
        play_audio {
          audio_uri = "http://example.com/some-audio-file.mp3"
        }
      }
      messages {
        telephony_transfer_call {
          phone_number = "1-234-567-8902"
        }
      }
      webhook = google_dialogflow_cx_webhook.my_webhook.id
      return_partial_responses = true
      tag = "some-tag"
      set_parameter_actions {
        parameter = "some-param"
        value     = "123.45"
      }
      conditional_cases {
        cases = jsonencode([
          {
            condition = "$sys.func.RAND() < 0.5",
            caseContent = [
              {
                message = { text = { text = ["First case"] } }
              }
            ]
          },
          {
            caseContent = [
              {
                message = { text = { text = ["Final case"] } }
              }
            ]
          },
        ])
      }
      advanced_settings {
        speech_settings {
          endpointer_sensitivity        = 30
          no_speech_timeout             = "3.500s"
          use_timeout_based_endpointing = true
          models = {
            name : "wrench"
            mass : "1.3kg"
            count : "3"
          }
        }
        dtmf_settings {
          enabled      = true
          max_digits   = 1
          finish_digit = "#"
          interdigit_timeout_duration = "3.500s"
          endpointing_timeout_duration = "3.500s"
        }
        logging_settings {
          enable_stackdriver_logging     = true
          enable_interaction_logging     = true
          enable_consent_based_redaction = true
        }
      }
      enable_generative_fallback = true
    }
    data_store_connections {
      data_store_type = "UNSTRUCTURED"
      data_store = "projects/${data.google_project.project.number}/locations/${google_dialogflow_cx_agent.agent.location}/collections/default_collection/dataStores/${google_discovery_engine_data_store.my_datastore.data_store_id}"
      document_processing_mode = "DOCUMENTS"
    }
    target_flow = google_dialogflow_cx_agent.agent.start_flow
  }
}

resource "google_discovery_engine_data_store" "my_datastore" {
  location          = "global"
  data_store_id     = "datastore-flow-full"
  display_name      = "datastore-flow-full"
  industry_vertical = "GENERIC"
  content_config    = "NO_CONTENT"
  solution_types    = ["SOLUTION_TYPE_CHAT"]
}

resource "google_dialogflow_cx_webhook" "my_webhook" {
  parent       = google_dialogflow_cx_agent.agent.id
  display_name = "MyWebhook"
  generic_web_service {
    uri = "https://example.com"
  }
}

data "google_project" "project" {
}
```

## Argument Reference

The following arguments are supported:


* `display_name` -
  (Required)
  The human-readable name of the flow.


* `description` -
  (Optional)
  The description of the flow. The maximum length is 500 characters. If exceeded, the request is rejected.

* `transition_routes` -
  (Optional)
  A flow's transition routes serve two purposes:
  They are responsible for matching the user's first utterances in the flow.
  They are inherited by every page's [transition routes][Page.transition_routes] and can support use cases such as the user saying "help" or "can I talk to a human?", which can be handled in a common way regardless of the current page. Transition routes defined in the page have higher priority than those defined in the flow.
  TransitionRoutes are evalauted in the following order:
    TransitionRoutes with intent specified.
    TransitionRoutes with only condition specified.
    TransitionRoutes with intent specified are inherited by pages in the flow.
  Structure is [documented below](#nested_transition_routes).

* `event_handlers` -
  (Optional)
  A flow's event handlers serve two purposes:
  They are responsible for handling events (e.g. no match, webhook errors) in the flow.
  They are inherited by every page's [event handlers][Page.event_handlers], which can be used to handle common events regardless of the current page. Event handlers defined in the page have higher priority than those defined in the flow.
  Unlike transitionRoutes, these handlers are evaluated on a first-match basis. The first one that matches the event get executed, with the rest being ignored.
  Structure is [documented below](#nested_event_handlers).

* `transition_route_groups` -
  (Optional)
  A flow's transition route group serve two purposes:
  They are responsible for matching the user's first utterances in the flow.
  They are inherited by every page's [transition route groups][Page.transition_route_groups]. Transition route groups defined in the page have higher priority than those defined in the flow.
  Format:projects/<Project ID>/locations/<Location ID>/agents/<Agent ID>/flows/<Flow ID>/transitionRouteGroups/<TransitionRouteGroup ID>.

* `nlu_settings` -
  (Optional)
  NLU related settings of the flow.
  Structure is [documented below](#nested_nlu_settings).

* `advanced_settings` -
  (Optional)
  Hierarchical advanced settings for this flow. The settings exposed at the lower level overrides the settings exposed at the higher level.
  Hierarchy: Agent->Flow->Page->Fulfillment/Parameter.
  Structure is [documented below](#nested_advanced_settings).

* `knowledge_connector_settings` -
  (Optional)
  Knowledge connector configuration.
  Structure is [documented below](#nested_knowledge_connector_settings).

* `parent` -
  (Optional)
  The agent to create a flow for.
  Format: projects/<Project ID>/locations/<Location ID>/agents/<Agent ID>.

* `language_code` -
  (Optional)
  The language of the following fields in flow:
  Flow.event_handlers.trigger_fulfillment.messages
  Flow.event_handlers.trigger_fulfillment.conditional_cases
  Flow.transition_routes.trigger_fulfillment.messages
  Flow.transition_routes.trigger_fulfillment.conditional_cases
  If not specified, the agent's default language is used. Many languages are supported. Note: languages must be enabled in the agent before they can be used.

* `is_default_start_flow` - (Optional) Marks this as the [Default Start Flow](https://cloud.google.com/dialogflow/cx/docs/concept/flow#start) for an agent. When you create an agent, the Default Start Flow is created automatically.
The Default Start Flow cannot be deleted; deleting the `google_dialogflow_cx_flow` resource does nothing to the underlying GCP resources.

~> Avoid having multiple `google_dialogflow_cx_flow` resources linked to the same agent with `is_default_start_flow = true` because they will compete to control a single Default Start Flow resource in GCP.



<a name="nested_transition_routes"></a>The `transition_routes` block supports:

* `name` -
  (Output)
  The unique identifier of this transition route.

* `intent` -
  (Optional)
  The unique identifier of an Intent.
  Format: projects/<Project ID>/locations/<Location ID>/agents/<Agent ID>/intents/<Intent ID>. Indicates that the transition can only happen when the given intent is matched. At least one of intent or condition must be specified. When both intent and condition are specified, the transition can only happen when both are fulfilled.

* `condition` -
  (Optional)
  The condition to evaluate against form parameters or session parameters.
  At least one of intent or condition must be specified. When both intent and condition are specified, the transition can only happen when both are fulfilled.

* `trigger_fulfillment` -
  (Optional)
  The fulfillment to call when the condition is satisfied. At least one of triggerFulfillment and target must be specified. When both are defined, triggerFulfillment is executed first.
  Structure is [documented below](#nested_transition_routes_transition_routes_trigger_fulfillment).

* `target_page` -
  (Optional)
  The target page to transition to.
  Format: projects/<Project ID>/locations/<Location ID>/agents/<Agent ID>/flows/<Flow ID>/pages/<Page ID>.

* `target_flow` -
  (Optional)
  The target flow to transition to.
  Format: projects/<Project ID>/locations/<Location ID>/agents/<Agent ID>/flows/<Flow ID>.


<a name="nested_transition_routes_transition_routes_trigger_fulfillment"></a>The `trigger_fulfillment` block supports:

* `messages` -
  (Optional)
  The list of rich message responses to present to the user.
  Structure is [documented below](#nested_transition_routes_transition_routes_trigger_fulfillment_messages).

* `webhook` -
  (Optional)
  The webhook to call. Format: projects/<Project ID>/locations/<Location ID>/agents/<Agent ID>/webhooks/<Webhook ID>.

* `return_partial_responses` -
  (Optional)
  Whether Dialogflow should return currently queued fulfillment response messages in streaming APIs. If a webhook is specified, it happens before Dialogflow invokes webhook. Warning: 1) This flag only affects streaming API. Responses are still queued and returned once in non-streaming API. 2) The flag can be enabled in any fulfillment but only the first 3 partial responses will be returned. You may only want to apply it to fulfillments that have slow webhooks.

* `tag` -
  (Optional)
  The tag used by the webhook to identify which fulfillment is being called. This field is required if webhook is specified.

* `set_parameter_actions` -
  (Optional)
  Set parameter values before executing the webhook.
  Structure is [documented below](#nested_transition_routes_transition_routes_trigger_fulfillment_set_parameter_actions).

* `conditional_cases` -
  (Optional)
  Conditional cases for this fulfillment.
  Structure is [documented below](#nested_transition_routes_transition_routes_trigger_fulfillment_conditional_cases).


<a name="nested_transition_routes_transition_routes_trigger_fulfillment_messages"></a>The `messages` block supports:

* `channel` -
  (Optional)
  The channel which the response is associated with. Clients can specify the channel via QueryParameters.channel, and only associated channel response will be returned.

* `text` -
  (Optional)
  The text response message.
  Structure is [documented below](#nested_transition_routes_transition_routes_trigger_fulfillment_messages_messages_text).

* `payload` -
  (Optional)
  A custom, platform-specific payload.

* `conversation_success` -
  (Optional)
  Indicates that the conversation succeeded, i.e., the bot handled the issue that the customer talked to it about.
  Dialogflow only uses this to determine which conversations should be counted as successful and doesn't process the metadata in this message in any way. Note that Dialogflow also considers conversations that get to the conversation end page as successful even if they don't return ConversationSuccess.
  You may set this, for example:
  * In the entryFulfillment of a Page if entering the page indicates that the conversation succeeded.
  * In a webhook response when you determine that you handled the customer issue.
  Structure is [documented below](#nested_transition_routes_transition_routes_trigger_fulfillment_messages_messages_conversation_success).

* `output_audio_text` -
  (Optional)
  A text or ssml response that is preferentially used for TTS output audio synthesis, as described in the comment on the ResponseMessage message.
  Structure is [documented below](#nested_transition_routes_transition_routes_trigger_fulfillment_messages_messages_output_audio_text).

* `live_agent_handoff` -
  (Optional)
  Indicates that the conversation should be handed off to a live agent.
  Dialogflow only uses this to determine which conversations were handed off to a human agent for measurement purposes. What else to do with this signal is up to you and your handoff procedures.
  You may set this, for example:
  * In the entryFulfillment of a Page if entering the page indicates something went extremely wrong in the conversation.
  * In a webhook response when you determine that the customer issue can only be handled by a human.
  Structure is [documented below](#nested_transition_routes_transition_routes_trigger_fulfillment_messages_messages_live_agent_handoff).

* `play_audio` -
  (Optional)
  Specifies an audio clip to be played by the client as part of the response.
  Structure is [documented below](#nested_transition_routes_transition_routes_trigger_fulfillment_messages_messages_play_audio).

* `telephony_transfer_call` -
  (Optional)
  Represents the signal that telles the client to transfer the phone call connected to the agent to a third-party endpoint.
  Structure is [documented below](#nested_transition_routes_transition_routes_trigger_fulfillment_messages_messages_telephony_transfer_call).


<a name="nested_transition_routes_transition_routes_trigger_fulfillment_messages_messages_text"></a>The `text` block supports:

* `text` -
  (Optional)
  A collection of text responses.

* `allow_playback_interruption` -
  (Output)
  Whether the playback of this message can be interrupted by the end user's speech and the client can then starts the next Dialogflow request.

<a name="nested_transition_routes_transition_routes_trigger_fulfillment_messages_messages_conversation_success"></a>The `conversation_success` block supports:

* `metadata` -
  (Optional)
  Custom metadata. Dialogflow doesn't impose any structure on this.

<a name="nested_transition_routes_transition_routes_trigger_fulfillment_messages_messages_output_audio_text"></a>The `output_audio_text` block supports:

* `allow_playback_interruption` -
  (Output)
  Whether the playback of this message can be interrupted by the end user's speech and the client can then starts the next Dialogflow request.

* `text` -
  (Optional)
  The raw text to be synthesized.

* `ssml` -
  (Optional)
  The SSML text to be synthesized. For more information, see SSML.

<a name="nested_transition_routes_transition_routes_trigger_fulfillment_messages_messages_live_agent_handoff"></a>The `live_agent_handoff` block supports:

* `metadata` -
  (Optional)
  Custom metadata. Dialogflow doesn't impose any structure on this.

<a name="nested_transition_routes_transition_routes_trigger_fulfillment_messages_messages_play_audio"></a>The `play_audio` block supports:

* `audio_uri` -
  (Required)
  URI of the audio clip. Dialogflow does not impose any validation on this value. It is specific to the client that reads it.

* `allow_playback_interruption` -
  (Output)
  Whether the playback of this message can be interrupted by the end user's speech and the client can then starts the next Dialogflow request.

<a name="nested_transition_routes_transition_routes_trigger_fulfillment_messages_messages_telephony_transfer_call"></a>The `telephony_transfer_call` block supports:

* `phone_number` -
  (Required)
  Transfer the call to a phone number in E.164 format.

<a name="nested_transition_routes_transition_routes_trigger_fulfillment_set_parameter_actions"></a>The `set_parameter_actions` block supports:

* `parameter` -
  (Optional)
  Display name of the parameter.

* `value` -
  (Optional)
  The new JSON-encoded value of the parameter. A null value clears the parameter.

<a name="nested_transition_routes_transition_routes_trigger_fulfillment_conditional_cases"></a>The `conditional_cases` block supports:

* `cases` -
  (Optional)
  A JSON encoded list of cascading if-else conditions. Cases are mutually exclusive. The first one with a matching condition is selected, all the rest ignored.
  See [Case](https://cloud.google.com/dialogflow/cx/docs/reference/rest/v3/Fulfillment#case) for the schema.

<a name="nested_event_handlers"></a>The `event_handlers` block supports:

* `name` -
  (Output)
  The unique identifier of this event handler.

* `event` -
  (Optional)
  The name of the event to handle.

* `trigger_fulfillment` -
  (Optional)
  The fulfillment to call when the event occurs. Handling webhook errors with a fulfillment enabled with webhook could cause infinite loop. It is invalid to specify such fulfillment for a handler handling webhooks.
  Structure is [documented below](#nested_event_handlers_event_handlers_trigger_fulfillment).

* `target_page` -
  (Optional)
  The target page to transition to.
  Format: projects/<Project ID>/locations/<Location ID>/agents/<Agent ID>/flows/<Flow ID>/pages/<Page ID>.

* `target_flow` -
  (Optional)
  The target flow to transition to.
  Format: projects/<Project ID>/locations/<Location ID>/agents/<Agent ID>/flows/<Flow ID>.


<a name="nested_event_handlers_event_handlers_trigger_fulfillment"></a>The `trigger_fulfillment` block supports:

* `messages` -
  (Optional)
  The list of rich message responses to present to the user.
  Structure is [documented below](#nested_event_handlers_event_handlers_trigger_fulfillment_messages).

* `webhook` -
  (Optional)
  The webhook to call. Format: projects/<Project ID>/locations/<Location ID>/agents/<Agent ID>/webhooks/<Webhook ID>.

* `return_partial_responses` -
  (Optional)
  Whether Dialogflow should return currently queued fulfillment response messages in streaming APIs. If a webhook is specified, it happens before Dialogflow invokes webhook. Warning: 1) This flag only affects streaming API. Responses are still queued and returned once in non-streaming API. 2) The flag can be enabled in any fulfillment but only the first 3 partial responses will be returned. You may only want to apply it to fulfillments that have slow webhooks.

* `tag` -
  (Optional)
  The tag used by the webhook to identify which fulfillment is being called. This field is required if webhook is specified.

* `set_parameter_actions` -
  (Optional)
  Set parameter values before executing the webhook.
  Structure is [documented below](#nested_event_handlers_event_handlers_trigger_fulfillment_set_parameter_actions).

* `conditional_cases` -
  (Optional)
  Conditional cases for this fulfillment.
  Structure is [documented below](#nested_event_handlers_event_handlers_trigger_fulfillment_conditional_cases).

* `enable_generative_fallback` -
  (Optional)
  If the flag is true, the agent will utilize LLM to generate a text response.
  If LLM generation fails, the defined responses in the fulfillment will be respected.
  This flag is only useful for fulfillments associated with no-match event handlers.


<a name="nested_event_handlers_event_handlers_trigger_fulfillment_messages"></a>The `messages` block supports:

* `channel` -
  (Optional)
  The channel which the response is associated with. Clients can specify the channel via QueryParameters.channel, and only associated channel response will be returned.

* `text` -
  (Optional)
  The text response message.
  Structure is [documented below](#nested_event_handlers_event_handlers_trigger_fulfillment_messages_messages_text).

* `payload` -
  (Optional)
  A custom, platform-specific payload.

* `conversation_success` -
  (Optional)
  Indicates that the conversation succeeded, i.e., the bot handled the issue that the customer talked to it about.
  Dialogflow only uses this to determine which conversations should be counted as successful and doesn't process the metadata in this message in any way. Note that Dialogflow also considers conversations that get to the conversation end page as successful even if they don't return ConversationSuccess.
  You may set this, for example:
  * In the entryFulfillment of a Page if entering the page indicates that the conversation succeeded.
  * In a webhook response when you determine that you handled the customer issue.
  Structure is [documented below](#nested_event_handlers_event_handlers_trigger_fulfillment_messages_messages_conversation_success).

* `output_audio_text` -
  (Optional)
  A text or ssml response that is preferentially used for TTS output audio synthesis, as described in the comment on the ResponseMessage message.
  Structure is [documented below](#nested_event_handlers_event_handlers_trigger_fulfillment_messages_messages_output_audio_text).

* `live_agent_handoff` -
  (Optional)
  Indicates that the conversation should be handed off to a live agent.
  Dialogflow only uses this to determine which conversations were handed off to a human agent for measurement purposes. What else to do with this signal is up to you and your handoff procedures.
  You may set this, for example:
  * In the entryFulfillment of a Page if entering the page indicates something went extremely wrong in the conversation.
  * In a webhook response when you determine that the customer issue can only be handled by a human.
  Structure is [documented below](#nested_event_handlers_event_handlers_trigger_fulfillment_messages_messages_live_agent_handoff).

* `play_audio` -
  (Optional)
  Specifies an audio clip to be played by the client as part of the response.
  Structure is [documented below](#nested_event_handlers_event_handlers_trigger_fulfillment_messages_messages_play_audio).

* `telephony_transfer_call` -
  (Optional)
  Represents the signal that telles the client to transfer the phone call connected to the agent to a third-party endpoint.
  Structure is [documented below](#nested_event_handlers_event_handlers_trigger_fulfillment_messages_messages_telephony_transfer_call).


<a name="nested_event_handlers_event_handlers_trigger_fulfillment_messages_messages_text"></a>The `text` block supports:

* `text` -
  (Optional)
  A collection of text responses.

* `allow_playback_interruption` -
  (Output)
  Whether the playback of this message can be interrupted by the end user's speech and the client can then starts the next Dialogflow request.

<a name="nested_event_handlers_event_handlers_trigger_fulfillment_messages_messages_conversation_success"></a>The `conversation_success` block supports:

* `metadata` -
  (Optional)
  Custom metadata. Dialogflow doesn't impose any structure on this.

<a name="nested_event_handlers_event_handlers_trigger_fulfillment_messages_messages_output_audio_text"></a>The `output_audio_text` block supports:

* `allow_playback_interruption` -
  (Output)
  Whether the playback of this message can be interrupted by the end user's speech and the client can then starts the next Dialogflow request.

* `text` -
  (Optional)
  The raw text to be synthesized.

* `ssml` -
  (Optional)
  The SSML text to be synthesized. For more information, see SSML.

<a name="nested_event_handlers_event_handlers_trigger_fulfillment_messages_messages_live_agent_handoff"></a>The `live_agent_handoff` block supports:

* `metadata` -
  (Optional)
  Custom metadata. Dialogflow doesn't impose any structure on this.

<a name="nested_event_handlers_event_handlers_trigger_fulfillment_messages_messages_play_audio"></a>The `play_audio` block supports:

* `audio_uri` -
  (Required)
  URI of the audio clip. Dialogflow does not impose any validation on this value. It is specific to the client that reads it.

* `allow_playback_interruption` -
  (Output)
  Whether the playback of this message can be interrupted by the end user's speech and the client can then starts the next Dialogflow request.

<a name="nested_event_handlers_event_handlers_trigger_fulfillment_messages_messages_telephony_transfer_call"></a>The `telephony_transfer_call` block supports:

* `phone_number` -
  (Required)
  Transfer the call to a phone number in E.164 format.

<a name="nested_event_handlers_event_handlers_trigger_fulfillment_set_parameter_actions"></a>The `set_parameter_actions` block supports:

* `parameter` -
  (Optional)
  Display name of the parameter.

* `value` -
  (Optional)
  The new JSON-encoded value of the parameter. A null value clears the parameter.

<a name="nested_event_handlers_event_handlers_trigger_fulfillment_conditional_cases"></a>The `conditional_cases` block supports:

* `cases` -
  (Optional)
  A JSON encoded list of cascading if-else conditions. Cases are mutually exclusive. The first one with a matching condition is selected, all the rest ignored.
  See [Case](https://cloud.google.com/dialogflow/cx/docs/reference/rest/v3/Fulfillment#case) for the schema.

<a name="nested_nlu_settings"></a>The `nlu_settings` block supports:

* `model_type` -
  (Optional)
  Indicates the type of NLU model.
  * MODEL_TYPE_STANDARD: Use standard NLU model.
  * MODEL_TYPE_ADVANCED: Use advanced NLU model.
  Possible values are: `MODEL_TYPE_STANDARD`, `MODEL_TYPE_ADVANCED`.

* `classification_threshold` -
  (Optional)
  To filter out false positive results and still get variety in matched natural language inputs for your agent, you can tune the machine learning classification threshold.
  If the returned score value is less than the threshold value, then a no-match event will be triggered. The score values range from 0.0 (completely uncertain) to 1.0 (completely certain). If set to 0.0, the default of 0.3 is used.

* `model_training_mode` -
  (Optional)
  Indicates NLU model training mode.
  * MODEL_TRAINING_MODE_AUTOMATIC: NLU model training is automatically triggered when a flow gets modified. User can also manually trigger model training in this mode.
  * MODEL_TRAINING_MODE_MANUAL: User needs to manually trigger NLU model training. Best for large flows whose models take long time to train.
  Possible values are: `MODEL_TRAINING_MODE_AUTOMATIC`, `MODEL_TRAINING_MODE_MANUAL`.

<a name="nested_advanced_settings"></a>The `advanced_settings` block supports:

* `audio_export_gcs_destination` -
  (Optional)
  If present, incoming audio is exported by Dialogflow to the configured Google Cloud Storage destination. Exposed at the following levels:
  * Agent level
  * Flow level
  Structure is [documented below](#nested_advanced_settings_audio_export_gcs_destination).

* `speech_settings` -
  (Optional)
  Settings for speech to text detection. Exposed at the following levels:
  * Agent level
  * Flow level
  * Page level
  * Parameter level
  Structure is [documented below](#nested_advanced_settings_speech_settings).

* `dtmf_settings` -
  (Optional)
  Define behaviors for DTMF (dual tone multi frequency). DTMF settings does not override each other. DTMF settings set at different levels define DTMF detections running in parallel. Exposed at the following levels:
  * Agent level
  * Flow level
  * Page level
  * Parameter level
  Structure is [documented below](#nested_advanced_settings_dtmf_settings).

* `logging_settings` -
  (Optional)
  Settings for logging. Settings for Dialogflow History, Contact Center messages, StackDriver logs, and speech logging. Exposed at the following levels:
  * Agent level
  Structure is [documented below](#nested_advanced_settings_logging_settings).


<a name="nested_advanced_settings_audio_export_gcs_destination"></a>The `audio_export_gcs_destination` block supports:

* `uri` -
  (Optional)
  The Google Cloud Storage URI for the exported objects. Whether a full object name, or just a prefix, its usage depends on the Dialogflow operation.
  Format: gs://bucket/object-name-or-prefix

<a name="nested_advanced_settings_speech_settings"></a>The `speech_settings` block supports:

* `endpointer_sensitivity` -
  (Optional)
  Sensitivity of the speech model that detects the end of speech. Scale from 0 to 100.

* `no_speech_timeout` -
  (Optional)
  Timeout before detecting no speech.
  A duration in seconds with up to nine fractional digits, ending with 's'. Example: "3.5s".

* `use_timeout_based_endpointing` -
  (Optional)
  Use timeout based endpointing, interpreting endpointer sensitivity as seconds of timeout value.

* `models` -
  (Optional)
  Mapping from language to Speech-to-Text model. The mapped Speech-to-Text model will be selected for requests from its corresponding language. For more information, see [Speech models](https://cloud.google.com/dialogflow/cx/docs/concept/speech-models).
  An object containing a list of **"key": value** pairs. Example: **{ "name": "wrench", "mass": "1.3kg", "count": "3" }**.

<a name="nested_advanced_settings_dtmf_settings"></a>The `dtmf_settings` block supports:

* `enabled` -
  (Optional)
  If true, incoming audio is processed for DTMF (dual tone multi frequency) events. For example, if the caller presses a button on their telephone keypad and DTMF processing is enabled, Dialogflow will detect the event (e.g. a "3" was pressed) in the incoming audio and pass the event to the bot to drive business logic (e.g. when 3 is pressed, return the account balance).

* `max_digits` -
  (Optional)
  Max length of DTMF digits.

* `finish_digit` -
  (Optional)
  The digit that terminates a DTMF digit sequence.

<a name="nested_advanced_settings_logging_settings"></a>The `logging_settings` block supports:

* `enable_stackdriver_logging` -
  (Optional)
  Enables Google Cloud Logging.

* `enable_interaction_logging` -
  (Optional)
  Enables DF Interaction logging.

* `enable_consent_based_redaction` -
  (Optional)
  Enables consent-based end-user input redaction, if true, a pre-defined session parameter **$session.params.conversation-redaction** will be used to determine if the utterance should be redacted.

<a name="nested_knowledge_connector_settings"></a>The `knowledge_connector_settings` block supports:

* `enabled` -
  (Optional)
  Whether Knowledge Connector is enabled or not.

* `trigger_fulfillment` -
  (Optional)
  The fulfillment to be triggered.
  When the answers from the Knowledge Connector are selected by Dialogflow, you can utitlize the request scoped parameter $request.knowledge.answers (contains up to the 5 highest confidence answers) and $request.knowledge.questions (contains the corresponding questions) to construct the fulfillment.
  Structure is [documented below](#nested_knowledge_connector_settings_trigger_fulfillment).

* `data_store_connections` -
  (Optional)
  Optional. List of related data store connections.
  Structure is [documented below](#nested_knowledge_connector_settings_data_store_connections).

* `target_page` -
  (Optional)
  The target page to transition to. Format: projects/<ProjectID>/locations/<LocationID>/agents/<AgentID>/flows/<FlowID>/pages/<PageID>.
  The page must be in the same host flow (the flow that owns this `KnowledgeConnectorSettings`).
  This field is part of a union field `target`: Only one of `targetPage` or `targetFlow` may be set.

* `target_flow` -
  (Optional)
  The target flow to transition to. Format: projects/<ProjectID>/locations/<LocationID>/agents/<AgentID>/flows/<FlowID>.
  This field is part of a union field `target`: Only one of `targetPage` or `targetFlow` may be set.


<a name="nested_knowledge_connector_settings_trigger_fulfillment"></a>The `trigger_fulfillment` block supports:

* `messages` -
  (Optional)
  The list of rich message responses to present to the user.
  Structure is [documented below](#nested_knowledge_connector_settings_trigger_fulfillment_messages).

* `webhook` -
  (Optional)
  The webhook to call. Format: projects/<Project ID>/locations/<Location ID>/agents/<Agent ID>/webhooks/<Webhook ID>.

* `return_partial_responses` -
  (Optional)
  Whether Dialogflow should return currently queued fulfillment response messages in streaming APIs. If a webhook is specified, it happens before Dialogflow invokes webhook. Warning: 1) This flag only affects streaming API. Responses are still queued and returned once in non-streaming API. 2) The flag can be enabled in any fulfillment but only the first 3 partial responses will be returned. You may only want to apply it to fulfillments that have slow webhooks.

* `tag` -
  (Optional)
  The tag used by the webhook to identify which fulfillment is being called. This field is required if webhook is specified.

* `set_parameter_actions` -
  (Optional)
  Set parameter values before executing the webhook.
  Structure is [documented below](#nested_knowledge_connector_settings_trigger_fulfillment_set_parameter_actions).

* `conditional_cases` -
  (Optional)
  Conditional cases for this fulfillment.
  Structure is [documented below](#nested_knowledge_connector_settings_trigger_fulfillment_conditional_cases).

* `advanced_settings` -
  (Optional)
  Hierarchical advanced settings for agent/flow/page/fulfillment/parameter. Settings exposed at lower level overrides the settings exposed at higher level. Overriding occurs at the sub-setting level. For example, the playbackInterruptionSettings at fulfillment level only overrides the playbackInterruptionSettings at the agent level, leaving other settings at the agent level unchanged.
  DTMF settings does not override each other. DTMF settings set at different levels define DTMF detections running in parallel.
  Hierarchy: Agent->Flow->Page->Fulfillment/Parameter.
  Structure is [documented below](#nested_knowledge_connector_settings_trigger_fulfillment_advanced_settings).

* `enable_generative_fallback` -
  (Optional)
  If the flag is true, the agent will utilize LLM to generate a text response. If LLM generation fails, the defined responses in the fulfillment will be respected. This flag is only useful for fulfillments associated with no-match event handlers.


<a name="nested_knowledge_connector_settings_trigger_fulfillment_messages"></a>The `messages` block supports:

* `channel` -
  (Optional)
  The channel which the response is associated with. Clients can specify the channel via QueryParameters.channel, and only associated channel response will be returned.

* `text` -
  (Optional)
  The text response message.
  This field is part of a union field `message`: Only one of `text`, `payload`, `conversationSuccess`, `outputAudioText`, `liveAgentHandoff`, `endInteraction`, `playAudio`, `mixedAudio`, `telephonyTransferCall`, or `knowledgeInfoCard` may be set.
  Structure is [documented below](#nested_knowledge_connector_settings_trigger_fulfillment_messages_messages_text).

* `payload` -
  (Optional)
  Returns a response containing a custom, platform-specific payload.
  This field is part of a union field `message`: Only one of `text`, `payload`, `conversationSuccess`, `outputAudioText`, `liveAgentHandoff`, `endInteraction`, `playAudio`, `mixedAudio`, `telephonyTransferCall`, or `knowledgeInfoCard` may be set.

* `conversation_success` -
  (Optional)
  Indicates that the conversation succeeded, i.e., the bot handled the issue that the customer talked to it about.
  Dialogflow only uses this to determine which conversations should be counted as successful and doesn't process the metadata in this message in any way. Note that Dialogflow also considers conversations that get to the conversation end page as successful even if they don't return ConversationSuccess.
  You may set this, for example:
  * In the entryFulfillment of a Page if entering the page indicates that the conversation succeeded.
  * In a webhook response when you determine that you handled the customer issue.
  This field is part of a union field `message`: Only one of `text`, `payload`, `conversationSuccess`, `outputAudioText`, `liveAgentHandoff`, `endInteraction`, `playAudio`, `mixedAudio`, `telephonyTransferCall`, or `knowledgeInfoCard` may be set.
  Structure is [documented below](#nested_knowledge_connector_settings_trigger_fulfillment_messages_messages_conversation_success).

* `output_audio_text` -
  (Optional)
  A text or ssml response that is preferentially used for TTS output audio synthesis, as described in the comment on the ResponseMessage message.
  This field is part of a union field `message`: Only one of `text`, `payload`, `conversationSuccess`, `outputAudioText`, `liveAgentHandoff`, `endInteraction`, `playAudio`, `mixedAudio`, `telephonyTransferCall`, or `knowledgeInfoCard` may be set.
  Structure is [documented below](#nested_knowledge_connector_settings_trigger_fulfillment_messages_messages_output_audio_text).

* `live_agent_handoff` -
  (Optional)
  Indicates that the conversation should be handed off to a live agent.
  Dialogflow only uses this to determine which conversations were handed off to a human agent for measurement purposes. What else to do with this signal is up to you and your handoff procedures.
  You may set this, for example:
  * In the entryFulfillment of a Page if entering the page indicates something went extremely wrong in the conversation.
  * In a webhook response when you determine that the customer issue can only be handled by a human.
  This field is part of a union field `message`: Only one of `text`, `payload`, `conversationSuccess`, `outputAudioText`, `liveAgentHandoff`, `endInteraction`, `playAudio`, `mixedAudio`, `telephonyTransferCall`, or `knowledgeInfoCard` may be set.
  Structure is [documented below](#nested_knowledge_connector_settings_trigger_fulfillment_messages_messages_live_agent_handoff).

* `end_interaction` -
  (Output)
  This type has no fields.
  Indicates that interaction with the Dialogflow agent has ended. This message is generated by Dialogflow only and not supposed to be defined by the user.
  This field is part of a union field `message`: Only one of `text`, `payload`, `conversationSuccess`, `outputAudioText`, `liveAgentHandoff`, `endInteraction`, `playAudio`, `mixedAudio`, `telephonyTransferCall`, or `knowledgeInfoCard` may be set.

* `play_audio` -
  (Optional)
  Specifies an audio clip to be played by the client as part of the response.
  This field is part of a union field `message`: Only one of `text`, `payload`, `conversationSuccess`, `outputAudioText`, `liveAgentHandoff`, `endInteraction`, `playAudio`, `mixedAudio`, `telephonyTransferCall`, or `knowledgeInfoCard` may be set.
  Structure is [documented below](#nested_knowledge_connector_settings_trigger_fulfillment_messages_messages_play_audio).

* `mixed_audio` -
  (Output)
  Represents an audio message that is composed of both segments synthesized from the Dialogflow agent prompts and ones hosted externally at the specified URIs. The external URIs are specified via playAudio. This message is generated by Dialogflow only and not supposed to be defined by the user.
  This field is part of a union field `message`: Only one of `text`, `payload`, `conversationSuccess`, `outputAudioText`, `liveAgentHandoff`, `endInteraction`, `playAudio`, `mixedAudio`, `telephonyTransferCall`, or `knowledgeInfoCard` may be set.
  Structure is [documented below](#nested_knowledge_connector_settings_trigger_fulfillment_messages_messages_mixed_audio).

* `telephony_transfer_call` -
  (Optional)
  Represents the signal that telles the client to transfer the phone call connected to the agent to a third-party endpoint.
  This field is part of a union field `message`: Only one of `text`, `payload`, `conversationSuccess`, `outputAudioText`, `liveAgentHandoff`, `endInteraction`, `playAudio`, `mixedAudio`, `telephonyTransferCall`, or `knowledgeInfoCard` may be set.
  Structure is [documented below](#nested_knowledge_connector_settings_trigger_fulfillment_messages_messages_telephony_transfer_call).

* `knowledge_info_card` -
  (Optional)
  This type has no fields.
  Represents info card response. If the response contains generative knowledge prediction, Dialogflow will return a payload with Infobot Messenger compatible info card.
  Otherwise, the info card response is skipped.
  This field is part of a union field `message`: Only one of `text`, `payload`, `conversationSuccess`, `outputAudioText`, `liveAgentHandoff`, `endInteraction`, `playAudio`, `mixedAudio`, `telephonyTransferCall`, or `knowledgeInfoCard` may be set.


<a name="nested_knowledge_connector_settings_trigger_fulfillment_messages_messages_text"></a>The `text` block supports:

* `text` -
  (Optional)
  A collection of text response variants. If multiple variants are defined, only one text response variant is returned at runtime.
  required: true

* `allow_playback_interruption` -
  (Output)
  Whether the playback of this message can be interrupted by the end user's speech and the client can then starts the next Dialogflow request.

<a name="nested_knowledge_connector_settings_trigger_fulfillment_messages_messages_conversation_success"></a>The `conversation_success` block supports:

* `metadata` -
  (Optional)
  Custom metadata. Dialogflow doesn't impose any structure on this.

<a name="nested_knowledge_connector_settings_trigger_fulfillment_messages_messages_output_audio_text"></a>The `output_audio_text` block supports:

* `allow_playback_interruption` -
  (Output)
  Whether the playback of this message can be interrupted by the end user's speech and the client can then starts the next Dialogflow request.

* `text` -
  (Optional)
  The raw text to be synthesized.
  This field is part of a union field `source`: Only one of `text` or `ssml` may be set.

* `ssml` -
  (Optional)
  The SSML text to be synthesized. For more information, see SSML.
  This field is part of a union field `source`: Only one of `text` or `ssml` may be set.

<a name="nested_knowledge_connector_settings_trigger_fulfillment_messages_messages_live_agent_handoff"></a>The `live_agent_handoff` block supports:

* `metadata` -
  (Optional)
  Custom metadata. Dialogflow doesn't impose any structure on this.

<a name="nested_knowledge_connector_settings_trigger_fulfillment_messages_messages_play_audio"></a>The `play_audio` block supports:

* `audio_uri` -
  (Required)
  URI of the audio clip. Dialogflow does not impose any validation on this value. It is specific to the client that reads it.

* `allow_playback_interruption` -
  (Output)
  Whether the playback of this message can be interrupted by the end user's speech and the client can then starts the next Dialogflow request.

<a name="nested_knowledge_connector_settings_trigger_fulfillment_messages_messages_mixed_audio"></a>The `mixed_audio` block contains:

* `segments` -
  (Optional)
  Segments this audio response is composed of.
  Structure is [documented below](#nested_knowledge_connector_settings_trigger_fulfillment_messages_messages_mixed_audio_segments).


<a name="nested_knowledge_connector_settings_trigger_fulfillment_messages_messages_mixed_audio_segments"></a>The `segments` block supports:

* `allow_playback_interruption` -
  (Output)
  Whether the playback of this segment can be interrupted by the end user's speech and the client should then start the next Dialogflow request.

* `audio` -
  (Optional)
  Raw audio synthesized from the Dialogflow agent's response using the output config specified in the request.
  A base64-encoded string.
  This field is part of a union field `content`: Only one of `audio` or `uri` may be set.

* `uri` -
  (Optional)
  Client-specific URI that points to an audio clip accessible to the client. Dialogflow does not impose any validation on it.
  This field is part of a union field `content`: Only one of `audio` or `uri` may be set.

<a name="nested_knowledge_connector_settings_trigger_fulfillment_messages_messages_telephony_transfer_call"></a>The `telephony_transfer_call` block supports:

* `phone_number` -
  (Required)
  Transfer the call to a phone number in E.164 format.

<a name="nested_knowledge_connector_settings_trigger_fulfillment_set_parameter_actions"></a>The `set_parameter_actions` block supports:

* `parameter` -
  (Optional)
  Display name of the parameter.

* `value` -
  (Optional)
  The new JSON-encoded value of the parameter. A null value clears the parameter.

<a name="nested_knowledge_connector_settings_trigger_fulfillment_conditional_cases"></a>The `conditional_cases` block supports:

* `cases` -
  (Optional)
  A JSON encoded list of cascading if-else conditions. Cases are mutually exclusive. The first one with a matching condition is selected, all the rest ignored.
  See [Case](https://cloud.google.com/dialogflow/cx/docs/reference/rest/v3/Fulfillment#case) for the schema.

<a name="nested_knowledge_connector_settings_trigger_fulfillment_advanced_settings"></a>The `advanced_settings` block supports:

* `speech_settings` -
  (Optional)
  Settings for speech to text detection. Exposed at the following levels:
  * Agent level
  * Flow level
  * Page level
  * Parameter level
  Structure is [documented below](#nested_knowledge_connector_settings_trigger_fulfillment_advanced_settings_speech_settings).

* `dtmf_settings` -
  (Optional)
  Define behaviors for DTMF (dual tone multi frequency). DTMF settings does not override each other. DTMF settings set at different levels define DTMF detections running in parallel. Exposed at the following levels:
  * Agent level
  * Flow level
  * Page level
  * Parameter level
  Structure is [documented below](#nested_knowledge_connector_settings_trigger_fulfillment_advanced_settings_dtmf_settings).

* `logging_settings` -
  (Optional)
  Settings for logging. Settings for Dialogflow History, Contact Center messages, StackDriver logs, and speech logging. Exposed at the following levels:
  * Agent level
  Structure is [documented below](#nested_knowledge_connector_settings_trigger_fulfillment_advanced_settings_logging_settings).


<a name="nested_knowledge_connector_settings_trigger_fulfillment_advanced_settings_speech_settings"></a>The `speech_settings` block supports:

* `endpointer_sensitivity` -
  (Optional)
  Sensitivity of the speech model that detects the end of speech. Scale from 0 to 100.

* `no_speech_timeout` -
  (Optional)
  Timeout before detecting no speech.
  A duration in seconds with up to nine fractional digits, ending with 's'. Example: "3.500s".

* `use_timeout_based_endpointing` -
  (Optional)
  Use timeout based endpointing, interpreting endpointer sensitivity as seconds of timeout value.

* `models` -
  (Optional)
  Mapping from language to Speech-to-Text model. The mapped Speech-to-Text model will be selected for requests from its corresponding language. For more information, see [Speech models](https://cloud.google.com/dialogflow/cx/docs/concept/speech-models).
  An object containing a list of **"key": value** pairs. Example: **{ "name": "wrench", "mass": "1.3kg", "count": "3" }**.

<a name="nested_knowledge_connector_settings_trigger_fulfillment_advanced_settings_dtmf_settings"></a>The `dtmf_settings` block supports:

* `enabled` -
  (Optional)
  If true, incoming audio is processed for DTMF (dual tone multi frequtectency) events. For example, if the caller presses a button on their telephone keypad and DTMF processing is enabled, Dialogflow will de the event (e.g. a "3" was pressed) in the incoming audio and pass the event to the bot to drive business logic (e.g. when 3 is pressed, return the account balance).

* `max_digits` -
  (Optional)
  Max length of DTMF digits.

* `finish_digit` -
  (Optional)
  The digit that terminates a DTMF digit sequence.

* `interdigit_timeout_duration` -
  (Optional)
  Interdigit timeout setting for matching dtmf input to regex.
  A duration in seconds with up to nine fractional digits, ending with 's'. Example: "3.500s".

* `endpointing_timeout_duration` -
  (Optional)
  Endpoint timeout setting for matching dtmf input to regex.
  A duration in seconds with up to nine fractional digits, ending with 's'. Example: "3.500s".

<a name="nested_knowledge_connector_settings_trigger_fulfillment_advanced_settings_logging_settings"></a>The `logging_settings` block supports:

* `enable_stackdriver_logging` -
  (Optional)
  Enables Google Cloud Logging.

* `enable_interaction_logging` -
  (Optional)
  Enables DF Interaction logging.

* `enable_consent_based_redaction` -
  (Optional)
  Enables consent-based end-user input redaction, if true, a pre-defined session parameter **$session.params.conversation-redaction** will be used to determine if the utterance should be redacted.

<a name="nested_knowledge_connector_settings_data_store_connections"></a>The `data_store_connections` block supports:

* `data_store_type` -
  (Optional)
  The type of the connected data store.
  * PUBLIC_WEB: A data store that contains public web content.
  * UNSTRUCTURED: A data store that contains unstructured private data.
  * STRUCTURED: A data store that contains structured data (for example FAQ).
  Possible values are: `PUBLIC_WEB`, `UNSTRUCTURED`, `STRUCTURED`.

* `data_store` -
  (Optional)
  The full name of the referenced data store. Formats: projects/{project}/locations/{location}/collections/{collection}/dataStores/{dataStore} projects/{project}/locations/{location}/dataStores/{dataStore}

* `document_processing_mode` -
  (Optional)
  The document processing mode for the data store connection. Should only be set for PUBLIC_WEB and UNSTRUCTURED data stores. If not set it is considered as DOCUMENTS, as this is the legacy mode.
  * DOCUMENTS: Documents are processed as documents.
  * CHUNKS: Documents are converted to chunks.
  Possible values are: `DOCUMENTS`, `CHUNKS`.

## Attributes Reference

In addition to the arguments listed above, the following computed attributes are exported:

* `id` - an identifier for the resource with format `{{parent}}/flows/{{name}}`

* `name` -
  The unique identifier of the flow.
  Format: projects/<Project ID>/locations/<Location ID>/agents/<Agent ID>/flows/<Flow ID>.


## Timeouts

This resource provides the following
[Timeouts](https://developer.hashicorp.com/terraform/plugin/sdkv2/resources/retries-and-customizable-timeouts) configuration options:

- `create` - Default is 40 minutes.
- `update` - Default is 40 minutes.
- `delete` - Default is 20 minutes.

## Import


Flow can be imported using any of these accepted formats:

* `{{parent}}/flows/{{name}}`
* `{{parent}}/{{name}}`


In Terraform v1.5.0 and later, use an [`import` block](https://developer.hashicorp.com/terraform/language/import) to import Flow using one of the formats above. For example:

```tf
import {
  id = "{{parent}}/flows/{{name}}"
  to = google_dialogflow_cx_flow.default
}
```

When using the [`terraform import` command](https://developer.hashicorp.com/terraform/cli/commands/import), Flow can be imported using one of the formats above. For example:

```
$ terraform import google_dialogflow_cx_flow.default {{parent}}/flows/{{name}}
$ terraform import google_dialogflow_cx_flow.default {{parent}}/{{name}}
```
