---
# ----------------------------------------------------------------------------
#
#     ***     AUTO GENERATED CODE    ***    Type: MMv1     ***
#
# ----------------------------------------------------------------------------
#
#     This code is generated by Magic Modules using the following:
#
#     Configuration: https:#github.com/GoogleCloudPlatform/magic-modules/tree/main/mmv1/products/netapp/StoragePool.yaml
#     Template:      https:#github.com/GoogleCloudPlatform/magic-modules/tree/main/mmv1/templates/terraform/resource.html.markdown.tmpl
#
#     DO NOT EDIT this file directly. Any changes made to this file will be
#     overwritten during the next generation cycle.
#
# ----------------------------------------------------------------------------
subcategory: "Google Cloud NetApp Volumes"
description: |-
  Storage pools act as containers for volumes.
---

# google_netapp_storage_pool

Storage pools act as containers for volumes. All volumes in a storage pool share the following information:
* Location
* Service level
* Virtual Private Cloud (VPC) network
* Active Directory policy
* LDAP use for NFS volumes, if applicable
* Customer-managed encryption key (CMEK) policy

The capacity of the pool can be split up and assigned to volumes within the pool. Storage pools are a billable
component of NetApp Volumes. Billing is based on the location, service level, and capacity allocated to a pool
independent of consumption at the volume level.

Storage pools of service level Flex are available as zonal (single zone) or regional (two zones in same region) pools.
Zonal and regional pools are high-available within the zone. On top of that, regional pools have `replica_zone` as
hot standby zone. All volume access is served from the `zone`. If `zone` fails, `replica_zone`
automatically becomes the active zone. This will cause state drift in your configuration.
If a zone switch (manual or automatic) is triggered outside of Terraform, you need to adjust the `zone`
and `replica_zone` values to reflect the current state, or Terraform will initiate a zone switch when running
the next apply. You can trigger a manual
[zone switch](https://cloud.google.com/netapp/volumes/docs/configure-and-use/storage-pools/edit-or-delete-storage-pool#switch_active_and_replica_zones)
via Terraform by swapping the value of the `zone` and `replica_zone` parameters in your HCL code.


To get more information about StoragePool, see:

* [API documentation](https://cloud.google.com/netapp/volumes/docs/reference/rest/v1/projects.locations.storagePools)
* How-to Guides
    * [Quickstart documentation](https://cloud.google.com/netapp/volumes/docs/get-started/quickstarts/create-storage-pool)
    * [Regional Flex zone switch](https://cloud.google.com/netapp/volumes/docs/configure-and-use/storage-pools/edit-or-delete-storage-pool#switch_active_and_replica_zones)

## Example Usage - Storage Pool Create Doc


```hcl
# Create a network or use datasource to reference existing network
resource "google_compute_network" "peering_network" {
  name = "test-network"
}

# Reserve a CIDR for NetApp Volumes to use
# When using shared-VPCs, this resource needs to be created in host project
resource "google_compute_global_address" "private_ip_alloc" {
  name          = "test-address"
  purpose       = "VPC_PEERING"
  address_type  = "INTERNAL"
  prefix_length = 16
  network       = google_compute_network.peering_network.id
}

# Create a Private Service Access connection
# When using shared-VPCs, this resource needs to be created in host project
resource "google_service_networking_connection" "default" {
  network                 = google_compute_network.peering_network.id
  service                 = "netapp.servicenetworking.goog"
  reserved_peering_ranges = [google_compute_global_address.private_ip_alloc.name]
}

# Modify the PSA Connection to allow import/export of custom routes
# When using shared-VPCs, this resource needs to be created in host project
resource "google_compute_network_peering_routes_config" "route_updates" {
  peering = google_service_networking_connection.default.peering
  network = google_compute_network.peering_network.name

  import_custom_routes = true
  export_custom_routes = true
}

# Create a storage pool
# Create this resource in the project which is expected to own the volumes
resource "google_netapp_storage_pool" "test_pool" {
  name = "test-pool"
  # project = <your_project>
  location = "us-central1"
  service_level = "PREMIUM"
  capacity_gib = "2048"
  network = google_compute_network.peering_network.id
}
```

## Argument Reference

The following arguments are supported:


* `service_level` -
  (Required)
  Service level of the storage pool.
  Possible values are: `PREMIUM`, `EXTREME`, `STANDARD`, `FLEX`.

* `capacity_gib` -
  (Required)
  Capacity of the storage pool (in GiB).

* `network` -
  (Required)
  VPC network name with format: `projects/{{project}}/global/networks/{{network}}`

* `location` -
  (Required)
  Name of the location. For zonal Flex pools specify a zone name, in all other cases a region name.

* `name` -
  (Required)
  The resource name of the storage pool. Needs to be unique per location/region.


* `description` -
  (Optional)
  An optional description of this resource.

* `labels` -
  (Optional)
  Labels as key value pairs. Example: `{ "owner": "Bob", "department": "finance", "purpose": "testing" }`.

  **Note**: This field is non-authoritative, and will only manage the labels present in your configuration.
  Please refer to the field `effective_labels` for all of the labels present on the resource.

* `active_directory` -
  (Optional)
  Specifies the Active Directory policy to be used. Format: `projects/{{project}}/locations/{{location}}/activeDirectories/{{name}}`.
  The policy needs to be in the same location as the storage pool.

* `kms_config` -
  (Optional)
  Specifies the CMEK policy to be used for volume encryption. Format: `projects/{{project}}/locations/{{location}}/kmsConfigs/{{name}}`.
  The policy needs to be in the same location as the storage pool.

* `ldap_enabled` -
  (Optional)
  When enabled, the volumes uses Active Directory as LDAP name service for UID/GID lookups. Required to enable extended group support for NFSv3,
  using security identifiers for NFSv4.1 or principal names for kerberized NFSv4.1.

* `zone` -
  (Optional)
  Specifies the active zone for regional Flex pools. `zone` and `replica_zone` values can be swapped to initiate a
  [zone switch](https://cloud.google.com/netapp/volumes/docs/configure-and-use/storage-pools/edit-or-delete-storage-pool#switch_active_and_replica_zones).
  If you want to create a zonal Flex pool, specify a zone name for `location` and omit `zone`.

* `replica_zone` -
  (Optional)
  Specifies the replica zone for regional Flex pools. `zone` and `replica_zone` values can be swapped to initiate a
  [zone switch](https://cloud.google.com/netapp/volumes/docs/configure-and-use/storage-pools/edit-or-delete-storage-pool#switch_active_and_replica_zones).

* `allow_auto_tiering` -
  (Optional)
  Optional. True if the storage pool supports Auto Tiering enabled volumes. Default is false.
  Auto-tiering can be enabled after storage pool creation but it can't be disabled once enabled.

* `custom_performance_enabled` -
  (Optional)
  Optional. True if using Independent Scaling of capacity and performance (Hyperdisk). Default is false.

* `total_throughput_mibps` -
  (Optional)
  Optional. Custom Performance Total Throughput of the pool (in MiB/s).

* `total_iops` -
  (Optional)
  Optional. Custom Performance Total IOPS of the pool If not provided, it will be calculated based on the totalThroughputMibps

* `hot_tier_size_gib` -
  (Optional)
  Total hot tier capacity for the Storage Pool. It is applicable only to Flex service level.
  It should be less than the minimum storage pool size and cannot be more than the current storage pool size. It cannot be decreased once set.

* `enable_hot_tier_auto_resize` -
  (Optional)
  Flag indicating that the hot-tier threshold will be auto-increased by 10% of the hot-tier when it hits 100%. Default is true.
  The increment will kick in only if the new size after increment is still less than or equal to storage pool size.

* `qos_type` -
  (Optional)
  QoS (Quality of Service) type of the storage pool.
  Possible values are: AUTO, MANUAL.
  Possible values are: `QOS_TYPE_UNSPECIFIED`, `AUTO`, `MANUAL`.

* `type` -
  (Optional)
  Type of the storage pool.
  This field is used to control whether the pool supports FILE based volumes only or UNIFIED (both FILE and BLOCK) volumes.
  If not specified during creation, it defaults to FILE.
  Possible values are: `STORAGE_POOL_TYPE_UNSPECIFIED`, `FILE`, `UNIFIED`.

* `project` - (Optional) The ID of the project in which the resource belongs.
    If it is not provided, the provider project is used.



## Attributes Reference

In addition to the arguments listed above, the following computed attributes are exported:

* `id` - an identifier for the resource with format `projects/{{project}}/locations/{{location}}/storagePools/{{name}}`

* `volume_capacity_gib` -
  Size allocated to volumes in the storage pool (in GiB).

* `volume_count` -
  Number of volume in the storage pool.

* `encryption_type` -
  Reports if volumes in the pool are encrypted using a Google-managed encryption key or CMEK.

* `available_throughput_mibps` -
  Available throughput of the storage pool (in MiB/s).

* `cold_tier_size_used_gib` -
  Total cold tier data rounded down to the nearest GiB used by the storage pool.

* `hot_tier_size_used_gib` -
  Total hot tier data rounded down to the nearest GiB used by the storage pool.

* `terraform_labels` -
  The combination of labels configured directly on the resource
   and default labels configured on the provider.

* `effective_labels` -
  All of labels (key/value pairs) present on the resource in GCP, including the labels configured through Terraform, other clients and services.


## Timeouts

This resource provides the following
[Timeouts](https://developer.hashicorp.com/terraform/plugin/sdkv2/resources/retries-and-customizable-timeouts) configuration options:

- `create` - Default is 45 minutes.
- `update` - Default is 60 minutes.
- `delete` - Default is 45 minutes.

## Import


StoragePool can be imported using any of these accepted formats:

* `projects/{{project}}/locations/{{location}}/storagePools/{{name}}`
* `{{project}}/{{location}}/{{name}}`
* `{{location}}/{{name}}`

In Terraform v1.12.0 and later, use an [`identity` block](https://developer.hashicorp.com/terraform/language/resources/identities) to import StoragePool using identity values. For example:

```tf
import {
  identity = {
    location = "<-required value->"
    name = "<-required value->"
    project = "<-optional value->"
  }
  to = google_netapp_storage_pool.default
}
```

In Terraform v1.5.0 and later, use an [`import` block](https://developer.hashicorp.com/terraform/language/import) to import StoragePool using one of the formats above. For example:

```tf
import {
  id = "projects/{{project}}/locations/{{location}}/storagePools/{{name}}"
  to = google_netapp_storage_pool.default
}
```

When using the [`terraform import` command](https://developer.hashicorp.com/terraform/cli/commands/import), StoragePool can be imported using one of the formats above. For example:

```
$ terraform import google_netapp_storage_pool.default projects/{{project}}/locations/{{location}}/storagePools/{{name}}
$ terraform import google_netapp_storage_pool.default {{project}}/{{location}}/{{name}}
$ terraform import google_netapp_storage_pool.default {{location}}/{{name}}
```

## User Project Overrides

This resource supports [User Project Overrides](https://registry.terraform.io/providers/hashicorp/google/latest/docs/guides/provider_reference#user_project_override).
