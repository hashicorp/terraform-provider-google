---
# ----------------------------------------------------------------------------
#
#     ***     AUTO GENERATED CODE    ***    Type: MMv1     ***
#
# ----------------------------------------------------------------------------
#
#     This code is generated by Magic Modules using the following:
#
#     Configuration: https:#github.com/GoogleCloudPlatform/magic-modules/tree/main/mmv1/products/compute/StoragePool.yaml
#     Template:      https:#github.com/GoogleCloudPlatform/magic-modules/tree/main/mmv1/templates/terraform/resource.html.markdown.tmpl
#
#     DO NOT EDIT this file directly. Any changes made to this file will be
#     overwritten during the next generation cycle.
#
# ----------------------------------------------------------------------------
subcategory: "Compute Engine"
description: |-
  A Hyperdisk Storage Pool is a pre-purchased collection of capacity, throughput, and IOPS
  which you can then provision to your applications as needed.
---

# google_compute_storage_pool

A Hyperdisk Storage Pool is a pre-purchased collection of capacity, throughput, and IOPS
which you can then provision to your applications as needed.
You can use Hyperdisk Storage Pools to create and manage disks in pools and use the disks across multiple workloads.


To get more information about StoragePool, see:

* [API documentation](https://cloud.google.com/compute/docs/reference/rest/v1/storagePools)
* How-to Guides
    * [Create Hyperdisk Storage Pools](https://cloud.google.com/compute/docs/disks/create-storage-pools)

## Example Usage - Compute Storage Pool Basic


```hcl
resource "google_compute_storage_pool" "test-storage-pool-basic" {
  name = "storage-pool-basic"

  pool_provisioned_capacity_gb = "10240"

  pool_provisioned_throughput = 100

  storage_pool_type = "hyperdisk-throughput"

  zone = "us-central1-a"

  labels = {
    environment = "test"
    purpose     = "storage-pool-testing"
    team        = "infrastructure"
    cost_center = "engineering"
  }

  deletion_protection = false
}

data "google_project" "project" {}
```
## Example Usage - Compute Storage Pool Full


```hcl
resource "google_compute_storage_pool" "test-storage-pool-full" {
  name = "storage-pool-full"

  description = "Hyperdisk Balanced storage pool"

  capacity_provisioning_type   = "STANDARD"
  pool_provisioned_capacity_gb = "10240"

  performance_provisioning_type = "STANDARD"
  pool_provisioned_iops         = "10000"
  pool_provisioned_throughput   = "1024"

  storage_pool_type = data.google_compute_storage_pool_types.balanced.self_link

  labels = {
    environment = "test"
    purpose     = "storage-pool-testing"
    team        = "infrastructure"
    cost_center = "engineering"
  }

  deletion_protection = false

  zone = "us-central1-a"
}

data "google_project" "project" {}

data "google_compute_storage_pool_types" "balanced" {
  zone = "us-central1-a"
  storage_pool_type = "hyperdisk-balanced"
}
```

## Argument Reference

The following arguments are supported:


* `name` -
  (Required)
  Name of the resource. Provided by the client when the resource is created.
  The name must be 1-63 characters long, and comply with RFC1035.
  Specifically, the name must be 1-63 characters long and match
  the regular expression `[a-z]([-a-z0-9]*[a-z0-9])?`
  which means the first character must be a lowercase letter,
  and all following characters must be a dash, lowercase letter, or digit,
  except the last character, which cannot be a dash.

* `pool_provisioned_capacity_gb` -
  (Required)
  Size, in GiB, of the storage pool. For more information about the size limits,
  see https://cloud.google.com/compute/docs/disks/storage-pools.

* `pool_provisioned_throughput` -
  (Required)
  Provisioned throughput, in MB/s, of the storage pool.
  Only relevant if the storage pool type is `hyperdisk-balanced` or `hyperdisk-throughput`.

* `storage_pool_type` -
  (Required)
  Type of the storage pool. For example, the
  following are valid values:
  * `https://www.googleapis.com/compute/v1/projects/{project_id}/zones/{zone}/storagePoolTypes/hyperdisk-balanced`
  * `hyperdisk-throughput`


* `description` -
  (Optional)
  A description of this resource. Provide this property when you create the resource.

* `pool_provisioned_iops` -
  (Optional)
  Provisioned IOPS of the storage pool.
  Only relevant if the storage pool type is `hyperdisk-balanced`.

* `capacity_provisioning_type` -
  (Optional)
  Provisioning type of the byte capacity of the pool.
  Possible values are: `STANDARD`, `ADVANCED`.

* `performance_provisioning_type` -
  (Optional)
  Provisioning type of the performance-related parameters of the pool, such as throughput and IOPS.
  Possible values are: `STANDARD`, `ADVANCED`.

* `labels` -
  (Optional)
  Labels to apply to this storage pool. These can be later modified by the setLabels method.

  **Note**: This field is non-authoritative, and will only manage the labels present in your configuration.
  Please refer to the field `effective_labels` for all of the labels present on the resource.

* `zone` -
  (Optional)
  A reference to the zone where the storage pool resides.

* `project` - (Optional) The ID of the project in which the resource belongs.
    If it is not provided, the provider project is used.

* `deletion_policy` - (Optional) Whether Terraform will be prevented from destroying the resource. Defaults to DELETE.
	When a 'terraform destroy' or 'terraform apply' would delete the resource,
	the command will fail if this field is set to "PREVENT" in Terraform state.
	When set to "ABANDON", the command will remove the resource from Terraform
	management without updating or deleting the resource in the API.
	When set to "DELETE", deleting the resource is allowed.
* `deletion_protection` - (Optional) Whether Terraform will be prevented from destroying the StoragePool.
When the field is set to true or unset in Terraform state, a `terraform apply`
or `terraform destroy` that would delete the StoragePool will fail.
When the field is set to false, deleting the StoragePool is allowed.



## Attributes Reference

In addition to the arguments listed above, the following computed attributes are exported:

* `id` - an identifier for the resource with format `projects/{{project}}/zones/{{zone}}/storagePools/{{name}}`

* `kind` -
  Type of the resource.

* `id` -
  The unique identifier for the resource. This identifier is defined by the server.

* `creation_timestamp` -
  Creation timestamp in RFC3339 text format.

* `label_fingerprint` -
  The fingerprint used for optimistic locking of this resource.
  Used internally during updates.

* `resource_status` -
  Status information for the storage pool resource.
  Structure is [documented below](#nested_resource_status).

* `status` -
  Status information for the storage pool resource.
  Structure is [documented below](#nested_status).

* `terraform_labels` -
  The combination of labels configured directly on the resource
   and default labels configured on the provider.

* `effective_labels` -
  All of labels (key/value pairs) present on the resource in GCP, including the labels configured through Terraform, other clients and services.


<a name="nested_resource_status"></a>The `resource_status` block contains:

* `last_resize_timestamp` -
  (Output)
  Timestamp of the last successful resize in RFC3339 text format.

* `disk_count` -
  (Output)
  Number of disks used.

* `pool_used_capacity_bytes` -
  (Output)
  Space used by data stored in disks within the storage pool (in bytes).
  This will reflect the total number of bytes written to the disks in the pool,
  in contrast to the capacity of those disks.

* `pool_user_written_bytes` -
  (Output)
  Amount of data written into the pool, before it is compacted.

* `total_provisioned_disk_capacity_gb` -
  (Output)
  Sum of all the capacity provisioned in disks in this storage pool.
  A disk's provisioned capacity is the same as its total capacity.

* `max_total_provisioned_disk_capacity_gb` -
  (Output)
  Maximum allowed aggregate disk size in gigabytes.

* `pool_used_iops` -
  (Output)
  Sum of all the disks' provisioned IOPS, minus some amount
  that is allowed per disk that is not counted towards pool's IOPS capacity.
  For more information, see https://cloud.google.com/compute/docs/disks/storage-pools.

* `total_provisioned_disk_iops` -
  (Output)
  Sum of all the disks' provisioned IOPS.

* `pool_used_throughput` -
  (Output)
  Sum of all the disks' provisioned throughput in MB/s.

* `total_provisioned_disk_throughput` -
  (Output)
  Sum of all the disks' provisioned throughput in MB/s,
  minus some amount that is allowed per disk that is not counted towards pool's throughput capacity.

<a name="nested_status"></a>The `status` block contains:

* `last_resize_timestamp` -
  (Output)
  Timestamp of the last successful resize in RFC3339 text format.

* `disk_count` -
  (Output)
  Number of disks used.

* `pool_used_capacity_bytes` -
  (Output)
  Space used by data stored in disks within the storage pool (in bytes).
  This will reflect the total number of bytes written to the disks in the pool, in contrast to the capacity of those disks.

* `pool_user_written_bytes` -
  (Output)
  Amount of data written into the pool, before it is compacted.

* `total_provisioned_disk_capacity_gb` -
  (Output)
  Sum of all the capacity provisioned in disks in this storage pool.
  A disk's provisioned capacity is the same as its total capacity.

* `max_total_provisioned_disk_capacity_gb` -
  (Output)
  Maximum allowed aggregate disk size in gigabytes.

* `pool_used_iops` -
  (Output)
  Sum of all the disks' provisioned IOPS, minus some amount that is allowed per disk that is not counted towards pool's IOPS capacity. For more information, see https://cloud.google.com/compute/docs/disks/storage-pools.

* `total_provisioned_disk_iops` -
  (Output)
  Sum of all the disks' provisioned IOPS.

* `pool_used_throughput` -
  (Output)
  Sum of all the disks' provisioned throughput in MB/s.

* `total_provisioned_disk_throughput` -
  (Output)
  Sum of all the disks' provisioned throughput in MB/s,
  minus some amount that is allowed per disk that is not counted towards pool's throughput capacity.

## Timeouts

This resource provides the following
[Timeouts](https://developer.hashicorp.com/terraform/plugin/sdkv2/resources/retries-and-customizable-timeouts) configuration options:

- `create` - Default is 20 minutes.
- `update` - Default is 20 minutes.
- `delete` - Default is 20 minutes.

## Import


StoragePool can be imported using any of these accepted formats:

* `projects/{{project}}/zones/{{zone}}/storagePools/{{name}}`
* `{{project}}/{{zone}}/{{name}}`
* `{{zone}}/{{name}}`
* `{{name}}`


In Terraform v1.5.0 and later, use an [`import` block](https://developer.hashicorp.com/terraform/language/import) to import StoragePool using one of the formats above. For example:

```tf
import {
  id = "projects/{{project}}/zones/{{zone}}/storagePools/{{name}}"
  to = google_compute_storage_pool.default
}
```

When using the [`terraform import` command](https://developer.hashicorp.com/terraform/cli/commands/import), StoragePool can be imported using one of the formats above. For example:

```
$ terraform import google_compute_storage_pool.default projects/{{project}}/zones/{{zone}}/storagePools/{{name}}
$ terraform import google_compute_storage_pool.default {{project}}/{{zone}}/{{name}}
$ terraform import google_compute_storage_pool.default {{zone}}/{{name}}
$ terraform import google_compute_storage_pool.default {{name}}
```

## User Project Overrides

This resource supports [User Project Overrides](https://registry.terraform.io/providers/hashicorp/google/latest/docs/guides/provider_reference#user_project_override).
