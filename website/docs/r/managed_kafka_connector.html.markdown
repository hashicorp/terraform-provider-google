---
# ----------------------------------------------------------------------------
#
#     ***     AUTO GENERATED CODE    ***    Type: MMv1     ***
#
# ----------------------------------------------------------------------------
#
#     This code is generated by Magic Modules using the following:
#
#     Configuration: https:#github.com/GoogleCloudPlatform/magic-modules/tree/main/mmv1/products/managedkafka/Connector.yaml
#     Template:      https:#github.com/GoogleCloudPlatform/magic-modules/tree/main/mmv1/templates/terraform/resource.html.markdown.tmpl
#
#     DO NOT EDIT this file directly. Any changes made to this file will be
#     overwritten during the next generation cycle.
#
# ----------------------------------------------------------------------------
subcategory: "Managed Kafka"
description: |-
  A Managed Service for Kafka Connect Connectors.
---

# google_managed_kafka_connector

A Managed Service for Kafka Connect Connectors.

~> **Warning:** This resource is in beta, and should be used with the terraform-provider-google-beta provider.
See [Provider Versions](https://terraform.io/docs/providers/google/guides/provider_versions.html) for more details on beta resources.


## Example Usage - Managedkafka Connector Basic


```hcl
resource "google_project" "project" {
  project_id      = "tf-test%{random_suffix}"
  name            = "tf-test%{random_suffix}"
  org_id          = "123456789"
  billing_account = "000000-0000000-0000000-000000"
  deletion_policy = "DELETE"

  provider = google-beta
}

resource "time_sleep" "wait_60_seconds" {
  create_duration = "60s"
  depends_on = [google_project.project]
}

resource "google_project_service" "compute" {
  project = google_project.project.project_id
  service = "compute.googleapis.com"
  depends_on = [time_sleep.wait_60_seconds]

  provider = google-beta
}

resource "google_project_service" "managedkafka" {
  project = google_project.project.project_id
  service = "managedkafka.googleapis.com"
  depends_on = [google_project_service.compute]

  provider = google-beta
}

resource "time_sleep" "wait_120_seconds" {
  create_duration = "120s"
  depends_on = [google_project_service.managedkafka]
}

resource "google_compute_subnetwork" "mkc_secondary_subnet" {
  project       = google_project.project.project_id
  name          = "my-secondary-subnetwork-00"
  ip_cidr_range = "10.5.0.0/16"
  region        = "us-central1"
  network       = "default"
  depends_on = [time_sleep.wait_120_seconds]

  provider = google-beta
}

resource "google_pubsub_topic" "cps_topic" {
  project = google_project.project.project_id
  name = "my-cps-topic"
  message_retention_duration = "86600s"

  provider = google-beta
}

resource "google_managed_kafka_cluster" "gmk_cluster" {
  project = google_project.project.project_id
  cluster_id = "my-cluster"
  location = "us-central1"
  capacity_config {
    vcpu_count = 3
    memory_bytes = 3221225472
  }
  gcp_config {
    access_config {
      network_configs {
        subnet = "projects/${google_project.project.project_id}/regions/us-central1/subnetworks/default"
      }
    }
  }
  depends_on = [google_project_service.managedkafka]

  provider = google-beta
}

resource "google_managed_kafka_topic" "gmk_topic" {
  project = google_project.project.project_id
  topic_id = "my-topic"
  cluster = google_managed_kafka_cluster.gmk_cluster.cluster_id
  location = "us-central1"
  partition_count = 2
  replication_factor = 3
  depends_on = [google_project_service.managedkafka]

  provider = google-beta
}

resource "google_managed_kafka_connect_cluster" "mkc_cluster" {
  project = google_project.project.project_id
  connect_cluster_id = "my-connect-cluster"
  kafka_cluster = "projects/${google_project.project.project_id}/locations/us-central1/clusters/${google_managed_kafka_cluster.gmk_cluster.cluster_id}"
  location = "us-central1"
  capacity_config {
    vcpu_count = 12
    memory_bytes = 21474836480
  }
  gcp_config {
    access_config {
      network_configs {
        primary_subnet = "projects/${google_project.project.project_id}/regions/us-central1/subnetworks/default"
        additional_subnets = ["${google_compute_subnetwork.mkc_secondary_subnet.id}"]
        dns_domain_names = ["${google_managed_kafka_cluster.gmk_cluster.cluster_id}.us-central1.managedkafka.${google_project.project.project_id}.cloud.goog"]
      }
    }
  }
  labels = {
    key = "value"
  }
  depends_on = [google_project_service.managedkafka]

  provider = google-beta
}

resource "google_managed_kafka_connector" "example" {
  project = google_project.project.project_id
  connector_id = "my-connector"
  connect_cluster = google_managed_kafka_connect_cluster.mkc_cluster.connect_cluster_id
  location = "us-central1"
  configs = {
    "connector.class" = "com.google.pubsub.kafka.sink.CloudPubSubSinkConnector"
    "name" = "my-connector"
    "tasks.max" = "1"
    "topics" = "${google_managed_kafka_topic.gmk_topic.topic_id}"
    "cps.topic" = "${google_pubsub_topic.cps_topic.name}"
    "cps.project" = "${google_project.project.project_id}"
    "value.converter" = "org.apache.kafka.connect.storage.StringConverter"
    "key.converter" = "org.apache.kafka.connect.storage.StringConverter"
  }
  task_restart_policy {
    minimum_backoff = "60s"
    maximum_backoff = "1800s"
  }
  depends_on = [google_project_service.managedkafka]

  provider = google-beta
}
```

## Argument Reference

The following arguments are supported:


* `location` -
  (Required)
  ID of the location of the Kafka Connect resource. See https://cloud.google.com/managed-kafka/docs/locations for a list of supported locations.

* `connect_cluster` -
  (Required)
  The connect cluster name.

* `connector_id` -
  (Required)
  The ID to use for the connector, which will become the final component of the connector's name. This value is structured like: `my-connector-id`.


- - -


* `configs` -
  (Optional)
  Connector config as keys/values. The keys of the map are connector property names, for example: `connector.class`, `tasks.max`, `key.converter`.

* `task_restart_policy` -
  (Optional)
  A policy that specifies how to restart the failed connectors/tasks in a Cluster resource. If not set, the failed connectors/tasks won't be restarted.
  Structure is [documented below](#nested_task_restart_policy).

* `project` - (Optional) The ID of the project in which the resource belongs.
    If it is not provided, the provider project is used.


<a name="nested_task_restart_policy"></a>The `task_restart_policy` block supports:

* `minimum_backoff` -
  (Optional)
  The minimum amount of time to wait before retrying a failed task. This sets a lower bound for the backoff delay.
  A duration in seconds with up to nine fractional digits, terminated by 's'. Example: "3.5s".

* `maximum_backoff` -
  (Optional)
  The maximum amount of time to wait before retrying a failed task. This sets an upper bound for the backoff delay.
  A duration in seconds with up to nine fractional digits, terminated by 's'. Example: "3.5s".

## Attributes Reference

In addition to the arguments listed above, the following computed attributes are exported:

* `id` - an identifier for the resource with format `projects/{{project}}/locations/{{location}}/connectClusters/{{connect_cluster}}/connectors/{{connector_id}}`

* `name` -
  The name of the connector. The `connector` segment is used when connecting directly to the connect cluster. Structured like: `projects/PROJECT_ID/locations/LOCATION/connectClusters/CONNECT_CLUSTER/connectors/CONNECTOR_ID`.

* `state` -
  The current state of the connect. Possible values: `STATE_UNSPECIFIED`, `UNASSIGNED`, `RUNNING`, `PAUSED`, `FAILED`, `RESTARTING`, and `STOPPED`.


## Timeouts

This resource provides the following
[Timeouts](https://developer.hashicorp.com/terraform/plugin/sdkv2/resources/retries-and-customizable-timeouts) configuration options:

- `create` - Default is 60 minutes.
- `update` - Default is 30 minutes.
- `delete` - Default is 30 minutes.

## Import


Connector can be imported using any of these accepted formats:

* `projects/{{project}}/locations/{{location}}/connectClusters/{{connect_cluster}}/connectors/{{connector_id}}`
* `{{project}}/{{location}}/{{connect_cluster}}/{{connector_id}}`
* `{{location}}/{{connect_cluster}}/{{connector_id}}`


In Terraform v1.5.0 and later, use an [`import` block](https://developer.hashicorp.com/terraform/language/import) to import Connector using one of the formats above. For example:

```tf
import {
  id = "projects/{{project}}/locations/{{location}}/connectClusters/{{connect_cluster}}/connectors/{{connector_id}}"
  to = google_managed_kafka_connector.default
}
```

When using the [`terraform import` command](https://developer.hashicorp.com/terraform/cli/commands/import), Connector can be imported using one of the formats above. For example:

```
$ terraform import google_managed_kafka_connector.default projects/{{project}}/locations/{{location}}/connectClusters/{{connect_cluster}}/connectors/{{connector_id}}
$ terraform import google_managed_kafka_connector.default {{project}}/{{location}}/{{connect_cluster}}/{{connector_id}}
$ terraform import google_managed_kafka_connector.default {{location}}/{{connect_cluster}}/{{connector_id}}
```

## User Project Overrides

This resource supports [User Project Overrides](https://registry.terraform.io/providers/hashicorp/google/latest/docs/guides/provider_reference#user_project_override).
